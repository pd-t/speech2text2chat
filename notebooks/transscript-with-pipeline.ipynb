{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "968e2106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.27.4\n",
      "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/ray/anaconda3/lib/python3.8/site-packages (from transformers==4.27.4) (3.8.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ray/anaconda3/lib/python3.8/site-packages (from transformers==4.27.4) (2022.9.13)\n",
      "Requirement already satisfied: requests in /home/ray/anaconda3/lib/python3.8/site-packages (from transformers==4.27.4) (2.25.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from transformers==4.27.4) (0.13.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ray/anaconda3/lib/python3.8/site-packages (from transformers==4.27.4) (1.23.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ray/anaconda3/lib/python3.8/site-packages (from transformers==4.27.4) (4.63.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/ray/anaconda3/lib/python3.8/site-packages (from transformers==4.27.4) (0.12.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ray/anaconda3/lib/python3.8/site-packages (from transformers==4.27.4) (5.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from transformers==4.27.4) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ray/anaconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.27.4) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ray/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->transformers==4.27.4) (3.0.9)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ray/anaconda3/lib/python3.8/site-packages (from requests->transformers==4.27.4) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ray/anaconda3/lib/python3.8/site-packages (from requests->transformers==4.27.4) (2022.6.15)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ray/anaconda3/lib/python3.8/site-packages (from requests->transformers==4.27.4) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ray/anaconda3/lib/python3.8/site-packages (from requests->transformers==4.27.4) (1.26.8)\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.21.3\n",
      "    Uninstalling transformers-4.21.3:\n",
      "      Successfully uninstalled transformers-4.21.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ludwig 0.6.3 requires pyarrow==6.0.1, but you have pyarrow 11.0.0 which is incompatible.\n",
      "ludwig 0.6.3 requires transformers<4.22,>=4.10.1, but you have transformers 4.27.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed transformers-4.27.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.27.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9f8fc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ray/anaconda3/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e10f23bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 1.96kB [00:00, 1.14MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 6.17G/6.17G [01:01<00:00, 100MB/s] \n",
      "Downloading (…)neration_config.json: 3.51kB [00:00, 2.23MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 842/842 [00:00<00:00, 290kB/s]\n",
      "Downloading (…)olve/main/vocab.json: 1.04MB [00:00, 3.53MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 2.20MB [00:00, 11.1MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 494kB [00:00, 4.14MB/s]\n",
      "Downloading (…)main/normalizer.json: 52.7kB [00:00, 25.4MB/s]\n",
      "Downloading (…)in/added_tokens.json: 2.08kB [00:00, 1.06MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 2.08kB [00:00, 1.37MB/s]\n",
      "Downloading (…)rocessor_config.json: 185kB [00:00, 71.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "pipe = pipeline(\n",
    "  \"automatic-speech-recognition\",\n",
    "  model=\"openai/whisper-large\",\n",
    "  chunk_length_s=30,\n",
    "  device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71b30303",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ray/anaconda3/lib/python3.8/site-packages/transformers/generation/utils.py:1288: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \" Hello and welcome to Kubeflow update. We're going to give a Kubeflow update on the 1.1 release and I am Josh Bottom and I am part of the Kubeflow community product management team. Kubeflow 1.1 has included several community deliveries and in this portion we are going to review the applications that have been completed, which finished up in August 2020. And in this release, we worked hard to follow the process that we've defined, which really came and fermented around Kubeflow 1.0. And that includes using the Kubeflow and application roadmaps to define features in timing for releases, as well as the Kubeflow versioning policy, which defines the maturity level of the components, either stable, beta or alpha. And for the stable requirements, we've defined an applications requirements template, which gives a set of requirements that we expect folks to follow when they're creating a stable version of one of the components. We're tracking and have tracked the release of 1.1 in the Kanban board using this project here, which is clickable, as well as this issue 5022. So both those are clickable and you can go through and look at where the progress is. In 1.1, you can see we made additional components stable, including Kubeflow pipelines, training operators for XGBoost and fare MXNet, and as well as the fairing component. This is in addition to all the components that we have made stable in the March portion, the March release of Kubeflow 1.0. And you can see all the roadmaps for the different components that are posted over here in these clickable links. Kubeflow 1.1 has six major deliveries, and those include simplifying pipeline building workflows. So that includes build train and tuna, as well as deploy from a notebook. Production operations and performance for MX net and XG boost distributed model training improved user isolation security and administration, including multi user pipelines. Improved model tuning with new and algorithms, as well as flexible configuration and tuning options. GitOps foundations for installation, configuration and management, in some cases even upgrades, as well as easier Kubeflow blog posting via a fast I process that we'll talk about here a little later. So now we're going to dive into the details. In this first section we'll have Jingxi go over the fairing CUJ. Jingxi over to you. Hello everyone. So let me update the QPLO foundry. So So you know KuboFlow Firmware is a PANZ SDK that can help users to process your training code and build a doc image and then deploy a job, gift job or petosh job to train your code. And then you can use the F public service of course family support to public service by keep serving so this release we get a stable release for kubeflow firing so our first item is that that we improved the file quality in this release And we fixed some bugs and enhanced the testing and examples under the kubectl-finr wrapper. And the next one is we enhanced the API document. As you know, Finr has a lot of API and if there is no API document, that is very bad for the end user. So this release, we take some effort to work on the API document enhancement. And the next one is we made some generic functions to interact with Kubernetes. So those functions support to apply the backend spec to the Kubernetes cluster. And next one, so we support one more build such as Podman and also support one more backend such as AmiCloud And the next one is this release family support config environment variables for deployment. That's very very important for ad users. So you know from this feature user can configure their environment variables for the deployment. And also this release, FanRee support to mount in the volume such as the PVC, screen and the config map for the deployer. So in one word, FanRee get stable release. So you can try the new Fan release. Thank you. Okay. Thanks, Jiushi. Now we'll pass it over to Konstantinos to talk about the KLCUJ. Konstantinos? Hello, everyone. This is Konstantinos from Oricto. During the 1.1 release cycle, we made some significant improvements also to the end-to-end customer user journey for building, training, tuning, and debugging models faster with Kailh. For those who don't know what Kailh is, Kailh is an open source workflow tool on top of Kubeflow that allows you to build pipelines directly from your code in a notebook or your IDE, for example, VS Code. To do that, it comes as a JupyterLab extension or an SDK. So you simply tag a cell with your remote code via the UI to create a pipeline step. And with one click, Kailh snapshots the environment, builds and runs a pipeline without the need to write any Kubeflow pipelines DSL code or build any Docker images. So with 1.1, Kailh now supports HP tuning with the Kative component of Kubeflow. So now you can tag shells to define hyperparameters and then set HP tuning job parameters all from a user interface, then starts the cattyp job. You can easily view the results and dig into the details provided by the pipeline runs. And it also comes with support for pipeline step caching that allows you to scale very efficiently. You can follow the links. We have an end-to-end tutorial that you can follow through and a video showcasing the end-to-end workflow. And with that, back to you, Josh. Thanks, Carlos. Now we'll go to the distributed training operators. Hi, everyone. This is Jiaxin from AWS. So I will give some updates on the training operators. In 1.1 release, community concentrate more on the reusability, performance, and maintainability of the training operators. The most important change is we released a stable Kubeflow common library. So some users may not have contacts of this library. As we know, Kubeflow has many distributed training operators, and most of them have similar designs and implementations. So in mid 2019 we started Coolflow Common Projects, aims to extract those common reconcellular logics and CRD types to make sure they can be reused in different training operators. So ideally we can add like generic logics and like fixes in the Coolflow Common project. Different operators just need to upgrade common dependencies to leverage these benefits and new changes. In the latest stable version, it starts to support a volcano batch scheduler, which is the main GAN scheduler offering in the community. It also provides the flexible interface to support like both informer and computer based operators. The app creates the dependency versions like Kubernetes, controller runtime, controller tools and refactor the codes to enhance the maintainability. So one last important feature is common controller reconciles the worker scale down events to support dynamic or elastic training. So that means the number of the workers can be changed during the training if the framework has the support like torch elastic. Currently we have migrated TensorFlow MXNet XGBoost implementations to this fashion and PyTorch is in progress. The major user facing changes are MXNet XGBoost and MPI operators both support V1 APIs. Most of the work to graduate feel free to take a look. Yeah, that's all the updates from training operator side. Thank you. And now for the multi-user pipeline update. Thank you Josh. For Kubeflow pipelines, now in run multiple deployments. So basically, Kubeflow pipelines resources are separated by namespace or also called profile in Kubeflow. And you can go to the UI and select the namespace selector to only view resources in your namespace. Also, the run in user namespaces so you can separate extra resources like secrets or config maps or whatever you like when integrating with Qubeflow pipelines. Other benefits also important are like we supported easier upgrade in Kubeflow. And we have brought new features like caching and artifact lineage auto tracking that are coming in this release. And do not forget that in 1.0 release, we have been doing a lot of bug fixes. We have improved usability and performance significantly that I hope will make the user experience more smoothly. And below are some references. You can get more information about this. I'll hand back to you, Josh. Thank you. Thank you, Yuan. And I know that many people have been looking for the QPo pipelines 1.0 and stable version. So great delivery here. Thank you very much for your work and for your team's work on this. And now we hand off to Andre to give an update on Catibib. Hi everyone. Today I'm just going to show you some quick updates for Katib, what we bring for 1.1 Kubeflow. And for 1.1 Katib is still with an alpha 3.0 release, but we just bring some new features. And especially one of the main feature was integrating new frameworks, especially go up tuna. And we integrating the new high primary tunic algorithm called covariance matrix adaptation of all the evolution strategy. And to continue integrating with neural architecture search algorithm, we integrated darts. This is like very common algorithm and should be very useful to use in KDIP. Also, we tried to support other frameworks like Chocolate Hyper-op and SQ-op to bring more stability and usability for end user. And one of the main feature was integrating new Python SDK to integrate KDP in the notebooks, Kubeflow notebooks and run it very smoothly. Also, we're improving UI with new trial template editor and right now users can run experiment without the goal. So it should be useful when you want to run experiment for the long time. And also, we integrate the resume policies when you just easily can kill off your resources after experiment is finished. Yeah, I think this is like the main features that we bring for 1.1. And also we try to make it stable for the future releases.. All right now we'll hand off to Jeff to talk about CVE scanning. Thanks. So the goal here was to mitigate some of the critical common vulnerabilities that we find when we scan Docker images and the project's been going on well this process has been going on quite a while. And with the creation of the new working groups, we're hoping, I'm hoping to get this part of the working group process. But we've had some success with mitigating. There's still a few outgoing. But more to come in the next releases. Now we get to hand it off to Animesh. Essentially the focus in this release was on stability and many features were added around that. But beyond stability, one of the key requirements we had around adding GPU support for PyTorch, model servers which was added, adding a Pickle model format support for Scikit-learn model which was added. And in terms of the stability, one of the major moves which we did was upgrading from Knative APIs from V1 Alpha 1 to V1. And that also entailed in turn upgrading some of the Kubernetes dependencies to 1.15 and Knative dependencies to 1.11. That brought a lot of the features which have been made available in Knative vis-a-vis the stability. There are more enhancements which we added around routing. So for example, supporting internal mesh routing to inference service. So for example, you can route from a Kafka based event source using this mechanism. Other things were added around a parallelism field to allow setting auto scaling target concurrency. Last but not the least, we also made the default for min replicas to one instead of zero. We have heard time and again from the community in terms of having a default scale back default to set to one, because in that case, you take advantage of some of the delays which happen if you have defaulted back to zero. And we are pretty sure as Knative improves, that feature will be improved to a core start from zero onwards. In addition, there are quite a bit of talks we have compiled from different conferences which have been uploaded on the KFServin community page where it's either the contributors to KFServin as well as the users of KFServin talking about the technical details as well as their usage infrastructure. There is also a page which we have compiled which actually goes and lists all the different users of KFServin who are either runningFServing in production or providing KFServing support on their cloud platform or redistributing KFServing. So if you go, you'll see a pretty comprehensive list at this point where we have 10 to 11 different adopters who are leveraging KFServing for their own needs. Thanks. With that, I will pass on to Iyegar. Hi, everyone. In this version we have made some significant improvements to GitOps processes for Kubeflow. Our goal is to simplify Kubeflow stack integration and configuration and management and eventually upgrades. So at the core of GitOps processes is Git repository, which is used as the central source of truth for all Kubeflow deployments for all environments. And with GitOps, you can now commit all infrastructure as code scripts into Git and then run installs and configurations from this Git repository. With Git you will achieve a lot better automation and also auditing and debugging of all Kubeflow environments. And there are several GitOps projects that we would encourage you to take a look at. Here you will find a link to Erectus example of GitOps processes and a link to AgileStacks example of GitOps processes to install, deploy and manage Kubeflow. I will turn it over back to Josh. Thanks Igor. And now we will talk about some ecosystem enhancements and hand off to Clive from Selden. 2.1 of Seldom which comes in this release we have new Golang service orchestrator which is protocol agnostic which means we can now support Seldom and TensorFlow protocols and further protocols in the future. I mean as usual Seldom allows you to build powerful inference graphs made up of models routers ensemble and many after the box optimized model servers. We've also added Qflow pipeline examples to show you how you can train and deploy models onto Seldom core and add key components such as state of the art outline detection, drift detection, and model explanation components using Seldom's open source Adoai Explain and Adoai Detect projects. And you can find a link to those examples on this slide. So yeah, so in general, we're looking forward to getting your feedback and further integrating with Qflow in the future. So thanks and back to Josh. Okay, well, thank you, Clive. And now we'll move on to another ecosystem enhancement from the Feast community and off to Willem. Thanks, Josh. This is Willem from the Feast community. So I'm excited to talk a bit about v0.6 and what that means for Kubeflow. So with Kubeflow 1.1, it's a first step towards integrating Feast as a top-level component into Kubeflow. So for this release, we've extended the Kubeflow documentation to include both the motivation for why you would want to use Feast, a feature store for machine learning in your use cases or for your use cases, and how you can get started. So we've also included some guides on installing Feast alongside Kubeflow, as well as tutorials and examples that show users how they can do that. So Feast is a system that essentially abstracts away your data modeling and your data engineering from your ML and operational requirements like model training and model serving. It manages ingestion jobs and the persistence of data. It allows teams to define and track features and reuse features. And it also provides a point in time correct view for retrieval of feature data for training and for serving. The latest Feast release, v0.6, also includes statistic generation and validation that ensures that your production system stays safe. For Kubeflow 1.2 and new releases, we're planning to also include or further integrate and potentially even deploy Feast alongside Kubeflow. So we're excited to be working with the Kubeflow community on that. That's it from my side. Back to you, Josh. Thank you very much and a great update. And now on to simplifying blog posts with Hamil. Hamil, can you give us an update on your work here? Yeah, sure. So we now have a blog system that you can see on this GitHub repo, kuflo.blog. So the reason why we have instituted this alternative blogging system is to allow a process to happen with regards to reviewing blog posts and discussing blog posts because with Medium before it was really difficult to have a transparent process of review and the community really wanted something that looked a lot like a pull request where somebody you know write something and then people can comment on it and then propose or make suggestions and then it can go through some kind of formal review and then get merged. And so a question came up is whether something like that can be done with blogs. So it turns out that the Fastai community has something called Fastpages. I'm the maintainer of that project. And what that project is, is it's a way where you can write blog posts with Jupyter notebooks or Markdown. And the purpose of that project is to make it really easy to write blog posts with Jupyter notebooks. Sort of before that, it was kind of difficult to write blog posts with Jupyter. You have to kind of prepare your notebook and then do a bunch of conversion scripts to kind of convert the notebook to HTML and then do all kinds of other stuff to make it suitable for a blog. And it was actually really complicated. So FastPages automates all of that. You save your notebook into a folder and then GitHub actions runs those conversion scripts for you, converts that to HTML, and then that's available as a blog post. And so one thing that you should know is there's a lot of configuration options and there's a lot of ways you can customize it. And there's a lot of ways you can even customize a blog post itself especially the formatting and stuff like that. There's a fairly lengthy read me that I encourage everybody to read if you are going to write a blog post. So you go to the fast pages repo, there is a really big instruction manual on how to do things like embed images or tweak your social cards on your blog post or to enable comments if you want people to be able to make comments. So there's a commenting system that is hooked in with GitHub issues. So when people comment on your blog post, it actually opens a GitHub issue on the blog website. So it's actually pretty convenient. And there's a lot of other cool stuff, like the ability to have collapsible code cells and then you know you can put images gifts with captions and all kinds of stuff it's very rich it's actually been used a lot in the data science community and especially the fast AI community so we have a couple of blog posts I think that have launched recently from the Kubeflow community on this site. So I think, you know, I encourage everybody to check it out and especially if you're interested in writing a blog post. I'll give it back to you, Josh. Hey, Hamill, thanks for all your work there. This is something critical to the growth of the community, especially in the need for us to let people know all the great work they're doing, whether it be an article or a blog post or even better yet, a tutorial with those notebooks in there. This is great work and we really do appreciate it. Okay, so we've covered a lot and now we're gonna talk about how to get involved and especially since we've Confirmed or approved a proposal for the Qflow working groups. We really look forward to and encourage people to either join a working group or start one as either a team lead a chair chair or a participating member. And for all of those folks that are just getting started in Kubeflow, remember we do have the Kubeflow Slack channel, the Kubeflow discuss mailing list, as well as the community meetings every Tuesday. You can see all the deliveries in Kubeflow in GitHub. and we really look forward to your success with Kubeflow 1.1. And with that I would just like to make sure that as you look to join the Kubeflow community you can see on this list all the folks that have contributed in this release. There are many others but these are the ones that were primarily to this. And you can see many of this top market leaders, whether it be Ant or Bloomberg and Cisco, Google, Seldin, GitHub, Eriktto and Amazon. So I think this is a great group of folks and we really do encourage you to get involved and participate either as a contributor or user and we really do appreciate your feedback and work in the Kubeflow community. Thanks again and we look forward to your questions and supporting your work on 1.1.\"}\n"
     ]
    }
   ],
   "source": [
    "text = pipe(\"audio.mp3\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b350ee53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ray/anaconda3/lib/python3.8/site-packages/transformers/generation/utils.py:1288: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'timestamp': (0.0, 9.44), 'text': \" Hello and welcome to Kubeflow update. We're going to give a Kubeflow update on the 1.1 release.\"}, {'timestamp': (9.44, 17.12), 'text': ' And I am Josh Bottom and I am part of the Kubeflow Community Product Management team.'}, {'timestamp': (18.96, 28.8), 'text': ' Kubeflow 1.1 has included several community deliveries and And in this portion, we are going to review'}, {'timestamp': (28.8, 31.4), 'text': ' the applications that have been completed,'}, {'timestamp': (31.4, 34.64), 'text': ' which finished up in August 2020.'}, {'timestamp': (35.66, 40.48), 'text': ' And in this release, we worked hard to follow the process'}, {'timestamp': (40.48, 44.76), 'text': \" that we've defined, which really came and fermented\"}, {'timestamp': (44.76, 47.0), 'text': ' around Kubeflow 1.0.'}, {'timestamp': (47.0, 54.0), 'text': ' And that includes using the Kubeflow and application roadmaps to define features in timing for releases,'}, {'timestamp': (54.0, 65.0), 'text': ' as well as the Kubeflow versioning policy, which defines the maturity level of the components, either stableava, Stable, Beta or Alpha.'}, {'timestamp': (65.64, 68.26), 'text': ' And for the Stable requirements,'}, {'timestamp': (68.26, 72.0), 'text': \" we've defined an applications requirement template,\"}, {'timestamp': (72.0, 74.9), 'text': ' or excuse me, applications requirements template,'}, {'timestamp': (74.9, 78.88), 'text': ' which gives a set of requirements that we expect folks'}, {'timestamp': (78.88, 83.12), 'text': \" to follow when they're creating a Stable version\"}, {'timestamp': (83.12, 85.0), 'text': ' of one of the components.'}, {'timestamp': (85.08, 89.76), 'text': \" We're tracking and have tracked the release of 1.1\"}, {'timestamp': (89.76, 93.32), 'text': ' in the Kanban board using this project here,'}, {'timestamp': (93.32, 97.54), 'text': ' which is just clickable, as well as this issue 5022.'}, {'timestamp': (97.54, 99.66), 'text': ' So both those are clickable and you can go through'}, {'timestamp': (99.66, 101.48), 'text': ' and look at where the progress is.'}, {'timestamp': (102.36, 107.36), 'text': ' In 1.1, you can see we made additional components stable,'}, {'timestamp': (108.5, 110.3), 'text': ' including Kubeflow pipelines,'}, {'timestamp': (110.3, 115.3), 'text': ' training operators for XGBoost and Fairen MXNet,'}, {'timestamp': (116.14, 118.7), 'text': ' and as well as the Fairen component.'}, {'timestamp': (118.7, 120.98), 'text': ' This is in addition to all the components'}, {'timestamp': (120.98, 128.08), 'text': ' that we have made stable in the March portion, the March release of Kubeflow 1.0.'}, {'timestamp': (128.72, 133.2), 'text': ' And you can see all the roadmaps for the different components that are posted'}, {'timestamp': (134.16, 141.12), 'text': ' over here in these clickable links. Kubeflow 1.1 has six major deliveries,'}, {'timestamp': (141.76, 145.68), 'text': ' and those include simplifying pipeline building workflows, so that includes'}, {'timestamp': (145.68, 152.6), 'text': ' build, train and tune as well as deploy from a notebook. Production operations and performance'}, {'timestamp': (152.6, 161.2), 'text': ' for MXNet and XGBoost distributed model training. Improved user isolation, security and administration,'}, {'timestamp': (161.2, 167.0), 'text': ' including multi-user pipelines. Improved model tuning with new frameworks and algorithms,'}, {'timestamp': (167.0, 171.0), 'text': ' as well as flexible configuration and tuning options.'}, {'timestamp': (171.0, 188.66), 'text': \" GitOps foundations for installation, configuration, and management, in some cases even upgrades, upgrades as well as easier QPLO blog posting via a fast I process that we'll talk about\"}, {'timestamp': (188.66, 190.2), 'text': ' here a little later.'}, {'timestamp': (190.2, 192.84), 'text': \" So now we're going to dive into the details.\"}, {'timestamp': (192.84, 197.8), 'text': \" In this first section we'll have Jingxi go over the fairing CUJ.\"}, {'timestamp': (197.8, 200.12), 'text': ' Jingxi, over to you.'}, {'timestamp': (200.12, 201.52), 'text': ' Hello everyone.'}, {'timestamp': (201.52, 205.0), 'text': ' So let me update the KuboFlow Firmware.'}, {'timestamp': (205.0, 216.0), 'text': ' So you know KuboFlow Firmware is a PANZ SDK that can help users to process your training code and build a doc image,'}, {'timestamp': (216.0, 226.96), 'text': ' and then deploy a job, gift job, or pet horse job to train your code and then you can use the file to public service.'}, {'timestamp': (226.96, 231.2), 'text': ' Of course, file support to public service by ksv.'}, {'timestamp': (231.2, 236.64), 'text': ' So this release we get a stable release for kubeflow file.'}, {'timestamp': (236.64, 248.94), 'text': ' So first item is that we improved the file quality in this release. And we fixed the sub-bugs and enhanced the testing'}, {'timestamp': (248.94, 253.36), 'text': ' and example under the kuboflow-finr wrapper.'}, {'timestamp': (253.36, 257.68), 'text': ' And the next one is we enhanced the API document.'}, {'timestamp': (257.68, 260.96), 'text': ' As you know, Finr has a lot of API'}, {'timestamp': (260.96, 264.82), 'text': ' and if there is no API document,'}, {'timestamp': (264.82, 268.08), 'text': ' that is very bad for the end user. So this release'}, {'timestamp': (268.8, 278.88), 'text': ' we take some effort to work on the API document enhancement. The next one is we made some'}, {'timestamp': (278.88, 287.9), 'text': ' generator function to interact with Kubernetes. So this function supports applying'}, {'timestamp': (287.9, 296.68), 'text': ' the backend spec to the Kubernetes cluster. Next one, we support one more'}, {'timestamp': (296.68, 309.84), 'text': ' build such as Podman and also support one more backend such as AmiCloud. And the next one is this release, family support'}, {'timestamp': (309.84, 318.16), 'text': \" config environment variables for deployment. That's very important for ad users. So you know\"}, {'timestamp': (319.04, 324.88), 'text': ' from this feature user can configure their environment variables for the deployment.'}, {'timestamp': (326.08, 333.0), 'text': ' user can configure their environment variables for the deployment. And also this release, FanRee supports two mountain volumes such as the PVC,'}, {'timestamp': (333.0, 337.04), 'text': ' CRID, and the config map for the deployer.'}, {'timestamp': (337.04, 344.4), 'text': ' So in one word, FanRee get stable release, so you can try the new FanRee release.'}, {'timestamp': (344.4, 348.08), 'text': ' Thank you.'}, {'timestamp': (353.24, 358.96), 'text': \" Okay. Thanks, Jiushi. Now we'll pass it over to Constantinos to talk about the KLCUJ. Constantinos? Hello, everyone. This is Constantinos from\"}, {'timestamp': (358.96, 366.04), 'text': ' Oricto. During the 1.1 release cycle, we made some significant improvements also to'}, {'timestamp': (366.04, 371.92), 'text': ' the end-to-end customer user journey for building, training, tuning and debugging'}, {'timestamp': (371.92, 376.48), 'text': \" models faster with Kailh. For those who don't know what Kailh is, Kailh is an\"}, {'timestamp': (376.48, 387.28), 'text': ' open source workflow tool on top of Kubeflow that allows you to build pipelines directly from your code in a notebook or your IDE,'}, {'timestamp': (387.28, 396.64), 'text': ' for example, VS Code. To do that, it comes as a JupyterLab extension or an SDK. So you'}, {'timestamp': (396.64, 404.48), 'text': ' simply tag a cell with your remote code via the UI to create a pipeline step. And with'}, {'timestamp': (404.48, 406.66), 'text': ' one click, Kailh snapshots the environment, builds and runs a pipeline step and with one click Kailh snapshots the environment'}, {'timestamp': (406.66, 412.1), 'text': ' builds and runs a pipeline without the need to write any'}, {'timestamp': (412.1, 420.3), 'text': ' Kubeflow pipelines DSL code or build any Docker images. So with 1.1 Kailh now'}, {'timestamp': (420.3, 425.0), 'text': ' supports HP tuning with the Kativep component of Kubeflow.'}, {'timestamp': (425.98, 430.98), 'text': ' So now you can tag shells to define hyperparameters'}, {'timestamp': (431.06, 433.5), 'text': ' and then set HP tuning job parameters'}, {'timestamp': (433.5, 437.9), 'text': ' all from a user interface, then starts the cattyp job.'}, {'timestamp': (437.9, 439.58), 'text': ' You can easily view the results'}, {'timestamp': (439.58, 443.18), 'text': ' and dig into the details provided by the pipeline runs.'}, {'timestamp': (443.18, 448.2), 'text': ' And it also comes with support for pipeline step caching'}, {'timestamp': (449.2, 452.66), 'text': ' that allows you to scale very efficiently.'}, {'timestamp': (453.7, 455.16), 'text': ' You can follow the links.'}, {'timestamp': (455.16, 460.16), 'text': ' We have an end-to-end tutorial that you can follow through'}, {'timestamp': (460.28, 463.4), 'text': ' and a video showcasing the end-to-end workflow.'}, {'timestamp': (463.4, 466.2), 'text': ' With that, back to you, Josh.'}, {'timestamp': (466.2, 468.0), 'text': ' Thanks, Carlos.'}, {'timestamp': (468.0, 471.96), 'text': \" Now we'll go to the distributed training operators.\"}, {'timestamp': (471.96, 473.4), 'text': ' Hi, everyone.'}, {'timestamp': (473.4, 476.44), 'text': ' This is Jiaxin from AWS.'}, {'timestamp': (476.44, 479.88), 'text': ' So I will give some updates on the training operators.'}, {'timestamp': (479.88, 483.4), 'text': ' In 1.1 release, community concentrate more'}, {'timestamp': (483.4, 489.0), 'text': ' on the reusability, performance, and maintainability of the training operators.'}, {'timestamp': (489.0, 494.0), 'text': ' The most important change is we released a stable Kubeflow common library.'}, {'timestamp': (494.0, 497.0), 'text': ' So some users may not have contacts of this library.'}, {'timestamp': (497.0, 505.84), 'text': ' As we know, Kubeflow has many distributed training operators and most of them have similar designs and implementations.'}, {'timestamp': (506.4, 513.76), 'text': ' So in mid 2019 we started Coolflow Common Projects, aims to extract those common reconciler'}, {'timestamp': (513.76, 519.92), 'text': ' logics and CRD types to make sure they can be reused in different training operators.'}, {'timestamp': (520.72, 529.0), 'text': ' Ideally we can add like generic logics and bug fixes in the Coolflow Common project.'}, {'timestamp': (529.0, 537.0), 'text': ' Different operators just need to upgrade common dependencies to leverage these benefits and new changes.'}, {'timestamp': (537.0, 545.4), 'text': ' In the latest stable version, it starts to support Volcano Batch Scheder, which is the main down'}, {'timestamp': (545.4, 547.28), 'text': ' scheduler offering in the community.'}, {'timestamp': (547.8, 552.56), 'text': ' It also provides the flexible interface to support like both'}, {'timestamp': (552.56, 555.44), 'text': ' informer and computer based operators.'}, {'timestamp': (556.12, 559.36), 'text': ' The app grades the dependency versions like Kubernetes,'}, {'timestamp': (559.56, 564.28), 'text': ' controller runtime, controller tools and refactor the codes to'}, {'timestamp': (564.28, 566.16), 'text': ' enhance the maintainability.'}, {'timestamp': (566.56, 570.92), 'text': ' So one last important feature is like common controller reconciles the'}, {'timestamp': (570.92, 575.36), 'text': ' workers scale down events to support dynamic or elastic training.'}, {'timestamp': (575.68, 579.6), 'text': ' So that means the number of the workers can be changed during the training.'}, {'timestamp': (579.96, 583.52), 'text': ' If the framework has the support like a torch elastic.'}, {'timestamp': (584.58, 588.64), 'text': ' if the framework has the support like torch elastic. Currently we have migrated TensorFlow, MXNet,'}, {'timestamp': (588.64, 592.14), 'text': ' XGBoost implementations to this fashion'}, {'timestamp': (592.14, 594.76), 'text': ' and PyTorch is in progress.'}, {'timestamp': (594.76, 598.12), 'text': ' The major user facing changes are MXNet,'}, {'timestamp': (598.12, 603.12), 'text': ' XGBoost and MPI operators both support V1 APIs.'}, {'timestamp': (603.46, 607.76), 'text': ' Most of the work to graduate to V1 has been done.'}, {'timestamp': (607.76, 610.52), 'text': \" However, we haven't officially claimed there are V1\"}, {'timestamp': (610.52, 614.48), 'text': ' because we want to do more scale and performance testing.'}, {'timestamp': (614.48, 619.1), 'text': ' User can use V1 API now and report issues to us.'}, {'timestamp': (620.44, 623.08), 'text': ' We have a few features and improvement plans'}, {'timestamp': (623.08, 624.72), 'text': ' in the roadmap doc.'}, {'timestamp': (624.72, 626.14), 'text': ' So feel free to take a look'}, {'timestamp': (626.3, 630.8), 'text': \" Yeah, that's all the updates from training operator side. Thank you\"}, {'timestamp': (631.86, 635.02), 'text': ' And now for the multi-user pipeline update'}, {'timestamp': (636.98, 638.86), 'text': ' Thank You Josh'}, {'timestamp': (638.86, 640.86), 'text': ' for cute little pipelines'}, {'timestamp': (641.14, 646.0), 'text': ' Now in cute for one point one, the most important thing is that'}, {'timestamp': (646.0, 653.0), 'text': \" Pipelines is now reaching 1.0 release, so it's becoming another stable component in Kubeflow.\"}, {'timestamp': (653.0, 661.0), 'text': ' The biggest feature in this release is multi-user support in Kubeflow Pipelines'}, {'timestamp': (661.0, 671.84), 'text': ' without needing to run multiple deployments. So basically, Kubeflow pipelines resources are separated by namespace, or also called'}, {'timestamp': (671.84, 674.16), 'text': ' profile in Kubeflow.'}, {'timestamp': (674.16, 687.84), 'text': ' And you can go to the UI and select the namespace selector to only view resources in your namespace. Also the pipelines run in user namespaces so you can'}, {'timestamp': (689.28, 697.6), 'text': ' separate extra resources like secrets or config maps or whatever you like when integrating with'}, {'timestamp': (697.6, 706.72), 'text': ' Qubeflow pipelines. Other benefits also important are like support an easier upgrade in Kubeflow.'}, {'timestamp': (708.16, 716.8), 'text': ' And we have brought new features like caching and artifact lineage auto tracking that are coming in'}, {'timestamp': (716.8, 725.94), 'text': ' this release. And do not forget that in 1.0 release, we have been doing a lot of bug fixes.'}, {'timestamp': (725.94, 735.08), 'text': ' We have improved usability and performance significantly that I hope will make the user'}, {'timestamp': (735.08, 738.22), 'text': ' experience more smoothly.'}, {'timestamp': (738.22, 740.12), 'text': ' And below are some references.'}, {'timestamp': (740.12, 742.4), 'text': ' You can get more information about this.'}, {'timestamp': (742.4, 744.26), 'text': \" I'll hand back to you, Josh.\"}, {'timestamp': (744.26, 746.08), 'text': ' Thank you. Thank you, Josh. Thank you.'}, {'timestamp': (746.92, 749.16), 'text': ' Thank you, Yuan. And I know that many people have been looking'}, {'timestamp': (749.16, 754.16), 'text': ' for the QPo pipelines, 1.0 and stable version.'}, {'timestamp': (754.8, 756.14), 'text': ' So great delivery here.'}, {'timestamp': (756.14, 758.2), 'text': ' Thank you very much for your work'}, {'timestamp': (758.2, 760.02), 'text': \" and for your team's work on this.\"}, {'timestamp': (761.2, 765.0), 'text': ' And now we hand off to Andre to give an update on Katib.'}, {'timestamp': (765.0, 774.0), 'text': \" Hi everyone. Today I'm just going to show you some quick updates for Katib, what we bring for 1.1 Kubeflow.\"}, {'timestamp': (774.0, 785.04), 'text': ' And for 1.1 Katib is still with an alpha 3.0 release, but we just bring some new features. And especially one of the main'}, {'timestamp': (789.84, 790.4), 'text': ' feature was integrating new frameworks, especially GOP tuna'}, {'timestamp': (793.6, 797.68), 'text': ' and we integrating the new high primary tunic algorithm called covariance matrix adaptation and evulsion strategy. And to'}, {'timestamp': (797.68, 800.16), 'text': ' continue integrating with neural architecture search'}, {'timestamp': (800.16, 803.84), 'text': ' algorithm, we integrated darts. This is like very common'}, {'timestamp': (803.84, 805.76), 'text': ' algorithm and should be very useful'}, {'timestamp': (806.48, 813.36), 'text': ' to use in KDIP. Also we tried to support other frameworks like Chocolate Hyperop and SQOP to'}, {'timestamp': (813.36, 825.3), 'text': ' bring more stability and usability for end user. And one of the main feature was integrating new Python SDK to'}, {'timestamp': (828.7, 829.6), 'text': ' to integrate KDP in notebooks, Kubeflow notebooks and run it'}, {'timestamp': (831.6, 832.54), 'text': ' very smoothly. Also,'}, {'timestamp': (836.34, 837.1), 'text': \" we're improving UI with new trial template editor and\"}, {'timestamp': (841.68, 842.32), 'text': ' right now users can run experiment without the goal. So it should be useful when you have'}, {'timestamp': (844.76, 852.8), 'text': ' when you want to run an experiment for a long time. And also, we integrate the resume policies, when you just easily can clean up your resources after the experiment is finished.'}, {'timestamp': (856.8, 864.8), 'text': ' Yeah, I think this is like the main features that we bring for 1.1, and also we try to make it stable for the future releases.'}, {'timestamp': (864.8, 865.2), 'text': \" Alright, now we'll hand off to make it stable for the future releases.\"}, {'timestamp': (865.2, 870.28), 'text': \" All right, now we'll hand off to Jeff to talk about CVE scanning.\"}, {'timestamp': (870.28, 871.16), 'text': ' Thanks.'}, {'timestamp': (871.16, 877.12), 'text': ' So the goal here was to mitigate some of the critical common'}, {'timestamp': (877.12, 882.08), 'text': ' vulnerabilities that we find when we scan Docker images.'}, {'timestamp': (882.08, 885.44), 'text': \" And the project's been going on, well, this process has been going on quite a while,\"}, {'timestamp': (885.44, 890.96), 'text': \" and with the creation of the new working groups, we're hoping, I'm hoping to get this\"}, {'timestamp': (891.52, 897.28), 'text': \" part of the working group process. But we've had some success with mitigating.\"}, {'timestamp': (898.8, 911.12), 'text': \" There's still a few outgoing. But more to come in the next releases. Now we get to hand it off to Animesh.\"}, {'timestamp': (911.12, 917.72), 'text': \" This is Animesh and thanks for being here. So we're going to talk in terms of\"}, {'timestamp': (917.72, 922.28), 'text': ' you know the enhancements we made to KFServing. Essentially the focus in this'}, {'timestamp': (922.28, 928.0), 'text': ' release was on stability and many features were added around that.'}, {'timestamp': (928.0, 933.0), 'text': ' But beyond stability, one of the key requirements we had around adding GPU support for PyTorch,'}, {'timestamp': (933.0, 935.0), 'text': ' model servers which was added,'}, {'timestamp': (935.0, 940.0), 'text': ' adding a Pickle format support for Scikit-learn model which was added.'}, {'timestamp': (940.0, 944.0), 'text': ' And in terms of the stability, one of the major moves which we did was'}, {'timestamp': (944.0, 948.86), 'text': ' upgrading from Knative APIs from V1 Alpha 1 to V1.'}, {'timestamp': (948.86, 954.28), 'text': ' And that also entailed in turn upgrading some of the Kubernetes dependencies to 1.15 and'}, {'timestamp': (954.28, 957.32), 'text': ' Knative dependencies to 1.11.'}, {'timestamp': (957.32, 961.32), 'text': ' That brought a lot of the features which have been made available in Knative vis-a-vis the'}, {'timestamp': (961.32, 962.32), 'text': ' stability.'}, {'timestamp': (962.32, 965.68), 'text': ' There are more enhancements which we added around'}, {'timestamp': (967.04, 973.6), 'text': ' routing. So for example, supporting internal mesh routing to inference service. So for example,'}, {'timestamp': (973.6, 980.24), 'text': ' you can route from a Kafka based event source using this mechanism. Other things were added'}, {'timestamp': (980.24, 986.4), 'text': ' around a parallelism field to allow setting auto-scaling target concurrency.'}, {'timestamp': (991.84, 998.88), 'text': ' Last but not the least, we also made the default for min replicas to one instead of zero. We have heard time and again from the community in terms of having a default scale back default to set to'}, {'timestamp': (998.88, 1004.32), 'text': ' one because in that case you take advantage of some of the delays which happen if you have'}, {'timestamp': (1004.32, 1008.88), 'text': ' defaulted back to zero. We are pretty know as Knative improves that feature will be improved'}, {'timestamp': (1009.68, 1016.16), 'text': ' to a core start from zero onwards. In addition there are quite a bit of you know talks'}, {'timestamp': (1017.84, 1028.7), 'text': \" we have compiled from different conferences which have been uploaded on the KF Serving community page, where it's either the contributors to KF Serving,\"}, {'timestamp': (1028.84, 1030.42), 'text': ' as well as the users of KF Serving,'}, {'timestamp': (1030.42, 1033.12), 'text': ' talking about the technical details,'}, {'timestamp': (1033.12, 1035.48), 'text': ' as well as their usage infrastructure.'}, {'timestamp': (1035.48, 1037.44), 'text': ' There is also a page which we have compiled,'}, {'timestamp': (1037.44, 1038.54), 'text': ' which actually goes,'}, {'timestamp': (1039.78, 1044.42), 'text': ' analysts all the different users of KF Serving,'}, {'timestamp': (1044.42, 1045.32), 'text': ' who are either'}, {'timestamp': (1045.32, 1049.52), 'text': ' running KFServing in production or providing KFServing support'}, {'timestamp': (1049.52, 1053.72), 'text': ' on their cloud platform or redistributing KFServing.'}, {'timestamp': (1053.72, 1056.08), 'text': \" So if you go, you'll see a pretty comprehensive list\"}, {'timestamp': (1056.08, 1061.2), 'text': ' at this point where we have 10 to 11 different adopters who'}, {'timestamp': (1061.2, 1064.88), 'text': ' are leveraging KFServing for their own needs.'}, {'timestamp': (1064.88, 1066.96), 'text': ' Thanks. With that, I will pass on to Igor.'}, {'timestamp': (1068.64, 1069.56), 'text': ' Hi everyone.'}, {'timestamp': (1070.42, 1073.88), 'text': ' In this version, we have made some significant improvements'}, {'timestamp': (1073.88, 1076.92), 'text': ' to GitOps processes for Kubeflow.'}, {'timestamp': (1076.92, 1081.5), 'text': ' Our goal is to simplify Kubeflow stack installation'}, {'timestamp': (1081.5, 1085.32), 'text': ' and configuration and management and eventually upgrades.'}, {'timestamp': (1085.32, 1090.88), 'text': ' So at the core of GitOps processes is Git repository,'}, {'timestamp': (1090.88, 1105.0), 'text': ' which is used as the central source of truth for all Kubeflow deployments for all environments. With GitOps, you can now commit all infrastructure'}, {'timestamp': (1107.4, 1111.56), 'text': ' as code scripts into Git,'}, {'timestamp': (1111.56, 1115.32), 'text': ' and then run installs and configurations'}, {'timestamp': (1115.32, 1117.34), 'text': ' from this Git repository.'}, {'timestamp': (1118.64, 1122.76), 'text': ' With Git, you will achieve a lot better automation'}, {'timestamp': (1122.76, 1128.72), 'text': ' and also auditing and debugging of all Kubeflow environments.'}, {'timestamp': (1128.72, 1134.32), 'text': ' And there are several GitOps projects that we would encourage you to take a look at.'}, {'timestamp': (1135.28, 1145.0), 'text': ' Here you will find a link to Erectus example of GitOps processes and a link to AgileStacks example of GitOps processes'}, {'timestamp': (1146.56, 1149.98), 'text': ' to install, deploy and manage Kubeflow.'}, {'timestamp': (1151.84, 1154.52), 'text': ' I will turn it over back to Josh.'}, {'timestamp': (1156.4, 1157.24), 'text': ' Thanks Igor.'}, {'timestamp': (1157.24, 1161.08), 'text': ' And now we will talk about some ecosystem enhancements'}, {'timestamp': (1161.08, 1163.24), 'text': ' and hand off to Clive from Seldon.'}, {'timestamp': (1165.0, 1167.0), 'text': \" Hi, thanks Josh. So I'm Clive, I'm CTO of Selden.\"}, {'timestamp': (1168.0, 1171.0), 'text': ' Selden is pleased to be part of the Kubeflow 1.1 release.'}, {'timestamp': (1172.0, 1175.0), 'text': ' So Selden is there for production ready, highly scalable inference'}, {'timestamp': (1176.0, 1178.0), 'text': ' alongside our work on the KFSR project for serverless deployment.'}, {'timestamp': (1179.0, 1182.0), 'text': ' In 1.2.1 of Selden, which comes in this release, we have new'}, {'timestamp': (1183.0, 1189.28), 'text': ' Go language service orchestrator, which is protocol agnosticostic which means we can now support Seldom and TensorFlow protocols and further'}, {'timestamp': (1189.28, 1193.76), 'text': ' protocols in the future. I mean as usual Seldom allows you to build powerful inference graphs'}, {'timestamp': (1193.76, 1200.24), 'text': \" made up of models routers ensemble and many after the box optimized model servers. We've also added\"}, {'timestamp': (1200.24, 1204.72), 'text': ' Qflow pipeline examples to show you how you can train and deploy models onto Seldom core and add'}, {'timestamp': (1204.72, 1208.12), 'text': ' key components such as state- the art outline detection drift detection.'}, {'timestamp': (1208.52, 1214.48), 'text': \" And model explanation components using Seldom's open source Adoai explain Adoai detect projects and you can find a link to those\"}, {'timestamp': (1215.16, 1224.2), 'text': \" Examples on this slide. So yeah, so in general, we're looking forward to getting your feedback and further integrating with Qflow in the future. So thanks and back to Josh.\"}, {'timestamp': (1222.16, 1224.4), 'text': ' further integrating with Kubeflow in the future. So thanks and back to Josh.'}, {'timestamp': (1225.28, 1226.72), 'text': ' Okay, well, thank you, Clive.'}, {'timestamp': (1226.72, 1230.26), 'text': \" And now we'll move on to another ecosystem enhancement\"}, {'timestamp': (1230.26, 1233.38), 'text': ' from the Feast community and off to Willem.'}, {'timestamp': (1234.44, 1235.64), 'text': ' Thanks Josh.'}, {'timestamp': (1235.64, 1238.56), 'text': ' This is Willem from the Feast community.'}, {'timestamp': (1238.56, 1241.44), 'text': \" So I'm excited to talk a bit about Feast 0.6\"}, {'timestamp': (1241.44, 1243.42), 'text': ' and what that means for Kubeflow.'}, {'timestamp': (1243.42, 1246.4), 'text': \" So with Kubeflow 1.1, it's a first step towards integrating Feast 0.6 and what that means for Kubeflow. So with Kubeflow 1.1, it's a first step towards\"}, {'timestamp': (1246.4, 1252.8), 'text': \" integrating Feast as a top-level component into Kubeflow. So for this release, we've extended the\"}, {'timestamp': (1252.8, 1258.48), 'text': ' Kubeflow documentation to include both the motivation for why you would want to use Feast,'}, {'timestamp': (1258.48, 1265.28), 'text': ' a feature store for machine learning in your use cases or for your use cases and how you can get started.'}, {'timestamp': (1265.64, 1270.76), 'text': \" So we've also included some guides on installing Feast alongside\"}, {'timestamp': (1270.76, 1275.92), 'text': ' Kubeflow, as well as tutorials and examples that show users how they can do that.'}, {'timestamp': (1276.2, 1280.96), 'text': ' So Feast is a system that essentially abstracts away your data modeling'}, {'timestamp': (1281.24, 1285.92), 'text': ' and your data engineering from your ML and operational requirements like model'}, {'timestamp': (1285.92, 1291.84), 'text': ' training and model serving. It manages ingestion jobs and the persistence of data. It allows teams'}, {'timestamp': (1291.84, 1299.04), 'text': ' to define and track features and reuse features. And it also provides a point in time correct view'}, {'timestamp': (1300.48, 1310.48), 'text': ' for retrieval of feature data for training and for serving. The latest Feast release, v0.6, also includes statistic generation and validation that'}, {'timestamp': (1310.48, 1315.6), 'text': ' ensures that your production system stays safe. For Kubeflow 1.2 and new releases,'}, {'timestamp': (1315.6, 1321.28), 'text': \" we're planning to also include or further integrate and potentially even deploy Feast\"}, {'timestamp': (1321.28, 1325.68), 'text': \" alongside Kubeflow. So we're excited to be working with the Kubeflow community on that.\"}, {'timestamp': (1326.72, 1329.04), 'text': \" That's it from my side. Back to you, Josh.\"}, {'timestamp': (1330.0, 1331.92), 'text': ' Thank you very much and a great update.'}, {'timestamp': (1332.48, 1336.48), 'text': ' And now on to simplifying blog posts with Hamil.'}, {'timestamp': (1336.48, 1338.88), 'text': ' Hamil, can you give us an update on your work here?'}, {'timestamp': (1340.16, 1347.72), 'text': ' Yeah, sure. So we now have a blog system that you can see on this'}, {'timestamp': (1347.72, 1356.56), 'text': ' GitHub repo, kuflow.blog. So the reason why we have instituted this'}, {'timestamp': (1356.56, 1363.6), 'text': ' alternative blogging system is to allow a process to happen with regards to'}, {'timestamp': (1363.6, 1368.56), 'text': ' reviewing blog posts and discussing blog posts because'}, {'timestamp': (1368.56, 1376.96), 'text': ' with Medium before it was really difficult to have a transparent process of review and'}, {'timestamp': (1376.96, 1388.16), 'text': ' the community really wanted something that looked a lot like a pull request where somebody write something and then people can comment on it and then propose'}, {'timestamp': (1388.16, 1396.0), 'text': ' or make suggestions and then it can go through some kind of formal review and then get merged.'}, {'timestamp': (1396.0, 1401.16), 'text': ' And so a question came up is whether something like that can be done with blogs.'}, {'timestamp': (1401.16, 1405.48), 'text': ' So it turns out that the Fast.ai community has'}, {'timestamp': (1405.48, 1412.32), 'text': \" something called Fast Pages. I'm the maintainer of that project and what that\"}, {'timestamp': (1412.32, 1418.28), 'text': \" project is, is it's a way where you can write blog posts with Jupyter notebooks\"}, {'timestamp': (1418.28, 1424.12), 'text': ' or Markdown and the purpose of that project is to make it really easy to'}, {'timestamp': (1424.12, 1427.0), 'text': ' write blog posts with Jupyter notebooks.'}, {'timestamp': (1427.0, 1431.0), 'text': ' Sort of before that, it was kind of difficult to write blog posts with Jupyter.'}, {'timestamp': (1431.0, 1440.0), 'text': ' You have to kind of prepare your notebook and then do a bunch of conversion scripts to kind of convert the notebook to HTML'}, {'timestamp': (1440.0, 1443.0), 'text': ' and then do all kinds of other stuff to make it suitable for a blog.'}, {'timestamp': (1443.0, 1448.0), 'text': ' And it was actually really complicated. So FastPages automates all of that.'}, {'timestamp': (1448.0, 1456.0), 'text': ' You save your notebook into a folder and then GitHub actions runs those conversion scripts for you,'}, {'timestamp': (1456.0, 1463.0), 'text': \" converts that to HTML, and then that's available as a blog post.\"}, {'timestamp': (1463.0, 1467.44), 'text': \" And so one thing that you should know is there's a lot of configuration options\"}, {'timestamp': (1467.44, 1470.88), 'text': \" and there's a lot of ways you can customize it.\"}, {'timestamp': (1471.04, 1473.84), 'text': \" And there's a lot of ways you can even customize a blog post itself,\"}, {'timestamp': (1475.0, 1477.4), 'text': ' especially the formatting and stuff like that.'}, {'timestamp': (1477.4, 1480.16), 'text': \" There's a fairly lengthy read me\"}, {'timestamp': (1480.68, 1485.76), 'text': ' that I encourage everybody to read if you are going to write a blog post. So'}, {'timestamp': (1485.76, 1491.12), 'text': \" if you go to the fast pages repo which is linked here on the slide, there's a\"}, {'timestamp': (1491.12, 1496.56), 'text': ' really big kind of like instruction manual on you know how to do things like'}, {'timestamp': (1496.56, 1503.94), 'text': ' you know embed images or tweak your social cards on your blog post or to'}, {'timestamp': (1503.94, 1506.56), 'text': ' enable comments if you want'}, {'timestamp': (1506.56, 1511.08), 'text': \" people to be able to make comments. So there's a commenting system that is\"}, {'timestamp': (1511.08, 1515.16), 'text': ' hooked in with GitHub issues so when people comment on your blog post it'}, {'timestamp': (1515.16, 1518.04), 'text': \" actually opens a GitHub issue on the blog website so it's actually pretty\"}, {'timestamp': (1518.04, 1528.16), 'text': \" convenient. And there's a lot of other cool stuff like the ability to have collapsible code cells and then you can put\"}, {'timestamp': (1529.2, 1535.84), 'text': \" images, GIFs with captions and all kinds of stuff. It's very rich. It's actually been used a lot in\"}, {'timestamp': (1535.84, 1547.28), 'text': ' the data science community and especially the Fast.ai community. We have a couple of blog posts, I think, that have launched recently from the Kubeflow community on this site.'}, {'timestamp': (1547.96, 1554.36), 'text': \" So I think, you know, I encourage everybody to check it out, and especially if you're interested in writing a blog post.\"}, {'timestamp': (1555.4, 1556.32), 'text': \" I'll give it back to you, Josh.\"}, {'timestamp': (1557.08, 1559.52), 'text': ' Hey, Hamill, thanks for all your work there.'}, {'timestamp': (1559.56, 1567.0), 'text': ' This is something critical to the growth of the community, especially in the need for us to let people know'}, {'timestamp': (1567.0, 1569.16), 'text': \" all the great work they're doing,\"}, {'timestamp': (1569.16, 1571.64), 'text': ' whether it be an article or a blog post,'}, {'timestamp': (1571.64, 1576.1), 'text': ' or even better yet, a tutorial with those notebooks in there.'}, {'timestamp': (1576.1, 1578.88), 'text': ' This is great work and we really do appreciate it.'}, {'timestamp': (1578.88, 1581.64), 'text': \" Okay, so we've covered a lot,\"}, {'timestamp': (1581.64, 1586.48), 'text': \" and now we're gonna talk about how how to get involved and especially since we've\"}, {'timestamp': (1588.88, 1597.68), 'text': ' confirmed or approved a proposal for the Kubeflow working groups. We really look forward to and encourage people to'}, {'timestamp': (1598.24, 1607.92), 'text': ' either join a working group or start one as either a team lead, a chair or a participating member.'}, {'timestamp': (1607.92, 1613.2), 'text': ' And for all of those folks that are just getting started in Kubeflow, remember we do have the'}, {'timestamp': (1613.2, 1620.04), 'text': ' Kubeflow Slack channel, the Kubeflow discuss mailing list, as well as the community meetings'}, {'timestamp': (1620.04, 1622.12), 'text': ' every Tuesday.'}, {'timestamp': (1622.12, 1627.44), 'text': ' You can see all the deliveries in Kubeflow in GitHub and we really look forward'}, {'timestamp': (1627.44, 1634.4), 'text': ' to your success with Kubeflow 1.1. And with that I would just like to make sure that as you look'}, {'timestamp': (1634.4, 1639.92), 'text': ' to join the Kubeflow community you can see on this list all the folks that have contributed'}, {'timestamp': (1639.92, 1649.14), 'text': ' in this release. There are many others but these are the ones that were primarily to this. And you can see many of this top market leaders,'}, {'timestamp': (1649.14, 1654.14), 'text': ' whether it be Ant or Bloomberg and Cisco, Google,'}, {'timestamp': (1654.38, 1659.1), 'text': ' Seldin, GitHub, Eriktto and Amazon.'}, {'timestamp': (1659.1, 1661.34), 'text': ' So I think this is a great group of folks'}, {'timestamp': (1661.34, 1664.42), 'text': ' and we really do encourage you to get involved'}, {'timestamp': (1664.42, 1666.32), 'text': ' and participate either as a'}, {'timestamp': (1666.32, 1671.36), 'text': ' contributor or user and we really do appreciate your feedback and work in the Kubeflow community.'}, {'timestamp': (1671.36, 1675.92), 'text': ' Thanks again we look forward to your questions and supporting your your work on 1.1.'}]\n"
     ]
    }
   ],
   "source": [
    "text_with_timestamps = pipe(\"audio.mp3\", return_timestamps=True)[\"chunks\"]\n",
    "print(text_with_timestamps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
