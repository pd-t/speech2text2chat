{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "339c32cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/ytdl-org/youtube-dl.git@master\n",
      "  Cloning https://github.com/ytdl-org/youtube-dl.git (to revision master) to /tmp/pip-req-build-_584no4v\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/ytdl-org/youtube-dl.git /tmp/pip-req-build-_584no4v\n",
      "  Resolved https://github.com/ytdl-org/youtube-dl.git to commit 6fece0a96b3cd8677f5c1185a57c6e21403fcb44\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install 'git+https://github.com/ytdl-org/youtube-dl.git@master'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b802de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
      "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu bionic InRelease                        \n",
      "Hit:5 http://archive.ubuntu.com/ubuntu bionic-updates InRelease                \n",
      "Hit:6 http://archive.ubuntu.com/ubuntu bionic-backports InRelease       \n",
      "Get:3 https://packages.cloud.google.com/apt kubernetes-xenial InRelease [8993 B]\n",
      "Err:3 https://packages.cloud.google.com/apt kubernetes-xenial InRelease\n",
      "  The following signatures couldn't be verified because the public key is not available: NO_PUBKEY B53DC80D13EDEF05\n",
      "Fetched 8993 B in 1s (11.1 kB/s)\n",
      "Reading package lists... Done\n",
      "W: An error occurred during the signature verification. The repository is not updated and the previous index files will be used. GPG error: https://packages.cloud.google.com/apt kubernetes-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY B53DC80D13EDEF05\n",
      "W: Failed to fetch http://apt.kubernetes.io/dists/kubernetes-xenial/InRelease  The following signatures couldn't be verified because the public key is not available: NO_PUBKEY B53DC80D13EDEF05\n",
      "W: Some index files failed to download. They have been ignored, or old ones used instead.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  dbus fontconfig fontconfig-config fonts-dejavu-core i965-va-driver libaacs0\n",
      "  libapparmor1 libasound2 libasound2-data libass9 libasyncns0 libavc1394-0\n",
      "  libavcodec57 libavdevice57 libavfilter6 libavformat57 libavresample3\n",
      "  libavutil55 libbdplus0 libbluray2 libbs2b0 libcaca0 libcairo2 libcdio-cdda2\n",
      "  libcdio-paranoia2 libcdio17 libchromaprint1 libcroco3 libcrystalhd3\n",
      "  libdatrie1 libdbus-1-3 libdc1394-22 libdrm-amdgpu1 libdrm-common\n",
      "  libdrm-intel1 libdrm-nouveau2 libdrm-radeon1 libdrm2 libegl-mesa0 libegl1\n",
      "  libelf1 libfftw3-double3 libflite1 libfontconfig1 libfreetype6 libfribidi0\n",
      "  libgbm1 libgdk-pixbuf2.0-0 libgdk-pixbuf2.0-bin libgdk-pixbuf2.0-common\n",
      "  libgl1 libgl1-mesa-dri libglapi-mesa libglib2.0-0 libglib2.0-data libglvnd0\n",
      "  libglx-mesa0 libglx0 libgme0 libgraphite2-3 libgsm1 libharfbuzz0b\n",
      "  libiec61883-0 libjack-jackd2-0 libjbig0 libjpeg-turbo8 libjpeg8 libllvm10\n",
      "  libmp3lame0 libmpg123-0 libmysofa0 libnorm1 libnuma1 libopenal-data\n",
      "  libopenal1 libopenjp2-7 libopenmpt0 libopus0 libpango-1.0-0\n",
      "  libpangocairo-1.0-0 libpangoft2-1.0-0 libpciaccess0 libpgm-5.2-0\n",
      "  libpixman-1-0 libpng16-16 libpostproc54 libpulse0 libraw1394-11 librsvg2-2\n",
      "  librsvg2-common librubberband2 libsamplerate0 libsdl2-2.0-0 libsensors4\n",
      "  libshine3 libslang2 libsnappy1v5 libsndio6.1 libsodium23 libsoxr0 libspeex1\n",
      "  libssh-gcrypt-4 libswresample2 libswscale4 libthai-data libthai0 libtheora0\n",
      "  libtiff5 libtwolame0 libusb-1.0-0 libva-drm2 libva-x11-2 libva2 libvdpau1\n",
      "  libvorbisfile3 libvpx5 libwavpack1 libwayland-client0 libwayland-cursor0\n",
      "  libwayland-egl1 libwayland-egl1-mesa libwayland-server0 libwebp6 libwebpmux3\n",
      "  libwrap0 libx11-xcb1 libx264-152 libx265-146 libxcb-dri2-0 libxcb-dri3-0\n",
      "  libxcb-glx0 libxcb-present0 libxcb-render0 libxcb-shape0 libxcb-shm0\n",
      "  libxcb-sync1 libxcb-xfixes0 libxcursor1 libxdamage1 libxfixes3 libxi6\n",
      "  libxinerama1 libxkbcommon0 libxrandr2 libxrender1 libxshmfence1 libxss1\n",
      "  libxv1 libxvidcore4 libxxf86vm1 libzmq5 libzvbi-common libzvbi0\n",
      "  mesa-va-drivers mesa-vdpau-drivers shared-mime-info ucf va-driver-all\n",
      "  vdpau-driver-all x11-common xdg-user-dirs xkb-data\n",
      "Suggested packages:\n",
      "  default-dbus-session-bus | dbus-session-bus ffmpeg-doc\n",
      "  i965-va-driver-shaders libasound2-plugins alsa-utils libbluray-bdj\n",
      "  firmware-crystalhd libfftw3-bin libfftw3-dev jackd2 libportaudio2 opus-tools\n",
      "  pciutils pulseaudio libraw1394-doc librsvg2-bin lm-sensors sndiod speex\n",
      "  libvdpau-va-gl1 nvidia-vdpau-driver nvidia-legacy-340xx-vdpau-driver\n",
      "The following NEW packages will be installed:\n",
      "  dbus ffmpeg fontconfig fontconfig-config fonts-dejavu-core i965-va-driver\n",
      "  libaacs0 libapparmor1 libasound2 libasound2-data libass9 libasyncns0\n",
      "  libavc1394-0 libavcodec57 libavdevice57 libavfilter6 libavformat57\n",
      "  libavresample3 libavutil55 libbdplus0 libbluray2 libbs2b0 libcaca0 libcairo2\n",
      "  libcdio-cdda2 libcdio-paranoia2 libcdio17 libchromaprint1 libcroco3\n",
      "  libcrystalhd3 libdatrie1 libdbus-1-3 libdc1394-22 libdrm-amdgpu1\n",
      "  libdrm-common libdrm-intel1 libdrm-nouveau2 libdrm-radeon1 libdrm2\n",
      "  libegl-mesa0 libegl1 libelf1 libfftw3-double3 libflite1 libfontconfig1\n",
      "  libfreetype6 libfribidi0 libgbm1 libgdk-pixbuf2.0-0 libgdk-pixbuf2.0-bin\n",
      "  libgdk-pixbuf2.0-common libgl1 libgl1-mesa-dri libglapi-mesa libglib2.0-0\n",
      "  libglib2.0-data libglvnd0 libglx-mesa0 libglx0 libgme0 libgraphite2-3\n",
      "  libgsm1 libharfbuzz0b libiec61883-0 libjack-jackd2-0 libjbig0 libjpeg-turbo8\n",
      "  libjpeg8 libllvm10 libmp3lame0 libmpg123-0 libmysofa0 libnorm1 libnuma1\n",
      "  libopenal-data libopenal1 libopenjp2-7 libopenmpt0 libopus0 libpango-1.0-0\n",
      "  libpangocairo-1.0-0 libpangoft2-1.0-0 libpciaccess0 libpgm-5.2-0\n",
      "  libpixman-1-0 libpng16-16 libpostproc54 libpulse0 libraw1394-11 librsvg2-2\n",
      "  librsvg2-common librubberband2 libsamplerate0 libsdl2-2.0-0 libsensors4\n",
      "  libshine3 libslang2 libsnappy1v5 libsndio6.1 libsodium23 libsoxr0 libspeex1\n",
      "  libssh-gcrypt-4 libswresample2 libswscale4 libthai-data libthai0 libtheora0\n",
      "  libtiff5 libtwolame0 libusb-1.0-0 libva-drm2 libva-x11-2 libva2 libvdpau1\n",
      "  libvorbisfile3 libvpx5 libwavpack1 libwayland-client0 libwayland-cursor0\n",
      "  libwayland-egl1 libwayland-egl1-mesa libwayland-server0 libwebp6 libwebpmux3\n",
      "  libwrap0 libx11-xcb1 libx264-152 libx265-146 libxcb-dri2-0 libxcb-dri3-0\n",
      "  libxcb-glx0 libxcb-present0 libxcb-render0 libxcb-shape0 libxcb-shm0\n",
      "  libxcb-sync1 libxcb-xfixes0 libxcursor1 libxdamage1 libxfixes3 libxi6\n",
      "  libxinerama1 libxkbcommon0 libxrandr2 libxrender1 libxshmfence1 libxss1\n",
      "  libxv1 libxvidcore4 libxxf86vm1 libzmq5 libzvbi-common libzvbi0\n",
      "  mesa-va-drivers mesa-vdpau-drivers shared-mime-info ucf va-driver-all\n",
      "  vdpau-driver-all x11-common xdg-user-dirs xkb-data\n",
      "0 upgraded, 163 newly installed, 0 to remove and 65 not upgraded.\n",
      "Need to get 70.3 MB of archives.\n",
      "After this operation, 519 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpng16-16 amd64 1.6.34-1ubuntu0.18.04.2 [176 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libfreetype6 amd64 2.8.1-2ubuntu2.2 [335 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 ucf all 3.0038 [50.5 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-core all 2.37-1 [1041 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 fontconfig-config all 2.12.6-0ubuntu2 [55.8 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfontconfig1 amd64 2.12.6-0ubuntu2 [137 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 fontconfig amd64 2.12.6-0ubuntu2 [169 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libjpeg-turbo8 amd64 1.5.2-0ubuntu5.18.04.6 [111 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxinerama1 amd64 2:1.1.3-1 [7908 B]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 x11-common all 1:7.7+19ubuntu7.1 [22.5 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxss1 amd64 1:1.2.2-1 [8582 B]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxxf86vm1 amd64 1:1.1.4-1 [10.6 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libapparmor1 amd64 2.12-4ubuntu5.1 [31.3 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libdbus-1-3 amd64 1.12.2-1ubuntu1.4 [175 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 dbus amd64 1.12.2-1ubuntu1.4 [150 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libelf1 amd64 0.170-0.4ubuntu0.1 [44.8 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libfribidi0 amd64 0.19.7-2ubuntu0.1 [25.2 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libglib2.0-0 amd64 2.56.4-0ubuntu0.18.04.9 [1169 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libglib2.0-data all 2.56.4-0ubuntu0.18.04.9 [4728 B]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 libslang2 amd64 2.3.1a-3ubuntu1 [424 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu bionic/main amd64 shared-mime-info amd64 1.9-2 [426 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu bionic/main amd64 xdg-user-dirs amd64 0.17-1ubuntu1 [48.0 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 xkb-data all 2.23.1-1ubuntu1.18.04.1 [325 kB]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libdrm-common all 2.4.101-2~18.04.1 [5560 B]\n",
      "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libdrm2 amd64 2.4.101-2~18.04.1 [32.3 kB]\n",
      "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libnuma1 amd64 2.0.11-2.1ubuntu0.1 [22.0 kB]\n",
      "Get:27 http://archive.ubuntu.com/ubuntu bionic/main amd64 libusb-1.0-0 amd64 2:1.0.21-2 [43.3 kB]\n",
      "Get:28 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libva2 amd64 2.1.0-3 [47.6 kB]\n",
      "Get:29 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libva-drm2 amd64 2.1.0-3 [6880 B]\n",
      "Get:30 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxfixes3 amd64 1:5.0.3-1 [10.8 kB]\n",
      "Get:31 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libva-x11-2 amd64 2.1.0-3 [11.5 kB]\n",
      "Get:32 http://archive.ubuntu.com/ubuntu bionic/main amd64 libvdpau1 amd64 1.1.1-3ubuntu1 [25.5 kB]\n",
      "Get:33 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libavutil55 amd64 7:3.4.11-0ubuntu0.1 [191 kB]\n",
      "Get:34 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpixman-1-0 amd64 0.34.0-2ubuntu0.1 [229 kB]\n",
      "Get:35 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxcb-render0 amd64 1.13-2~ubuntu18.04 [14.7 kB]\n",
      "Get:36 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxcb-shm0 amd64 1.13-2~ubuntu18.04 [5600 B]\n",
      "Get:37 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxrender1 amd64 1:0.9.10-1 [18.7 kB]\n",
      "Get:38 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcairo2 amd64 1.15.10-2ubuntu0.1 [580 kB]\n",
      "Get:39 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libcrystalhd3 amd64 1:0.0~git20110715.fdd2f19-12 [45.8 kB]\n",
      "Get:40 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgsm1 amd64 1.0.13-4build1 [22.4 kB]\n",
      "Get:41 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmp3lame0 amd64 3.100-2 [136 kB]\n",
      "Get:42 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libopenjp2-7 amd64 2.3.0-2+deb10u2build0.18.04.1 [145 kB]\n",
      "Get:43 http://archive.ubuntu.com/ubuntu bionic/main amd64 libopus0 amd64 1.1.2-1ubuntu1 [159 kB]\n",
      "Get:44 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcroco3 amd64 0.6.12-2 [81.3 kB]\n",
      "Get:45 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjpeg8 amd64 8c-2ubuntu8 [2194 B]\n",
      "Get:46 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libjbig0 amd64 2.1-3.1ubuntu0.18.04.1 [27.0 kB]\n",
      "Get:47 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libtiff5 amd64 4.0.9-5ubuntu0.10 [154 kB]\n",
      "Get:48 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgdk-pixbuf2.0-common all 2.36.11-2 [4536 B]\n",
      "Get:49 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgdk-pixbuf2.0-0 amd64 2.36.11-2 [165 kB]\n",
      "Get:50 http://archive.ubuntu.com/ubuntu bionic/main amd64 libthai-data all 0.1.27-2 [133 kB]\n",
      "Get:51 http://archive.ubuntu.com/ubuntu bionic/main amd64 libdatrie1 amd64 0.2.10-7 [17.8 kB]\n",
      "Get:52 http://archive.ubuntu.com/ubuntu bionic/main amd64 libthai0 amd64 0.1.27-2 [18.0 kB]\n",
      "Get:53 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpango-1.0-0 amd64 1.40.14-1ubuntu0.1 [153 kB]\n",
      "Get:54 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgraphite2-3 amd64 1.3.11-2 [78.7 kB]\n",
      "Get:55 http://archive.ubuntu.com/ubuntu bionic/main amd64 libharfbuzz0b amd64 1.7.2-1ubuntu1 [232 kB]\n",
      "Get:56 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpangoft2-1.0-0 amd64 1.40.14-1ubuntu0.1 [33.2 kB]\n",
      "Get:57 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpangocairo-1.0-0 amd64 1.40.14-1ubuntu0.1 [20.8 kB]\n",
      "Get:58 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 librsvg2-2 amd64 2.40.20-2ubuntu0.2 [98.6 kB]\n",
      "Get:59 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libshine3 amd64 3.1.1-1 [22.9 kB]\n",
      "Get:60 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsnappy1v5 amd64 1.1.7-1 [16.0 kB]\n",
      "Get:61 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libspeex1 amd64 1.2~rc1.2-1ubuntu2.1 [52.1 kB]\n",
      "Get:62 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsoxr0 amd64 0.1.2-3 [65.9 kB]\n",
      "Get:63 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libswresample2 amd64 7:3.4.11-0ubuntu0.1 [55.2 kB]\n",
      "Get:64 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtheora0 amd64 1.1.1+dfsg.1-14 [170 kB]\n",
      "Get:65 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtwolame0 amd64 0.3.13-3 [46.7 kB]\n",
      "Get:66 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libvpx5 amd64 1.7.0-3ubuntu0.18.04.1 [796 kB]\n",
      "Get:67 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libwavpack1 amd64 5.1.0-2ubuntu1.5 [76.8 kB]\n",
      "Get:68 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libwebp6 amd64 0.6.1-2ubuntu0.18.04.1 [186 kB]\n",
      "Get:69 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libwebpmux3 amd64 0.6.1-2ubuntu0.18.04.1 [19.6 kB]\n",
      "Get:70 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libx264-152 amd64 2:0.152.2854+gite9a5903-2 [609 kB]\n",
      "Get:71 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libx265-146 amd64 2.6-3 [1026 kB]\n",
      "Get:72 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libxvidcore4 amd64 2:1.3.5-1 [200 kB]\n",
      "Get:73 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libzvbi-common all 0.2.35-13 [32.1 kB]\n",
      "Get:74 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libzvbi0 amd64 0.2.35-13 [235 kB]\n",
      "Get:75 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libavcodec57 amd64 7:3.4.11-0ubuntu0.1 [4600 kB]\n",
      "Get:76 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libasound2-data all 1.1.3-5ubuntu0.6 [38.5 kB]\n",
      "Get:77 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libasound2 amd64 1.1.3-5ubuntu0.6 [360 kB]\n",
      "Get:78 http://archive.ubuntu.com/ubuntu bionic/main amd64 libraw1394-11 amd64 2.1.2-1 [30.7 kB]\n",
      "Get:79 http://archive.ubuntu.com/ubuntu bionic/main amd64 libavc1394-0 amd64 0.5.4-4build1 [16.1 kB]\n",
      "Get:80 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libass9 amd64 1:0.14.0-1 [88.2 kB]\n",
      "Get:81 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libbluray2 amd64 1:1.0.2-3 [141 kB]\n",
      "Get:82 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libchromaprint1 amd64 1.4.3-1 [36.8 kB]\n",
      "Get:83 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgme0 amd64 0.6.2-1 [121 kB]\n",
      "Get:84 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmpg123-0 amd64 1.25.10-1 [125 kB]\n",
      "Get:85 http://archive.ubuntu.com/ubuntu bionic/main amd64 libvorbisfile3 amd64 1.3.5-4.2 [16.0 kB]\n",
      "Get:86 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopenmpt0 amd64 0.3.6-1 [561 kB]\n",
      "Get:87 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libssh-gcrypt-4 amd64 0.8.0~20170825.94fa1e38-1ubuntu0.7 [172 kB]\n",
      "Get:88 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libavformat57 amd64 7:3.4.11-0ubuntu0.1 [953 kB]\n",
      "Get:89 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libavresample3 amd64 7:3.4.11-0ubuntu0.1 [52.6 kB]\n",
      "Get:90 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libbs2b0 amd64 3.1.0+dfsg-2.2 [10.5 kB]\n",
      "Get:91 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libflite1 amd64 2.1-release-1 [12.8 MB]\n",
      "Get:92 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libmysofa0 amd64 0.6~dfsg0-3+deb10u1build1 [38.5 kB]\n",
      "Get:93 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libpostproc54 amd64 7:3.4.11-0ubuntu0.1 [50.3 kB]\n",
      "Get:94 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfftw3-double3 amd64 3.3.7-1 [735 kB]\n",
      "Get:95 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsamplerate0 amd64 0.1.9-1 [938 kB]\n",
      "Get:96 http://archive.ubuntu.com/ubuntu bionic/universe amd64 librubberband2 amd64 1.8.1-7ubuntu2 [86.7 kB]\n",
      "Get:97 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libswscale4 amd64 7:3.4.11-0ubuntu0.1 [150 kB]\n",
      "Get:98 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libnorm1 amd64 1.5r6+dfsg1-6 [224 kB]\n",
      "Get:99 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libpgm-5.2-0 amd64 5.2.122~dfsg-2 [157 kB]\n",
      "Get:100 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsodium23 amd64 1.0.16-2 [143 kB]\n",
      "Get:101 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libzmq5 amd64 4.2.5-1ubuntu0.2 [221 kB]\n",
      "Get:102 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libavfilter6 amd64 7:3.4.11-0ubuntu0.1 [875 kB]\n",
      "Get:103 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcaca0 amd64 0.99.beta19-2ubuntu0.18.04.3 [203 kB]\n",
      "Get:104 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcdio17 amd64 1.0.0-2ubuntu2 [58.8 kB]\n",
      "Get:105 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcdio-cdda2 amd64 10.2+0.94+2-2build1 [17.7 kB]\n",
      "Get:106 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcdio-paranoia2 amd64 10.2+0.94+2-2build1 [17.2 kB]\n",
      "Get:107 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libdc1394-22 amd64 2.2.5-1 [77.5 kB]\n",
      "Get:108 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libglvnd0 amd64 1.0.0-2ubuntu2.3 [47.0 kB]\n",
      "Get:109 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libglapi-mesa amd64 20.0.8-0ubuntu1~18.04.1 [26.6 kB]\n",
      "Get:110 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libx11-xcb1 amd64 2:1.6.4-3ubuntu0.4 [9720 B]\n",
      "Get:111 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxcb-dri2-0 amd64 1.13-2~ubuntu18.04 [6920 B]\n",
      "Get:112 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxcb-dri3-0 amd64 1.13-2~ubuntu18.04 [6568 B]\n",
      "Get:113 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxcb-glx0 amd64 1.13-2~ubuntu18.04 [22.1 kB]\n",
      "Get:114 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxcb-present0 amd64 1.13-2~ubuntu18.04 [5552 B]\n",
      "Get:115 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxcb-sync1 amd64 1.13-2~ubuntu18.04 [8808 B]\n",
      "Get:116 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxdamage1 amd64 1:1.1.4-3 [6934 B]\n",
      "Get:117 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxshmfence1 amd64 1.3-1 [5028 B]\n",
      "Get:118 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libdrm-amdgpu1 amd64 2.4.101-2~18.04.1 [18.2 kB]\n",
      "Get:119 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpciaccess0 amd64 0.14-1 [17.9 kB]\n",
      "Get:120 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libdrm-intel1 amd64 2.4.101-2~18.04.1 [60.0 kB]\n",
      "Get:121 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libdrm-nouveau2 amd64 2.4.101-2~18.04.1 [16.5 kB]\n",
      "Get:122 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libdrm-radeon1 amd64 2.4.101-2~18.04.1 [21.7 kB]\n",
      "Get:123 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libllvm10 amd64 1:10.0.0-4ubuntu1~18.04.2 [15.4 MB]\n",
      "Get:124 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libsensors4 amd64 1:3.4.0-4ubuntu0.1 [28.3 kB]\n",
      "Get:125 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgl1-mesa-dri amd64 20.0.8-0ubuntu1~18.04.1 [9333 kB]\n",
      "Get:126 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libglx-mesa0 amd64 20.0.8-0ubuntu1~18.04.1 [139 kB]\n",
      "Get:127 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libglx0 amd64 1.0.0-2ubuntu2.3 [28.1 kB]\n",
      "Get:128 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgl1 amd64 1.0.0-2ubuntu2.3 [86.2 kB]\n",
      "Get:129 http://archive.ubuntu.com/ubuntu bionic/main amd64 libiec61883-0 amd64 1.2.0-2 [23.5 kB]\n",
      "Get:130 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjack-jackd2-0 amd64 1.9.12~dfsg-2 [263 kB]\n",
      "Get:131 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopenal-data all 1:1.18.2-2 [102 kB]\n",
      "Get:132 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsndio6.1 amd64 1.1.0-3 [23.4 kB]\n",
      "Get:133 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopenal1 amd64 1:1.18.2-2 [266 kB]\n",
      "Get:134 http://archive.ubuntu.com/ubuntu bionic/main amd64 libasyncns0 amd64 0.8-6 [12.1 kB]\n",
      "Get:135 http://archive.ubuntu.com/ubuntu bionic/main amd64 libwrap0 amd64 7.6.q-27 [46.3 kB]\n",
      "Get:136 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpulse0 amd64 1:11.1-1ubuntu7.11 [266 kB]\n",
      "Get:137 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libwayland-client0 amd64 1.16.0-1ubuntu1.1~18.04.4 [23.6 kB]\n",
      "Get:138 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libwayland-cursor0 amd64 1.16.0-1ubuntu1.1~18.04.4 [10.2 kB]\n",
      "Get:139 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libwayland-server0 amd64 1.16.0-1ubuntu1.1~18.04.4 [29.6 kB]\n",
      "Get:140 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgbm1 amd64 20.0.8-0ubuntu1~18.04.1 [27.6 kB]\n",
      "Get:141 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxcb-xfixes0 amd64 1.13-2~ubuntu18.04 [9352 B]\n",
      "Get:142 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libegl-mesa0 amd64 20.0.8-0ubuntu1~18.04.1 [96.3 kB]\n",
      "Get:143 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libegl1 amd64 1.0.0-2ubuntu2.3 [32.0 kB]\n",
      "Get:144 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libwayland-egl1 amd64 1.16.0-1ubuntu1.1~18.04.4 [5424 B]\n",
      "Get:145 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libwayland-egl1-mesa amd64 20.0.8-0ubuntu1~18.04.1 [6444 B]\n",
      "Get:146 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxcursor1 amd64 1:1.1.15-1 [19.8 kB]\n",
      "Get:147 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxi6 amd64 2:1.7.9-1 [29.2 kB]\n",
      "Get:148 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxkbcommon0 amd64 0.8.2-1~ubuntu18.04.1 [97.8 kB]\n",
      "Get:149 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxrandr2 amd64 2:1.5.1-1 [18.1 kB]\n",
      "Get:150 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libsdl2-2.0-0 amd64 2.0.8+dfsg1-1ubuntu1.18.04.4 [382 kB]\n",
      "Get:151 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxcb-shape0 amd64 1.13-2~ubuntu18.04 [5972 B]\n",
      "Get:152 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxv1 amd64 2:1.0.11-1 [10.7 kB]\n",
      "Get:153 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libavdevice57 amd64 7:3.4.11-0ubuntu0.1 [75.1 kB]\n",
      "Get:154 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 ffmpeg amd64 7:3.4.11-0ubuntu0.1 [1587 kB]\n",
      "Get:155 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libaacs0 amd64 0.9.0-1 [51.4 kB]\n",
      "Get:156 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libbdplus0 amd64 0.1.2-2 [46.6 kB]\n",
      "Get:157 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgdk-pixbuf2.0-bin amd64 2.36.11-2 [7864 B]\n",
      "Get:158 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 librsvg2-common amd64 2.40.20-2ubuntu0.2 [5064 B]\n",
      "Get:159 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 mesa-va-drivers amd64 20.0.8-0ubuntu1~18.04.1 [2376 kB]\n",
      "Get:160 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 mesa-vdpau-drivers amd64 20.0.8-0ubuntu1~18.04.1 [2496 kB]\n",
      "Get:161 http://archive.ubuntu.com/ubuntu bionic/universe amd64 i965-va-driver amd64 2.1.0-0ubuntu1 [925 kB]\n",
      "Get:162 http://archive.ubuntu.com/ubuntu bionic/universe amd64 va-driver-all amd64 2.1.0-3 [4376 B]\n",
      "Get:163 http://archive.ubuntu.com/ubuntu bionic/main amd64 vdpau-driver-all amd64 1.1.1-3ubuntu1 [4674 B]\n",
      "Fetched 70.3 MB in 16s (4496 kB/s)                                             \n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package libpng16-16:amd64.\n",
      "(Reading database ... 20980 files and directories currently installed.)\n",
      "Preparing to unpack .../000-libpng16-16_1.6.34-1ubuntu0.18.04.2_amd64.deb ...\n",
      "Unpacking libpng16-16:amd64 (1.6.34-1ubuntu0.18.04.2) ...\n",
      "Selecting previously unselected package libfreetype6:amd64.\n",
      "Preparing to unpack .../001-libfreetype6_2.8.1-2ubuntu2.2_amd64.deb ...\n",
      "Unpacking libfreetype6:amd64 (2.8.1-2ubuntu2.2) ...\n",
      "Selecting previously unselected package ucf.\n",
      "Preparing to unpack .../002-ucf_3.0038_all.deb ...\n",
      "Moving old data out of the way\n",
      "Unpacking ucf (3.0038) ...\n",
      "Selecting previously unselected package fonts-dejavu-core.\n",
      "Preparing to unpack .../003-fonts-dejavu-core_2.37-1_all.deb ...\n",
      "Unpacking fonts-dejavu-core (2.37-1) ...\n",
      "Selecting previously unselected package fontconfig-config.\n",
      "Preparing to unpack .../004-fontconfig-config_2.12.6-0ubuntu2_all.deb ...\n",
      "Unpacking fontconfig-config (2.12.6-0ubuntu2) ...\n",
      "Selecting previously unselected package libfontconfig1:amd64.\n",
      "Preparing to unpack .../005-libfontconfig1_2.12.6-0ubuntu2_amd64.deb ...\n",
      "Unpacking libfontconfig1:amd64 (2.12.6-0ubuntu2) ...\n",
      "Selecting previously unselected package fontconfig.\n",
      "Preparing to unpack .../006-fontconfig_2.12.6-0ubuntu2_amd64.deb ...\n",
      "Unpacking fontconfig (2.12.6-0ubuntu2) ...\n",
      "Selecting previously unselected package libjpeg-turbo8:amd64.\n",
      "Preparing to unpack .../007-libjpeg-turbo8_1.5.2-0ubuntu5.18.04.6_amd64.deb ...\n",
      "Unpacking libjpeg-turbo8:amd64 (1.5.2-0ubuntu5.18.04.6) ...\n",
      "Selecting previously unselected package libxinerama1:amd64.\n",
      "Preparing to unpack .../008-libxinerama1_2%3a1.1.3-1_amd64.deb ...\n",
      "Unpacking libxinerama1:amd64 (2:1.1.3-1) ...\n",
      "Selecting previously unselected package x11-common.\n",
      "Preparing to unpack .../009-x11-common_1%3a7.7+19ubuntu7.1_all.deb ...\n",
      "dpkg-query: no packages found matching nux-tools\n",
      "Unpacking x11-common (1:7.7+19ubuntu7.1) ...\n",
      "Selecting previously unselected package libxss1:amd64.\n",
      "Preparing to unpack .../010-libxss1_1%3a1.2.2-1_amd64.deb ...\n",
      "Unpacking libxss1:amd64 (1:1.2.2-1) ...\n",
      "Selecting previously unselected package libxxf86vm1:amd64.\n",
      "Preparing to unpack .../011-libxxf86vm1_1%3a1.1.4-1_amd64.deb ...\n",
      "Unpacking libxxf86vm1:amd64 (1:1.1.4-1) ...\n",
      "Selecting previously unselected package libapparmor1:amd64.\n",
      "Preparing to unpack .../012-libapparmor1_2.12-4ubuntu5.1_amd64.deb ...\n",
      "Unpacking libapparmor1:amd64 (2.12-4ubuntu5.1) ...\n",
      "Selecting previously unselected package libdbus-1-3:amd64.\n",
      "Preparing to unpack .../013-libdbus-1-3_1.12.2-1ubuntu1.4_amd64.deb ...\n",
      "Unpacking libdbus-1-3:amd64 (1.12.2-1ubuntu1.4) ...\n",
      "Selecting previously unselected package dbus.\n",
      "Preparing to unpack .../014-dbus_1.12.2-1ubuntu1.4_amd64.deb ...\n",
      "Unpacking dbus (1.12.2-1ubuntu1.4) ...\n",
      "Selecting previously unselected package libelf1:amd64.\n",
      "Preparing to unpack .../015-libelf1_0.170-0.4ubuntu0.1_amd64.deb ...\n",
      "Unpacking libelf1:amd64 (0.170-0.4ubuntu0.1) ...\n",
      "Selecting previously unselected package libfribidi0:amd64.\n",
      "Preparing to unpack .../016-libfribidi0_0.19.7-2ubuntu0.1_amd64.deb ...\n",
      "Unpacking libfribidi0:amd64 (0.19.7-2ubuntu0.1) ...\n",
      "Selecting previously unselected package libglib2.0-0:amd64.\n",
      "Preparing to unpack .../017-libglib2.0-0_2.56.4-0ubuntu0.18.04.9_amd64.deb ...\n",
      "Unpacking libglib2.0-0:amd64 (2.56.4-0ubuntu0.18.04.9) ...\n",
      "Selecting previously unselected package libglib2.0-data.\n",
      "Preparing to unpack .../018-libglib2.0-data_2.56.4-0ubuntu0.18.04.9_all.deb ...\n",
      "Unpacking libglib2.0-data (2.56.4-0ubuntu0.18.04.9) ...\n",
      "Selecting previously unselected package libslang2:amd64.\n",
      "Preparing to unpack .../019-libslang2_2.3.1a-3ubuntu1_amd64.deb ...\n",
      "Unpacking libslang2:amd64 (2.3.1a-3ubuntu1) ...\n",
      "Selecting previously unselected package shared-mime-info.\n",
      "Preparing to unpack .../020-shared-mime-info_1.9-2_amd64.deb ...\n",
      "Unpacking shared-mime-info (1.9-2) ...\n",
      "Selecting previously unselected package xdg-user-dirs.\n",
      "Preparing to unpack .../021-xdg-user-dirs_0.17-1ubuntu1_amd64.deb ...\n",
      "Unpacking xdg-user-dirs (0.17-1ubuntu1) ...\n",
      "Selecting previously unselected package xkb-data.\n",
      "Preparing to unpack .../022-xkb-data_2.23.1-1ubuntu1.18.04.1_all.deb ...\n",
      "Unpacking xkb-data (2.23.1-1ubuntu1.18.04.1) ...\n",
      "Selecting previously unselected package libdrm-common.\n",
      "Preparing to unpack .../023-libdrm-common_2.4.101-2~18.04.1_all.deb ...\n",
      "Unpacking libdrm-common (2.4.101-2~18.04.1) ...\n",
      "Selecting previously unselected package libdrm2:amd64.\n",
      "Preparing to unpack .../024-libdrm2_2.4.101-2~18.04.1_amd64.deb ...\n",
      "Unpacking libdrm2:amd64 (2.4.101-2~18.04.1) ...\n",
      "Selecting previously unselected package libnuma1:amd64.\n",
      "Preparing to unpack .../025-libnuma1_2.0.11-2.1ubuntu0.1_amd64.deb ...\n",
      "Unpacking libnuma1:amd64 (2.0.11-2.1ubuntu0.1) ...\n",
      "Selecting previously unselected package libusb-1.0-0:amd64.\n",
      "Preparing to unpack .../026-libusb-1.0-0_2%3a1.0.21-2_amd64.deb ...\n",
      "Unpacking libusb-1.0-0:amd64 (2:1.0.21-2) ...\n",
      "Selecting previously unselected package libva2:amd64.\n",
      "Preparing to unpack .../027-libva2_2.1.0-3_amd64.deb ...\n",
      "Unpacking libva2:amd64 (2.1.0-3) ...\n",
      "Selecting previously unselected package libva-drm2:amd64.\n",
      "Preparing to unpack .../028-libva-drm2_2.1.0-3_amd64.deb ...\n",
      "Unpacking libva-drm2:amd64 (2.1.0-3) ...\n",
      "Selecting previously unselected package libxfixes3:amd64.\n",
      "Preparing to unpack .../029-libxfixes3_1%3a5.0.3-1_amd64.deb ...\n",
      "Unpacking libxfixes3:amd64 (1:5.0.3-1) ...\n",
      "Selecting previously unselected package libva-x11-2:amd64.\n",
      "Preparing to unpack .../030-libva-x11-2_2.1.0-3_amd64.deb ...\n",
      "Unpacking libva-x11-2:amd64 (2.1.0-3) ...\n",
      "Selecting previously unselected package libvdpau1:amd64.\n",
      "Preparing to unpack .../031-libvdpau1_1.1.1-3ubuntu1_amd64.deb ...\n",
      "Unpacking libvdpau1:amd64 (1.1.1-3ubuntu1) ...\n",
      "Selecting previously unselected package libavutil55:amd64.\n",
      "Preparing to unpack .../032-libavutil55_7%3a3.4.11-0ubuntu0.1_amd64.deb ...\n",
      "Unpacking libavutil55:amd64 (7:3.4.11-0ubuntu0.1) ...\n",
      "Selecting previously unselected package libpixman-1-0:amd64.\n",
      "Preparing to unpack .../033-libpixman-1-0_0.34.0-2ubuntu0.1_amd64.deb ...\n",
      "Unpacking libpixman-1-0:amd64 (0.34.0-2ubuntu0.1) ...\n",
      "Selecting previously unselected package libxcb-render0:amd64.\n",
      "Preparing to unpack .../034-libxcb-render0_1.13-2~ubuntu18.04_amd64.deb ...\n",
      "Unpacking libxcb-render0:amd64 (1.13-2~ubuntu18.04) ...\n",
      "Selecting previously unselected package libxcb-shm0:amd64.\n",
      "Preparing to unpack .../035-libxcb-shm0_1.13-2~ubuntu18.04_amd64.deb ...\n",
      "Unpacking libxcb-shm0:amd64 (1.13-2~ubuntu18.04) ...\n",
      "Selecting previously unselected package libxrender1:amd64.\n",
      "Preparing to unpack .../036-libxrender1_1%3a0.9.10-1_amd64.deb ...\n",
      "Unpacking libxrender1:amd64 (1:0.9.10-1) ...\n",
      "Selecting previously unselected package libcairo2:amd64.\n",
      "Preparing to unpack .../037-libcairo2_1.15.10-2ubuntu0.1_amd64.deb ...\n",
      "Unpacking libcairo2:amd64 (1.15.10-2ubuntu0.1) ...\n",
      "Selecting previously unselected package libcrystalhd3:amd64.\n",
      "Preparing to unpack .../038-libcrystalhd3_1%3a0.0~git20110715.fdd2f19-12_amd64.deb ...\n",
      "Unpacking libcrystalhd3:amd64 (1:0.0~git20110715.fdd2f19-12) ...\n",
      "Selecting previously unselected package libgsm1:amd64.\n",
      "Preparing to unpack .../039-libgsm1_1.0.13-4build1_amd64.deb ...\n",
      "Unpacking libgsm1:amd64 (1.0.13-4build1) ...\n",
      "Selecting previously unselected package libmp3lame0:amd64.\n",
      "Preparing to unpack .../040-libmp3lame0_3.100-2_amd64.deb ...\n",
      "Unpacking libmp3lame0:amd64 (3.100-2) ...\n",
      "Selecting previously unselected package libopenjp2-7:amd64.\n",
      "Preparing to unpack .../041-libopenjp2-7_2.3.0-2+deb10u2build0.18.04.1_amd64.deb ...\n",
      "Unpacking libopenjp2-7:amd64 (2.3.0-2+deb10u2build0.18.04.1) ...\n",
      "Selecting previously unselected package libopus0:amd64.\n",
      "Preparing to unpack .../042-libopus0_1.1.2-1ubuntu1_amd64.deb ...\n",
      "Unpacking libopus0:amd64 (1.1.2-1ubuntu1) ...\n",
      "Selecting previously unselected package libcroco3:amd64.\n",
      "Preparing to unpack .../043-libcroco3_0.6.12-2_amd64.deb ...\n",
      "Unpacking libcroco3:amd64 (0.6.12-2) ...\n",
      "Selecting previously unselected package libjpeg8:amd64.\n",
      "Preparing to unpack .../044-libjpeg8_8c-2ubuntu8_amd64.deb ...\n",
      "Unpacking libjpeg8:amd64 (8c-2ubuntu8) ...\n",
      "Selecting previously unselected package libjbig0:amd64.\n",
      "Preparing to unpack .../045-libjbig0_2.1-3.1ubuntu0.18.04.1_amd64.deb ...\n",
      "Unpacking libjbig0:amd64 (2.1-3.1ubuntu0.18.04.1) ...\n",
      "Selecting previously unselected package libtiff5:amd64.\n",
      "Preparing to unpack .../046-libtiff5_4.0.9-5ubuntu0.10_amd64.deb ...\n",
      "Unpacking libtiff5:amd64 (4.0.9-5ubuntu0.10) ...\n",
      "Selecting previously unselected package libgdk-pixbuf2.0-common.\n",
      "Preparing to unpack .../047-libgdk-pixbuf2.0-common_2.36.11-2_all.deb ...\n",
      "Unpacking libgdk-pixbuf2.0-common (2.36.11-2) ...\n",
      "Selecting previously unselected package libgdk-pixbuf2.0-0:amd64.\n",
      "Preparing to unpack .../048-libgdk-pixbuf2.0-0_2.36.11-2_amd64.deb ...\n",
      "Unpacking libgdk-pixbuf2.0-0:amd64 (2.36.11-2) ...\n",
      "Selecting previously unselected package libthai-data.\n",
      "Preparing to unpack .../049-libthai-data_0.1.27-2_all.deb ...\n",
      "Unpacking libthai-data (0.1.27-2) ...\n",
      "Selecting previously unselected package libdatrie1:amd64.\n",
      "Preparing to unpack .../050-libdatrie1_0.2.10-7_amd64.deb ...\n",
      "Unpacking libdatrie1:amd64 (0.2.10-7) ...\n",
      "Selecting previously unselected package libthai0:amd64.\n",
      "Preparing to unpack .../051-libthai0_0.1.27-2_amd64.deb ...\n",
      "Unpacking libthai0:amd64 (0.1.27-2) ...\n",
      "Selecting previously unselected package libpango-1.0-0:amd64.\n",
      "Preparing to unpack .../052-libpango-1.0-0_1.40.14-1ubuntu0.1_amd64.deb ...\n",
      "Unpacking libpango-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
      "Selecting previously unselected package libgraphite2-3:amd64.\n",
      "Preparing to unpack .../053-libgraphite2-3_1.3.11-2_amd64.deb ...\n",
      "Unpacking libgraphite2-3:amd64 (1.3.11-2) ...\n",
      "Selecting previously unselected package libharfbuzz0b:amd64.\n",
      "Preparing to unpack .../054-libharfbuzz0b_1.7.2-1ubuntu1_amd64.deb ...\n",
      "Unpacking libharfbuzz0b:amd64 (1.7.2-1ubuntu1) ...\n",
      "Selecting previously unselected package libpangoft2-1.0-0:amd64.\n",
      "Preparing to unpack .../055-libpangoft2-1.0-0_1.40.14-1ubuntu0.1_amd64.deb ...\n",
      "Unpacking libpangoft2-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
      "Selecting previously unselected package libpangocairo-1.0-0:amd64.\n",
      "Preparing to unpack .../056-libpangocairo-1.0-0_1.40.14-1ubuntu0.1_amd64.deb ...\n",
      "Unpacking libpangocairo-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
      "Selecting previously unselected package librsvg2-2:amd64.\n",
      "Preparing to unpack .../057-librsvg2-2_2.40.20-2ubuntu0.2_amd64.deb ...\n",
      "Unpacking librsvg2-2:amd64 (2.40.20-2ubuntu0.2) ...\n",
      "Selecting previously unselected package libshine3:amd64.\n",
      "Preparing to unpack .../058-libshine3_3.1.1-1_amd64.deb ...\n",
      "Unpacking libshine3:amd64 (3.1.1-1) ...\n",
      "Selecting previously unselected package libsnappy1v5:amd64.\n",
      "Preparing to unpack .../059-libsnappy1v5_1.1.7-1_amd64.deb ...\n",
      "Unpacking libsnappy1v5:amd64 (1.1.7-1) ...\n",
      "Selecting previously unselected package libspeex1:amd64.\n",
      "Preparing to unpack .../060-libspeex1_1.2~rc1.2-1ubuntu2.1_amd64.deb ...\n",
      "Unpacking libspeex1:amd64 (1.2~rc1.2-1ubuntu2.1) ...\n",
      "Selecting previously unselected package libsoxr0:amd64.\n",
      "Preparing to unpack .../061-libsoxr0_0.1.2-3_amd64.deb ...\n",
      "Unpacking libsoxr0:amd64 (0.1.2-3) ...\n",
      "Selecting previously unselected package libswresample2:amd64.\n",
      "Preparing to unpack .../062-libswresample2_7%3a3.4.11-0ubuntu0.1_amd64.deb ...\n",
      "Unpacking libswresample2:amd64 (7:3.4.11-0ubuntu0.1) ...\n",
      "Selecting previously unselected package libtheora0:amd64.\n",
      "Preparing to unpack .../063-libtheora0_1.1.1+dfsg.1-14_amd64.deb ...\n",
      "Unpacking libtheora0:amd64 (1.1.1+dfsg.1-14) ...\n",
      "Selecting previously unselected package libtwolame0:amd64.\n",
      "Preparing to unpack .../064-libtwolame0_0.3.13-3_amd64.deb ...\n",
      "Unpacking libtwolame0:amd64 (0.3.13-3) ...\n",
      "Selecting previously unselected package libvpx5:amd64.\n",
      "Preparing to unpack .../065-libvpx5_1.7.0-3ubuntu0.18.04.1_amd64.deb ...\n",
      "Unpacking libvpx5:amd64 (1.7.0-3ubuntu0.18.04.1) ...\n",
      "Selecting previously unselected package libwavpack1:amd64.\n",
      "Preparing to unpack .../066-libwavpack1_5.1.0-2ubuntu1.5_amd64.deb ...\n",
      "Unpacking libwavpack1:amd64 (5.1.0-2ubuntu1.5) ...\n",
      "Selecting previously unselected package libwebp6:amd64.\n",
      "Preparing to unpack .../067-libwebp6_0.6.1-2ubuntu0.18.04.1_amd64.deb ...\n",
      "Unpacking libwebp6:amd64 (0.6.1-2ubuntu0.18.04.1) ...\n",
      "Selecting previously unselected package libwebpmux3:amd64.\n",
      "Preparing to unpack .../068-libwebpmux3_0.6.1-2ubuntu0.18.04.1_amd64.deb ...\n",
      "Unpacking libwebpmux3:amd64 (0.6.1-2ubuntu0.18.04.1) ...\n",
      "Selecting previously unselected package libx264-152:amd64.\n",
      "Preparing to unpack .../069-libx264-152_2%3a0.152.2854+gite9a5903-2_amd64.deb ...\n",
      "Unpacking libx264-152:amd64 (2:0.152.2854+gite9a5903-2) ...\n",
      "Selecting previously unselected package libx265-146:amd64.\n",
      "Preparing to unpack .../070-libx265-146_2.6-3_amd64.deb ...\n",
      "Unpacking libx265-146:amd64 (2.6-3) ...\n",
      "Selecting previously unselected package libxvidcore4:amd64.\n",
      "Preparing to unpack .../071-libxvidcore4_2%3a1.3.5-1_amd64.deb ...\n",
      "Unpacking libxvidcore4:amd64 (2:1.3.5-1) ...\n",
      "Selecting previously unselected package libzvbi-common.\n",
      "Preparing to unpack .../072-libzvbi-common_0.2.35-13_all.deb ...\n",
      "Unpacking libzvbi-common (0.2.35-13) ...\n",
      "Selecting previously unselected package libzvbi0:amd64.\n",
      "Preparing to unpack .../073-libzvbi0_0.2.35-13_amd64.deb ...\n",
      "Unpacking libzvbi0:amd64 (0.2.35-13) ...\n",
      "Selecting previously unselected package libavcodec57:amd64.\n",
      "Preparing to unpack .../074-libavcodec57_7%3a3.4.11-0ubuntu0.1_amd64.deb ...\n",
      "Unpacking libavcodec57:amd64 (7:3.4.11-0ubuntu0.1) ...\n",
      "Selecting previously unselected package libasound2-data.\n",
      "Preparing to unpack .../075-libasound2-data_1.1.3-5ubuntu0.6_all.deb ...\n",
      "Unpacking libasound2-data (1.1.3-5ubuntu0.6) ...\n",
      "Selecting previously unselected package libasound2:amd64.\n",
      "Preparing to unpack .../076-libasound2_1.1.3-5ubuntu0.6_amd64.deb ...\n",
      "Unpacking libasound2:amd64 (1.1.3-5ubuntu0.6) ...\n",
      "Selecting previously unselected package libraw1394-11:amd64.\n",
      "Preparing to unpack .../077-libraw1394-11_2.1.2-1_amd64.deb ...\n",
      "Unpacking libraw1394-11:amd64 (2.1.2-1) ...\n",
      "Selecting previously unselected package libavc1394-0:amd64.\n",
      "Preparing to unpack .../078-libavc1394-0_0.5.4-4build1_amd64.deb ...\n",
      "Unpacking libavc1394-0:amd64 (0.5.4-4build1) ...\n",
      "Selecting previously unselected package libass9:amd64.\n",
      "Preparing to unpack .../079-libass9_1%3a0.14.0-1_amd64.deb ...\n",
      "Unpacking libass9:amd64 (1:0.14.0-1) ...\n",
      "Selecting previously unselected package libbluray2:amd64.\n",
      "Preparing to unpack .../080-libbluray2_1%3a1.0.2-3_amd64.deb ...\n",
      "Unpacking libbluray2:amd64 (1:1.0.2-3) ...\n",
      "Selecting previously unselected package libchromaprint1:amd64.\n",
      "Preparing to unpack .../081-libchromaprint1_1.4.3-1_amd64.deb ...\n",
      "Unpacking libchromaprint1:amd64 (1.4.3-1) ...\n",
      "Selecting previously unselected package libgme0:amd64.\n",
      "Preparing to unpack .../082-libgme0_0.6.2-1_amd64.deb ...\n",
      "Unpacking libgme0:amd64 (0.6.2-1) ...\n",
      "Selecting previously unselected package libmpg123-0:amd64.\n",
      "Preparing to unpack .../083-libmpg123-0_1.25.10-1_amd64.deb ...\n",
      "Unpacking libmpg123-0:amd64 (1.25.10-1) ...\n",
      "Selecting previously unselected package libvorbisfile3:amd64.\n",
      "Preparing to unpack .../084-libvorbisfile3_1.3.5-4.2_amd64.deb ...\n",
      "Unpacking libvorbisfile3:amd64 (1.3.5-4.2) ...\n",
      "Selecting previously unselected package libopenmpt0:amd64.\n",
      "Preparing to unpack .../085-libopenmpt0_0.3.6-1_amd64.deb ...\n",
      "Unpacking libopenmpt0:amd64 (0.3.6-1) ...\n",
      "Selecting previously unselected package libssh-gcrypt-4:amd64.\n",
      "Preparing to unpack .../086-libssh-gcrypt-4_0.8.0~20170825.94fa1e38-1ubuntu0.7_amd64.deb ...\n",
      "Unpacking libssh-gcrypt-4:amd64 (0.8.0~20170825.94fa1e38-1ubuntu0.7) ...\n",
      "Selecting previously unselected package libavformat57:amd64.\n",
      "Preparing to unpack .../087-libavformat57_7%3a3.4.11-0ubuntu0.1_amd64.deb ...\n",
      "Unpacking libavformat57:amd64 (7:3.4.11-0ubuntu0.1) ...\n",
      "Selecting previously unselected package libavresample3:amd64.\n",
      "Preparing to unpack .../088-libavresample3_7%3a3.4.11-0ubuntu0.1_amd64.deb ...\n",
      "Unpacking libavresample3:amd64 (7:3.4.11-0ubuntu0.1) ...\n",
      "Selecting previously unselected package libbs2b0:amd64.\n",
      "Preparing to unpack .../089-libbs2b0_3.1.0+dfsg-2.2_amd64.deb ...\n",
      "Unpacking libbs2b0:amd64 (3.1.0+dfsg-2.2) ...\n",
      "Selecting previously unselected package libflite1:amd64.\n",
      "Preparing to unpack .../090-libflite1_2.1-release-1_amd64.deb ...\n",
      "Unpacking libflite1:amd64 (2.1-release-1) ...\n",
      "Selecting previously unselected package libmysofa0:amd64.\n",
      "Preparing to unpack .../091-libmysofa0_0.6~dfsg0-3+deb10u1build1_amd64.deb ...\n",
      "Unpacking libmysofa0:amd64 (0.6~dfsg0-3+deb10u1build1) ...\n",
      "Selecting previously unselected package libpostproc54:amd64.\n",
      "Preparing to unpack .../092-libpostproc54_7%3a3.4.11-0ubuntu0.1_amd64.deb ...\n",
      "Unpacking libpostproc54:amd64 (7:3.4.11-0ubuntu0.1) ...\n",
      "Selecting previously unselected package libfftw3-double3:amd64.\n",
      "Preparing to unpack .../093-libfftw3-double3_3.3.7-1_amd64.deb ...\n",
      "Unpacking libfftw3-double3:amd64 (3.3.7-1) ...\n",
      "Selecting previously unselected package libsamplerate0:amd64.\n",
      "Preparing to unpack .../094-libsamplerate0_0.1.9-1_amd64.deb ...\n",
      "Unpacking libsamplerate0:amd64 (0.1.9-1) ...\n",
      "Selecting previously unselected package librubberband2:amd64.\n",
      "Preparing to unpack .../095-librubberband2_1.8.1-7ubuntu2_amd64.deb ...\n",
      "Unpacking librubberband2:amd64 (1.8.1-7ubuntu2) ...\n",
      "Selecting previously unselected package libswscale4:amd64.\n",
      "Preparing to unpack .../096-libswscale4_7%3a3.4.11-0ubuntu0.1_amd64.deb ...\n",
      "Unpacking libswscale4:amd64 (7:3.4.11-0ubuntu0.1) ...\n",
      "Selecting previously unselected package libnorm1:amd64.\n",
      "Preparing to unpack .../097-libnorm1_1.5r6+dfsg1-6_amd64.deb ...\n",
      "Unpacking libnorm1:amd64 (1.5r6+dfsg1-6) ...\n",
      "Selecting previously unselected package libpgm-5.2-0:amd64.\n",
      "Preparing to unpack .../098-libpgm-5.2-0_5.2.122~dfsg-2_amd64.deb ...\n",
      "Unpacking libpgm-5.2-0:amd64 (5.2.122~dfsg-2) ...\n",
      "Selecting previously unselected package libsodium23:amd64.\n",
      "Preparing to unpack .../099-libsodium23_1.0.16-2_amd64.deb ...\n",
      "Unpacking libsodium23:amd64 (1.0.16-2) ...\n",
      "Selecting previously unselected package libzmq5:amd64.\n",
      "Preparing to unpack .../100-libzmq5_4.2.5-1ubuntu0.2_amd64.deb ...\n",
      "Unpacking libzmq5:amd64 (4.2.5-1ubuntu0.2) ...\n",
      "Selecting previously unselected package libavfilter6:amd64.\n",
      "Preparing to unpack .../101-libavfilter6_7%3a3.4.11-0ubuntu0.1_amd64.deb ...\n",
      "Unpacking libavfilter6:amd64 (7:3.4.11-0ubuntu0.1) ...\n",
      "Selecting previously unselected package libcaca0:amd64.\n",
      "Preparing to unpack .../102-libcaca0_0.99.beta19-2ubuntu0.18.04.3_amd64.deb ...\n",
      "Unpacking libcaca0:amd64 (0.99.beta19-2ubuntu0.18.04.3) ...\n",
      "Selecting previously unselected package libcdio17:amd64.\n",
      "Preparing to unpack .../103-libcdio17_1.0.0-2ubuntu2_amd64.deb ...\n",
      "Unpacking libcdio17:amd64 (1.0.0-2ubuntu2) ...\n",
      "Selecting previously unselected package libcdio-cdda2:amd64.\n",
      "Preparing to unpack .../104-libcdio-cdda2_10.2+0.94+2-2build1_amd64.deb ...\n",
      "Unpacking libcdio-cdda2:amd64 (10.2+0.94+2-2build1) ...\n",
      "Selecting previously unselected package libcdio-paranoia2:amd64.\n",
      "Preparing to unpack .../105-libcdio-paranoia2_10.2+0.94+2-2build1_amd64.deb ...\n",
      "Unpacking libcdio-paranoia2:amd64 (10.2+0.94+2-2build1) ...\n",
      "Selecting previously unselected package libdc1394-22:amd64.\n",
      "Preparing to unpack .../106-libdc1394-22_2.2.5-1_amd64.deb ...\n",
      "Unpacking libdc1394-22:amd64 (2.2.5-1) ...\n",
      "Selecting previously unselected package libglvnd0:amd64.\n",
      "Preparing to unpack .../107-libglvnd0_1.0.0-2ubuntu2.3_amd64.deb ...\n",
      "Unpacking libglvnd0:amd64 (1.0.0-2ubuntu2.3) ...\n",
      "Selecting previously unselected package libglapi-mesa:amd64.\n",
      "Preparing to unpack .../108-libglapi-mesa_20.0.8-0ubuntu1~18.04.1_amd64.deb ...\n",
      "Unpacking libglapi-mesa:amd64 (20.0.8-0ubuntu1~18.04.1) ...\n",
      "Selecting previously unselected package libx11-xcb1:amd64.\n",
      "Preparing to unpack .../109-libx11-xcb1_2%3a1.6.4-3ubuntu0.4_amd64.deb ...\n",
      "Unpacking libx11-xcb1:amd64 (2:1.6.4-3ubuntu0.4) ...\n",
      "Selecting previously unselected package libxcb-dri2-0:amd64.\n",
      "Preparing to unpack .../110-libxcb-dri2-0_1.13-2~ubuntu18.04_amd64.deb ...\n",
      "Unpacking libxcb-dri2-0:amd64 (1.13-2~ubuntu18.04) ...\n",
      "Selecting previously unselected package libxcb-dri3-0:amd64.\n",
      "Preparing to unpack .../111-libxcb-dri3-0_1.13-2~ubuntu18.04_amd64.deb ...\n",
      "Unpacking libxcb-dri3-0:amd64 (1.13-2~ubuntu18.04) ...\n",
      "Selecting previously unselected package libxcb-glx0:amd64.\n",
      "Preparing to unpack .../112-libxcb-glx0_1.13-2~ubuntu18.04_amd64.deb ...\n",
      "Unpacking libxcb-glx0:amd64 (1.13-2~ubuntu18.04) ...\n",
      "Selecting previously unselected package libxcb-present0:amd64.\n",
      "Preparing to unpack .../113-libxcb-present0_1.13-2~ubuntu18.04_amd64.deb ...\n",
      "Unpacking libxcb-present0:amd64 (1.13-2~ubuntu18.04) ...\n",
      "Selecting previously unselected package libxcb-sync1:amd64.\n",
      "Preparing to unpack .../114-libxcb-sync1_1.13-2~ubuntu18.04_amd64.deb ...\n",
      "Unpacking libxcb-sync1:amd64 (1.13-2~ubuntu18.04) ...\n",
      "Selecting previously unselected package libxdamage1:amd64.\n",
      "Preparing to unpack .../115-libxdamage1_1%3a1.1.4-3_amd64.deb ...\n",
      "Unpacking libxdamage1:amd64 (1:1.1.4-3) ...\n",
      "Selecting previously unselected package libxshmfence1:amd64.\n",
      "Preparing to unpack .../116-libxshmfence1_1.3-1_amd64.deb ...\n",
      "Unpacking libxshmfence1:amd64 (1.3-1) ...\n",
      "Selecting previously unselected package libdrm-amdgpu1:amd64.\n",
      "Preparing to unpack .../117-libdrm-amdgpu1_2.4.101-2~18.04.1_amd64.deb ...\n",
      "Unpacking libdrm-amdgpu1:amd64 (2.4.101-2~18.04.1) ...\n",
      "Selecting previously unselected package libpciaccess0:amd64.\n",
      "Preparing to unpack .../118-libpciaccess0_0.14-1_amd64.deb ...\n",
      "Unpacking libpciaccess0:amd64 (0.14-1) ...\n",
      "Selecting previously unselected package libdrm-intel1:amd64.\n",
      "Preparing to unpack .../119-libdrm-intel1_2.4.101-2~18.04.1_amd64.deb ...\n",
      "Unpacking libdrm-intel1:amd64 (2.4.101-2~18.04.1) ...\n",
      "Selecting previously unselected package libdrm-nouveau2:amd64.\n",
      "Preparing to unpack .../120-libdrm-nouveau2_2.4.101-2~18.04.1_amd64.deb ...\n",
      "Unpacking libdrm-nouveau2:amd64 (2.4.101-2~18.04.1) ...\n",
      "Selecting previously unselected package libdrm-radeon1:amd64.\n",
      "Preparing to unpack .../121-libdrm-radeon1_2.4.101-2~18.04.1_amd64.deb ...\n",
      "Unpacking libdrm-radeon1:amd64 (2.4.101-2~18.04.1) ...\n",
      "Selecting previously unselected package libllvm10:amd64.\n",
      "Preparing to unpack .../122-libllvm10_1%3a10.0.0-4ubuntu1~18.04.2_amd64.deb ...\n",
      "Unpacking libllvm10:amd64 (1:10.0.0-4ubuntu1~18.04.2) ...\n",
      "Selecting previously unselected package libsensors4:amd64.\n",
      "Preparing to unpack .../123-libsensors4_1%3a3.4.0-4ubuntu0.1_amd64.deb ...\n",
      "Unpacking libsensors4:amd64 (1:3.4.0-4ubuntu0.1) ...\n",
      "Selecting previously unselected package libgl1-mesa-dri:amd64.\n",
      "Preparing to unpack .../124-libgl1-mesa-dri_20.0.8-0ubuntu1~18.04.1_amd64.deb ...\n",
      "Unpacking libgl1-mesa-dri:amd64 (20.0.8-0ubuntu1~18.04.1) ...\n",
      "Selecting previously unselected package libglx-mesa0:amd64.\n",
      "Preparing to unpack .../125-libglx-mesa0_20.0.8-0ubuntu1~18.04.1_amd64.deb ...\n",
      "Unpacking libglx-mesa0:amd64 (20.0.8-0ubuntu1~18.04.1) ...\n",
      "Selecting previously unselected package libglx0:amd64.\n",
      "Preparing to unpack .../126-libglx0_1.0.0-2ubuntu2.3_amd64.deb ...\n",
      "Unpacking libglx0:amd64 (1.0.0-2ubuntu2.3) ...\n",
      "Selecting previously unselected package libgl1:amd64.\n",
      "Preparing to unpack .../127-libgl1_1.0.0-2ubuntu2.3_amd64.deb ...\n",
      "Unpacking libgl1:amd64 (1.0.0-2ubuntu2.3) ...\n",
      "Selecting previously unselected package libiec61883-0:amd64.\n",
      "Preparing to unpack .../128-libiec61883-0_1.2.0-2_amd64.deb ...\n",
      "Unpacking libiec61883-0:amd64 (1.2.0-2) ...\n",
      "Selecting previously unselected package libjack-jackd2-0:amd64.\n",
      "Preparing to unpack .../129-libjack-jackd2-0_1.9.12~dfsg-2_amd64.deb ...\n",
      "Unpacking libjack-jackd2-0:amd64 (1.9.12~dfsg-2) ...\n",
      "Selecting previously unselected package libopenal-data.\n",
      "Preparing to unpack .../130-libopenal-data_1%3a1.18.2-2_all.deb ...\n",
      "Unpacking libopenal-data (1:1.18.2-2) ...\n",
      "Selecting previously unselected package libsndio6.1:amd64.\n",
      "Preparing to unpack .../131-libsndio6.1_1.1.0-3_amd64.deb ...\n",
      "Unpacking libsndio6.1:amd64 (1.1.0-3) ...\n",
      "Selecting previously unselected package libopenal1:amd64.\n",
      "Preparing to unpack .../132-libopenal1_1%3a1.18.2-2_amd64.deb ...\n",
      "Unpacking libopenal1:amd64 (1:1.18.2-2) ...\n",
      "Selecting previously unselected package libasyncns0:amd64.\n",
      "Preparing to unpack .../133-libasyncns0_0.8-6_amd64.deb ...\n",
      "Unpacking libasyncns0:amd64 (0.8-6) ...\n",
      "Selecting previously unselected package libwrap0:amd64.\n",
      "Preparing to unpack .../134-libwrap0_7.6.q-27_amd64.deb ...\n",
      "Unpacking libwrap0:amd64 (7.6.q-27) ...\n",
      "Selecting previously unselected package libpulse0:amd64.\n",
      "Preparing to unpack .../135-libpulse0_1%3a11.1-1ubuntu7.11_amd64.deb ...\n",
      "Unpacking libpulse0:amd64 (1:11.1-1ubuntu7.11) ...\n",
      "Selecting previously unselected package libwayland-client0:amd64.\n",
      "Preparing to unpack .../136-libwayland-client0_1.16.0-1ubuntu1.1~18.04.4_amd64.deb ...\n",
      "Unpacking libwayland-client0:amd64 (1.16.0-1ubuntu1.1~18.04.4) ...\n",
      "Selecting previously unselected package libwayland-cursor0:amd64.\n",
      "Preparing to unpack .../137-libwayland-cursor0_1.16.0-1ubuntu1.1~18.04.4_amd64.deb ...\n",
      "Unpacking libwayland-cursor0:amd64 (1.16.0-1ubuntu1.1~18.04.4) ...\n",
      "Selecting previously unselected package libwayland-server0:amd64.\n",
      "Preparing to unpack .../138-libwayland-server0_1.16.0-1ubuntu1.1~18.04.4_amd64.deb ...\n",
      "Unpacking libwayland-server0:amd64 (1.16.0-1ubuntu1.1~18.04.4) ...\n",
      "Selecting previously unselected package libgbm1:amd64.\n",
      "Preparing to unpack .../139-libgbm1_20.0.8-0ubuntu1~18.04.1_amd64.deb ...\n",
      "Unpacking libgbm1:amd64 (20.0.8-0ubuntu1~18.04.1) ...\n",
      "Selecting previously unselected package libxcb-xfixes0:amd64.\n",
      "Preparing to unpack .../140-libxcb-xfixes0_1.13-2~ubuntu18.04_amd64.deb ...\n",
      "Unpacking libxcb-xfixes0:amd64 (1.13-2~ubuntu18.04) ...\n",
      "Selecting previously unselected package libegl-mesa0:amd64.\n",
      "Preparing to unpack .../141-libegl-mesa0_20.0.8-0ubuntu1~18.04.1_amd64.deb ...\n",
      "Unpacking libegl-mesa0:amd64 (20.0.8-0ubuntu1~18.04.1) ...\n",
      "Selecting previously unselected package libegl1:amd64.\n",
      "Preparing to unpack .../142-libegl1_1.0.0-2ubuntu2.3_amd64.deb ...\n",
      "Unpacking libegl1:amd64 (1.0.0-2ubuntu2.3) ...\n",
      "Selecting previously unselected package libwayland-egl1:amd64.\n",
      "Preparing to unpack .../143-libwayland-egl1_1.16.0-1ubuntu1.1~18.04.4_amd64.deb ...\n",
      "Unpacking libwayland-egl1:amd64 (1.16.0-1ubuntu1.1~18.04.4) ...\n",
      "Selecting previously unselected package libwayland-egl1-mesa:amd64.\n",
      "Preparing to unpack .../144-libwayland-egl1-mesa_20.0.8-0ubuntu1~18.04.1_amd64.deb ...\n",
      "Unpacking libwayland-egl1-mesa:amd64 (20.0.8-0ubuntu1~18.04.1) ...\n",
      "Selecting previously unselected package libxcursor1:amd64.\n",
      "Preparing to unpack .../145-libxcursor1_1%3a1.1.15-1_amd64.deb ...\n",
      "Unpacking libxcursor1:amd64 (1:1.1.15-1) ...\n",
      "Selecting previously unselected package libxi6:amd64.\n",
      "Preparing to unpack .../146-libxi6_2%3a1.7.9-1_amd64.deb ...\n",
      "Unpacking libxi6:amd64 (2:1.7.9-1) ...\n",
      "Selecting previously unselected package libxkbcommon0:amd64.\n",
      "Preparing to unpack .../147-libxkbcommon0_0.8.2-1~ubuntu18.04.1_amd64.deb ...\n",
      "Unpacking libxkbcommon0:amd64 (0.8.2-1~ubuntu18.04.1) ...\n",
      "Selecting previously unselected package libxrandr2:amd64.\n",
      "Preparing to unpack .../148-libxrandr2_2%3a1.5.1-1_amd64.deb ...\n",
      "Unpacking libxrandr2:amd64 (2:1.5.1-1) ...\n",
      "Selecting previously unselected package libsdl2-2.0-0:amd64.\n",
      "Preparing to unpack .../149-libsdl2-2.0-0_2.0.8+dfsg1-1ubuntu1.18.04.4_amd64.deb ...\n",
      "Unpacking libsdl2-2.0-0:amd64 (2.0.8+dfsg1-1ubuntu1.18.04.4) ...\n",
      "Selecting previously unselected package libxcb-shape0:amd64.\n",
      "Preparing to unpack .../150-libxcb-shape0_1.13-2~ubuntu18.04_amd64.deb ...\n",
      "Unpacking libxcb-shape0:amd64 (1.13-2~ubuntu18.04) ...\n",
      "Selecting previously unselected package libxv1:amd64.\n",
      "Preparing to unpack .../151-libxv1_2%3a1.0.11-1_amd64.deb ...\n",
      "Unpacking libxv1:amd64 (2:1.0.11-1) ...\n",
      "Selecting previously unselected package libavdevice57:amd64.\n",
      "Preparing to unpack .../152-libavdevice57_7%3a3.4.11-0ubuntu0.1_amd64.deb ...\n",
      "Unpacking libavdevice57:amd64 (7:3.4.11-0ubuntu0.1) ...\n",
      "Selecting previously unselected package ffmpeg.\n",
      "Preparing to unpack .../153-ffmpeg_7%3a3.4.11-0ubuntu0.1_amd64.deb ...\n",
      "Unpacking ffmpeg (7:3.4.11-0ubuntu0.1) ...\n",
      "Selecting previously unselected package libaacs0:amd64.\n",
      "Preparing to unpack .../154-libaacs0_0.9.0-1_amd64.deb ...\n",
      "Unpacking libaacs0:amd64 (0.9.0-1) ...\n",
      "Selecting previously unselected package libbdplus0:amd64.\n",
      "Preparing to unpack .../155-libbdplus0_0.1.2-2_amd64.deb ...\n",
      "Unpacking libbdplus0:amd64 (0.1.2-2) ...\n",
      "Selecting previously unselected package libgdk-pixbuf2.0-bin.\n",
      "Preparing to unpack .../156-libgdk-pixbuf2.0-bin_2.36.11-2_amd64.deb ...\n",
      "Unpacking libgdk-pixbuf2.0-bin (2.36.11-2) ...\n",
      "Selecting previously unselected package librsvg2-common:amd64.\n",
      "Preparing to unpack .../157-librsvg2-common_2.40.20-2ubuntu0.2_amd64.deb ...\n",
      "Unpacking librsvg2-common:amd64 (2.40.20-2ubuntu0.2) ...\n",
      "Selecting previously unselected package mesa-va-drivers:amd64.\n",
      "Preparing to unpack .../158-mesa-va-drivers_20.0.8-0ubuntu1~18.04.1_amd64.deb ...\n",
      "Unpacking mesa-va-drivers:amd64 (20.0.8-0ubuntu1~18.04.1) ...\n",
      "Selecting previously unselected package mesa-vdpau-drivers:amd64.\n",
      "Preparing to unpack .../159-mesa-vdpau-drivers_20.0.8-0ubuntu1~18.04.1_amd64.deb ...\n",
      "Unpacking mesa-vdpau-drivers:amd64 (20.0.8-0ubuntu1~18.04.1) ...\n",
      "Selecting previously unselected package i965-va-driver:amd64.\n",
      "Preparing to unpack .../160-i965-va-driver_2.1.0-0ubuntu1_amd64.deb ...\n",
      "Unpacking i965-va-driver:amd64 (2.1.0-0ubuntu1) ...\n",
      "Selecting previously unselected package va-driver-all:amd64.\n",
      "Preparing to unpack .../161-va-driver-all_2.1.0-3_amd64.deb ...\n",
      "Unpacking va-driver-all:amd64 (2.1.0-3) ...\n",
      "Selecting previously unselected package vdpau-driver-all:amd64.\n",
      "Preparing to unpack .../162-vdpau-driver-all_1.1.1-3ubuntu1_amd64.deb ...\n",
      "Unpacking vdpau-driver-all:amd64 (1.1.1-3ubuntu1) ...\n",
      "Setting up libvorbisfile3:amd64 (1.3.5-4.2) ...\n",
      "Setting up libxi6:amd64 (2:1.7.9-1) ...\n",
      "Setting up libpgm-5.2-0:amd64 (5.2.122~dfsg-2) ...\n",
      "Setting up libxcb-present0:amd64 (1.13-2~ubuntu18.04) ...\n",
      "Setting up libglvnd0:amd64 (1.0.0-2ubuntu2.3) ...\n",
      "Setting up libxinerama1:amd64 (2:1.1.3-1) ...\n",
      "Setting up libxcb-dri2-0:amd64 (1.13-2~ubuntu18.04) ...\n",
      "Setting up libxcb-dri3-0:amd64 (1.13-2~ubuntu18.04) ...\n",
      "Setting up libxcb-glx0:amd64 (1.13-2~ubuntu18.04) ...\n",
      "Setting up libtwolame0:amd64 (0.3.13-3) ...\n",
      "Setting up libraw1394-11:amd64 (2.1.2-1) ...\n",
      "Setting up libx264-152:amd64 (2:0.152.2854+gite9a5903-2) ...\n",
      "Setting up libxcb-xfixes0:amd64 (1.13-2~ubuntu18.04) ...\n",
      "Setting up libxcb-render0:amd64 (1.13-2~ubuntu18.04) ...\n",
      "Setting up libopenjp2-7:amd64 (2.3.0-2+deb10u2build0.18.04.1) ...\n",
      "Setting up libllvm10:amd64 (1:10.0.0-4ubuntu1~18.04.2) ...\n",
      "Setting up libasyncns0:amd64 (0.8-6) ...\n",
      "Setting up libxdamage1:amd64 (1:1.1.4-3) ...\n",
      "Setting up libxfixes3:amd64 (1:5.0.3-1) ...\n",
      "Setting up libpng16-16:amd64 (1.6.34-1ubuntu0.18.04.2) ...\n",
      "Setting up libwavpack1:amd64 (5.1.0-2ubuntu1.5) ...\n",
      "Setting up libjbig0:amd64 (2.1-3.1ubuntu0.18.04.1) ...\n",
      "Setting up fonts-dejavu-core (2.37-1) ...\n",
      "Setting up libaacs0:amd64 (0.9.0-1) ...\n",
      "Setting up libnuma1:amd64 (2.0.11-2.1ubuntu0.1) ...\n",
      "Setting up libelf1:amd64 (0.170-0.4ubuntu0.1) ...\n",
      "Setting up libsoxr0:amd64 (0.1.2-3) ...\n",
      "Setting up libglib2.0-0:amd64 (2.56.4-0ubuntu0.18.04.9) ...\n",
      "No schema files found: doing nothing.\n",
      "Setting up libssh-gcrypt-4:amd64 (0.8.0~20170825.94fa1e38-1ubuntu0.7) ...\n",
      "Setting up libasound2-data (1.1.3-5ubuntu0.6) ...\n",
      "Setting up libxshmfence1:amd64 (1.3-1) ...\n",
      "Setting up libwayland-client0:amd64 (1.16.0-1ubuntu1.1~18.04.4) ...\n",
      "Setting up xkb-data (2.23.1-1ubuntu1.18.04.1) ...\n",
      "Setting up libvdpau1:amd64 (1.1.1-3ubuntu1) ...\n",
      "Setting up libgdk-pixbuf2.0-common (2.36.11-2) ...\n",
      "Setting up libdatrie1:amd64 (0.2.10-7) ...\n",
      "Setting up libshine3:amd64 (3.1.1-1) ...\n",
      "Setting up libva2:amd64 (2.1.0-3) ...\n",
      "Setting up libjpeg-turbo8:amd64 (1.5.2-0ubuntu5.18.04.6) ...\n",
      "Setting up libiec61883-0:amd64 (1.2.0-2) ...\n",
      "Setting up libglapi-mesa:amd64 (20.0.8-0ubuntu1~18.04.1) ...\n",
      "Setting up libspeex1:amd64 (1.2~rc1.2-1ubuntu2.1) ...\n",
      "Setting up libfftw3-double3:amd64 (3.3.7-1) ...\n",
      "Setting up libxvidcore4:amd64 (2:1.3.5-1) ...\n",
      "Setting up ucf (3.0038) ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
      "debconf: falling back to frontend: Readline\n",
      "Setting up libopus0:amd64 (1.1.2-1ubuntu1) ...\n",
      "Setting up libfreetype6:amd64 (2.8.1-2ubuntu2.2) ...\n",
      "Setting up libx265-146:amd64 (2.6-3) ...\n",
      "Setting up libasound2:amd64 (1.1.3-5ubuntu0.6) ...\n",
      "Setting up libopenal-data (1:1.18.2-2) ...\n",
      "Setting up libdrm-common (2.4.101-2~18.04.1) ...\n",
      "Setting up libgraphite2-3:amd64 (1.3.11-2) ...\n",
      "Setting up libbs2b0:amd64 (3.1.0+dfsg-2.2) ...\n",
      "Setting up libcroco3:amd64 (0.6.12-2) ...\n",
      "Setting up libxcb-sync1:amd64 (1.13-2~ubuntu18.04) ...\n",
      "Setting up libnorm1:amd64 (1.5r6+dfsg1-6) ...\n",
      "Setting up libsodium23:amd64 (1.0.16-2) ...\n",
      "Setting up libx11-xcb1:amd64 (2:1.6.4-3ubuntu0.4) ...\n",
      "Setting up libpixman-1-0:amd64 (0.34.0-2ubuntu0.1) ...\n",
      "Setting up libmp3lame0:amd64 (3.100-2) ...\n",
      "Setting up libglib2.0-data (2.56.4-0ubuntu0.18.04.9) ...\n",
      "Setting up libusb-1.0-0:amd64 (2:1.0.21-2) ...\n",
      "Setting up libcrystalhd3:amd64 (1:0.0~git20110715.fdd2f19-12) ...\n",
      "Setting up libapparmor1:amd64 (2.12-4ubuntu5.1) ...\n",
      "Setting up libsnappy1v5:amd64 (1.1.7-1) ...\n",
      "Setting up libavc1394-0:amd64 (0.5.4-4build1) ...\n",
      "Setting up libzvbi-common (0.2.35-13) ...\n",
      "Setting up libfribidi0:amd64 (0.19.7-2ubuntu0.1) ...\n",
      "Setting up libxcb-shm0:amd64 (1.13-2~ubuntu18.04) ...\n",
      "Setting up libxcb-shape0:amd64 (1.13-2~ubuntu18.04) ...\n",
      "Setting up libpciaccess0:amd64 (0.14-1) ...\n",
      "Setting up libxrender1:amd64 (1:0.9.10-1) ...\n",
      "Setting up libxv1:amd64 (2:1.0.11-1) ...\n",
      "Setting up libsensors4:amd64 (1:3.4.0-4ubuntu0.1) ...\n",
      "Setting up shared-mime-info (1.9-2) ...\n",
      "Setting up libxkbcommon0:amd64 (0.8.2-1~ubuntu18.04.1) ...\n",
      "Setting up libvpx5:amd64 (1.7.0-3ubuntu0.18.04.1) ...\n",
      "Setting up libgme0:amd64 (0.6.2-1) ...\n",
      "Setting up libthai-data (0.1.27-2) ...\n",
      "Setting up libbdplus0:amd64 (0.1.2-2) ...\n",
      "Setting up libxxf86vm1:amd64 (1:1.1.4-1) ...\n",
      "Setting up libzvbi0:amd64 (0.2.35-13) ...\n",
      "Setting up libsamplerate0:amd64 (0.1.9-1) ...\n",
      "Setting up libsndio6.1:amd64 (1.1.0-3) ...\n",
      "Setting up x11-common (1:7.7+19ubuntu7.1) ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
      "debconf: falling back to frontend: Readline\n",
      "update-rc.d: warning: start and stop actions are no longer supported; falling back to defaults\n",
      "invoke-rc.d: could not determine current runlevel\n",
      "invoke-rc.d: policy-rc.d denied execution of start.\n",
      "Setting up libmpg123-0:amd64 (1.25.10-1) ...\n",
      "Setting up libslang2:amd64 (2.3.1a-3ubuntu1) ...\n",
      "Setting up xdg-user-dirs (0.17-1ubuntu1) ...\n",
      "Setting up libwayland-cursor0:amd64 (1.16.0-1ubuntu1.1~18.04.4) ...\n",
      "Setting up libgsm1:amd64 (1.0.13-4build1) ...\n",
      "Setting up libmysofa0:amd64 (0.6~dfsg0-3+deb10u1build1) ...\n",
      "Setting up libwayland-egl1:amd64 (1.16.0-1ubuntu1.1~18.04.4) ...\n",
      "Setting up libcdio17:amd64 (1.0.0-2ubuntu2) ...\n",
      "Setting up libxrandr2:amd64 (2:1.5.1-1) ...\n",
      "Setting up libdbus-1-3:amd64 (1.12.2-1ubuntu1.4) ...\n",
      "Setting up libwrap0:amd64 (7.6.q-27) ...\n",
      "Setting up libwayland-server0:amd64 (1.16.0-1ubuntu1.1~18.04.4) ...\n",
      "Setting up libwebp6:amd64 (0.6.1-2ubuntu0.18.04.1) ...\n",
      "Setting up libjpeg8:amd64 (8c-2ubuntu8) ...\n",
      "Setting up fontconfig-config (2.12.6-0ubuntu2) ...\n",
      "Setting up libzmq5:amd64 (4.2.5-1ubuntu0.2) ...\n",
      "Setting up libopenmpt0:amd64 (0.3.6-1) ...\n",
      "Setting up libflite1:amd64 (2.1-release-1) ...\n",
      "Setting up libxss1:amd64 (1:1.2.2-1) ...\n",
      "Setting up libharfbuzz0b:amd64 (1.7.2-1ubuntu1) ...\n",
      "Setting up libdc1394-22:amd64 (2.2.5-1) ...\n",
      "Setting up libcdio-cdda2:amd64 (10.2+0.94+2-2build1) ...\n",
      "Setting up libtiff5:amd64 (4.0.9-5ubuntu0.10) ...\n",
      "Setting up libthai0:amd64 (0.1.27-2) ...\n",
      "Setting up libpulse0:amd64 (1:11.1-1ubuntu7.11) ...\n",
      "Setting up libdrm2:amd64 (2.4.101-2~18.04.1) ...\n",
      "Setting up libdrm-intel1:amd64 (2.4.101-2~18.04.1) ...\n",
      "Setting up libxcursor1:amd64 (1:1.1.15-1) ...\n",
      "Setting up librubberband2:amd64 (1.8.1-7ubuntu2) ...\n",
      "Setting up libsdl2-2.0-0:amd64 (2.0.8+dfsg1-1ubuntu1.18.04.4) ...\n",
      "Setting up libwebpmux3:amd64 (0.6.1-2ubuntu0.18.04.1) ...\n",
      "Setting up libcdio-paranoia2:amd64 (10.2+0.94+2-2build1) ...\n",
      "Setting up libva-drm2:amd64 (2.1.0-3) ...\n",
      "Setting up libjack-jackd2-0:amd64 (1.9.12~dfsg-2) ...\n",
      "Setting up libopenal1:amd64 (1:1.18.2-2) ...\n",
      "Setting up libdrm-radeon1:amd64 (2.4.101-2~18.04.1) ...\n",
      "Setting up dbus (1.12.2-1ubuntu1.4) ...\n",
      "Setting up libva-x11-2:amd64 (2.1.0-3) ...\n",
      "Setting up libdrm-nouveau2:amd64 (2.4.101-2~18.04.1) ...\n",
      "Setting up libcaca0:amd64 (0.99.beta19-2ubuntu0.18.04.3) ...\n",
      "Setting up libfontconfig1:amd64 (2.12.6-0ubuntu2) ...\n",
      "Setting up libavutil55:amd64 (7:3.4.11-0ubuntu0.1) ...\n",
      "Setting up libdrm-amdgpu1:amd64 (2.4.101-2~18.04.1) ...\n",
      "Setting up mesa-vdpau-drivers:amd64 (20.0.8-0ubuntu1~18.04.1) ...\n",
      "Setting up libgdk-pixbuf2.0-0:amd64 (2.36.11-2) ...\n",
      "Setting up libgbm1:amd64 (20.0.8-0ubuntu1~18.04.1) ...\n",
      "Setting up libass9:amd64 (1:0.14.0-1) ...\n",
      "Setting up libgl1-mesa-dri:amd64 (20.0.8-0ubuntu1~18.04.1) ...\n",
      "Setting up libgdk-pixbuf2.0-bin (2.36.11-2) ...\n",
      "Setting up libbluray2:amd64 (1:1.0.2-3) ...\n",
      "Setting up libswresample2:amd64 (7:3.4.11-0ubuntu0.1) ...\n",
      "Setting up i965-va-driver:amd64 (2.1.0-0ubuntu1) ...\n",
      "Setting up libswscale4:amd64 (7:3.4.11-0ubuntu0.1) ...\n",
      "Setting up mesa-va-drivers:amd64 (20.0.8-0ubuntu1~18.04.1) ...\n",
      "Setting up libpostproc54:amd64 (7:3.4.11-0ubuntu0.1) ...\n",
      "Setting up libegl-mesa0:amd64 (20.0.8-0ubuntu1~18.04.1) ...\n",
      "Setting up fontconfig (2.12.6-0ubuntu2) ...\n",
      "Regenerating fonts cache... done.\n",
      "Setting up libglx-mesa0:amd64 (20.0.8-0ubuntu1~18.04.1) ...\n",
      "Setting up vdpau-driver-all:amd64 (1.1.1-3ubuntu1) ...\n",
      "Setting up libcairo2:amd64 (1.15.10-2ubuntu0.1) ...\n",
      "Setting up libavresample3:amd64 (7:3.4.11-0ubuntu0.1) ...\n",
      "Setting up libegl1:amd64 (1.0.0-2ubuntu2.3) ...\n",
      "Setting up va-driver-all:amd64 (2.1.0-3) ...\n",
      "Setting up libpango-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
      "Setting up libwayland-egl1-mesa:amd64 (20.0.8-0ubuntu1~18.04.1) ...\n",
      "Setting up libtheora0:amd64 (1.1.1+dfsg.1-14) ...\n",
      "Setting up libglx0:amd64 (1.0.0-2ubuntu2.3) ...\n",
      "Setting up libpangoft2-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
      "Setting up libgl1:amd64 (1.0.0-2ubuntu2.3) ...\n",
      "Setting up libpangocairo-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
      "Setting up librsvg2-2:amd64 (2.40.20-2ubuntu0.2) ...\n",
      "Setting up libavcodec57:amd64 (7:3.4.11-0ubuntu0.1) ...\n",
      "Setting up librsvg2-common:amd64 (2.40.20-2ubuntu0.2) ...\n",
      "Setting up libchromaprint1:amd64 (1.4.3-1) ...\n",
      "Setting up libavformat57:amd64 (7:3.4.11-0ubuntu0.1) ...\n",
      "Setting up libavfilter6:amd64 (7:3.4.11-0ubuntu0.1) ...\n",
      "Setting up libavdevice57:amd64 (7:3.4.11-0ubuntu0.1) ...\n",
      "Setting up ffmpeg (7:3.4.11-0ubuntu0.1) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n",
      "Processing triggers for libgdk-pixbuf2.0-0:amd64 (2.36.11-2) ...\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get update && sudo apt-get install -y ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea0d7b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[debug] System config: []\n",
      "[debug] User config: []\n",
      "[debug] Custom config: []\n",
      "[debug] Command-line args: ['-x', '--audio-format', 'mp3', 'https://www.youtube.com/watch?v=kd-mWl1cq48', '--verbose']\n",
      "[debug] Encodings: locale UTF-8, fs utf-8, out utf-8, pref UTF-8\n",
      "[debug] youtube-dl version 2021.12.17\n",
      "[debug] Python version 3.8.5 (CPython) - Linux-5.15.0-67-generic-x86_64-with-glibc2.10\n",
      "[debug] exe versions: ffmpeg 3.4.11, ffprobe 3.4.11\n",
      "[debug] Proxy map: {}\n",
      "[youtube] kd-mWl1cq48: Downloading webpage\n",
      "[debug] [youtube] Decrypted nsig R7FkS0DqUUvtSIuSJ6 => A0pG-TC5GOfthg\n",
      "[debug] [youtube] Decrypted nsig G3qFj632GywJ-4MPVN => SjWaTPuqOynvRA\n",
      "[debug] Invoking downloader on 'https://rr1---sn-4g5e6ns6.googlevideo.com/videoplayback?expire=1679690552&ei=2LYdZPOnFp7W1wLyy5egBg&ip=62.204.170.174&id=o-AAST0Y3F001Ah469wTR1MOd29ao-5l8dUoPHaBDrGJ3u&itag=140&source=youtube&requiressl=yes&mh=hC&mm=31%2C29&mn=sn-4g5e6ns6%2Csn-4g5edndz&ms=au%2Crdu&mv=m&mvi=1&pl=21&initcwndbps=1952500&vprv=1&mime=audio%2Fmp4&ns=v49V1C7_OU7NH0c3qw3K-awM&gir=yes&clen=27125884&dur=1676.062&lmt=1678595992038346&mt=1679668656&fvip=4&keepalive=yes&fexp=24007246&c=WEB&txp=6211224&n=A0pG-TC5GOfthg&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cvprv%2Cmime%2Cns%2Cgir%2Cclen%2Cdur%2Clmt&sig=AOq0QJ8wRAIfL0zrgY1C3245xeKAVRCjBxy2ylM56Aez5vAz1WcZZAIhAP1J1nwXW4KR2F5iC4K1E8RNdoQNdDOJ2Saz1Vb6xzp3&lsparams=mh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl%2Cinitcwndbps&lsig=AG3C_xAwRgIhAMG0lcRgKzlKyyKaos-3HkE2SjrcIDid0ea_fIf9xZ5aAiEAhgnNa_b7341e6JkOVzj3Tp6N_9r5lUpWZ3xHFZ6Uh5k%3D'\n",
      "[download] Kubeflow 1.1 Community Release Update-kd-mWl1cq48.m4a has already been downloaded\n",
      "\u001b[K[download] 100% of 25.87MiB\n",
      "[ffmpeg] Correcting container in \"Kubeflow 1.1 Community Release Update-kd-mWl1cq48.m4a\"\n",
      "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:Kubeflow 1.1 Community Release Update-kd-mWl1cq48.m4a' -c copy -f mp4 'file:Kubeflow 1.1 Community Release Update-kd-mWl1cq48.temp.m4a'\n",
      "[debug] ffmpeg command line: ffprobe -show_streams 'file:Kubeflow 1.1 Community Release Update-kd-mWl1cq48.m4a'\n",
      "[ffmpeg] Destination: Kubeflow 1.1 Community Release Update-kd-mWl1cq48.mp3\n",
      "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:Kubeflow 1.1 Community Release Update-kd-mWl1cq48.m4a' -vn -acodec libmp3lame -q:a 5 'file:Kubeflow 1.1 Community Release Update-kd-mWl1cq48.mp3'\n",
      "Deleting original file Kubeflow 1.1 Community Release Update-kd-mWl1cq48.m4a (pass -k to keep)\n"
     ]
    }
   ],
   "source": [
    "!youtube-dl -x --audio-format mp3 https://www.youtube.com/watch\\?v\\=kd-mWl1cq48 --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53dc8628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/ray/anaconda3/lib/python3.8/site-packages (4.21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ray/anaconda3/lib/python3.8/site-packages (from transformers) (4.63.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ray/anaconda3/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ray/anaconda3/lib/python3.8/site-packages (from transformers) (1.23.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: requests in /home/ray/anaconda3/lib/python3.8/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ray/anaconda3/lib/python3.8/site-packages (from transformers) (2022.9.13)\n",
      "Requirement already satisfied: filelock in /home/ray/anaconda3/lib/python3.8/site-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/ray/anaconda3/lib/python3.8/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ray/anaconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ray/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ray/anaconda3/lib/python3.8/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ray/anaconda3/lib/python3.8/site-packages (from requests->transformers) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ray/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ray/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8573045f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-2.10.1-py3-none-any.whl (469 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting xxhash\n",
      "  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m213.0/213.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multiprocess\n",
      "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m132.0/132.0 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (2022.7.1)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (2.25.1)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (0.3.5.1)\n",
      "Requirement already satisfied: packaging in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (21.3)\n",
      "Collecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (0.13.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (5.4.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (4.63.0)\n",
      "Requirement already satisfied: pandas in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (1.23.2)\n",
      "Requirement already satisfied: filelock in /home/ray/anaconda3/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ray/anaconda3/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ray/anaconda3/lib/python3.8/site-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ray/anaconda3/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2022.6.15)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ray/anaconda3/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ray/anaconda3/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ray/anaconda3/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.26.8)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ray/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ray/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ray/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ray/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Collecting dill<0.3.7,>=0.3.0\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /home/ray/anaconda3/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ray/anaconda3/lib/python3.8/site-packages (from pandas->datasets) (2022.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ray/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.13.0)\n",
      "Installing collected packages: xxhash, dill, responses, multiprocess, datasets\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.5.1\n",
      "    Uninstalling dill-0.3.5.1:\n",
      "      Successfully uninstalled dill-0.3.5.1\n",
      "Successfully installed datasets-2.10.1 dill-0.3.6 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c69094f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10207464",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63b5a40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: soundfile in /home/ray/anaconda3/lib/python3.8/site-packages (0.12.1)\n",
      "Collecting librosa\n",
      "  Downloading librosa-0.10.0.post2-py3-none-any.whl (253 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cffi>=1.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from soundfile) (1.15.0)\n",
      "Collecting lazy-loader>=0.1\n",
      "  Downloading lazy_loader-0.2-py3-none-any.whl (8.6 kB)\n",
      "Collecting audioread>=2.1.9\n",
      "  Downloading audioread-3.0.0.tar.gz (377 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m377.0/377.0 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: decorator>=4.3.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /home/ray/anaconda3/lib/python3.8/site-packages (from librosa) (4.3.0)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from librosa) (1.9.0)\n",
      "Collecting soxr>=0.3.2\n",
      "  Downloading soxr-0.3.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from librosa) (1.1.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /home/ray/anaconda3/lib/python3.8/site-packages (from librosa) (1.2.0)\n",
      "Collecting pooch<1.7,>=1.0\n",
      "  Downloading pooch-1.6.0-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m56.3/56.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /home/ray/anaconda3/lib/python3.8/site-packages (from librosa) (1.23.2)\n",
      "Collecting numba>=0.51.0\n",
      "  Downloading numba-0.56.4-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: msgpack>=1.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from librosa) (1.0.4)\n",
      "Requirement already satisfied: pycparser in /home/ray/anaconda3/lib/python3.8/site-packages (from cffi>=1.0->soundfile) (2.21)\n",
      "Collecting llvmlite<0.40,>=0.39.0dev0\n",
      "  Downloading llvmlite-0.39.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.6 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m34.6/34.6 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /home/ray/anaconda3/lib/python3.8/site-packages (from numba>=0.51.0->librosa) (63.4.1)\n",
      "Requirement already satisfied: importlib-metadata in /home/ray/anaconda3/lib/python3.8/site-packages (from numba>=0.51.0->librosa) (4.12.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from pooch<1.7,>=1.0->librosa) (2.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from pooch<1.7,>=1.0->librosa) (21.3)\n",
      "Collecting appdirs>=1.3.0\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.20.0->librosa) (3.1.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ray/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->pooch<1.7,>=1.0->librosa) (3.0.9)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ray/anaconda3/lib/python3.8/site-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ray/anaconda3/lib/python3.8/site-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ray/anaconda3/lib/python3.8/site-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2022.6.15)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ray/anaconda3/lib/python3.8/site-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2.10)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ray/anaconda3/lib/python3.8/site-packages (from importlib-metadata->numba>=0.51.0->librosa) (3.8.1)\n",
      "Building wheels for collected packages: audioread\n",
      "  Building wheel for audioread (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for audioread: filename=audioread-3.0.0-py3-none-any.whl size=23703 sha256=98b36a2a31d587424743d63d657c556163310edd4131b72857ec0c86c19a0e2b\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/74/25/48/ad94b69151b78e9aeba6850da119f04eda1c811d22fcf4b32d\n",
      "Successfully built audioread\n",
      "Installing collected packages: appdirs, soxr, llvmlite, lazy-loader, audioread, pooch, numba, librosa\n",
      "Successfully installed appdirs-1.4.4 audioread-3.0.0 lazy-loader-0.2 librosa-0.10.0.post2 llvmlite-0.39.1 numba-0.56.4 pooch-1.6.0 soxr-0.3.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install soundfile librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb9bf397",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading ()rocessor_config.json: 100%|| 185k/185k [00:00<00:00, 576kB/s]\n",
      "Downloading ()okenizer_config.json: 100%|| 842/842 [00:00<00:00, 102kB/s]\n",
      "Downloading ()olve/main/vocab.json: 100%|| 1.04M/1.04M [00:00<00:00, 1.86MB/s]\n",
      "Downloading ()/main/tokenizer.json: 100%|| 2.20M/2.20M [00:00<00:00, 2.83MB/s]\n",
      "Downloading ()olve/main/merges.txt: 100%|| 494k/494k [00:00<00:00, 1.11MB/s]\n",
      "Downloading ()main/normalizer.json: 100%|| 52.7k/52.7k [00:00<00:00, 478kB/s]\n",
      "Downloading ()in/added_tokens.json: 100%|| 2.08k/2.08k [00:00<00:00, 1.14MB/s]\n",
      "Downloading ()cial_tokens_map.json: 100%|| 2.08k/2.08k [00:00<00:00, 897kB/s]\n",
      "Downloading ()lve/main/config.json: 100%|| 1.93k/1.93k [00:00<00:00, 274kB/s]\n",
      "Downloading pytorch_model.bin: 100%|| 6.17G/6.17G [01:04<00:00, 95.1MB/s]\n",
      "Downloading ()neration_config.json: 100%|| 3.49k/3.49k [00:00<00:00, 513kB/s]\n",
      "Downloading builder script: 100%|| 5.17k/5.17k [00:00<00:00, 2.31MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset librispeech_asr_dummy/clean to /home/jovyan/.cache/huggingface/datasets/hf-internal-testing___librispeech_asr_dummy/clean/2.1.0/d3bc4c2bc2078fcde3ad0f0f635862e4c0fef78ba94c4a34c4c250a097af240b...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Downloading data:   0%|          | 0.00/9.08M [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data:   0%|          | 2.05k/9.08M [00:00<07:37, 19.8kB/s]\u001b[A\n",
      "Downloading data:   1%|          | 52.2k/9.08M [00:00<00:31, 287kB/s] \u001b[A\n",
      "Downloading data:   1%|          | 104k/9.08M [00:00<00:23, 378kB/s] \u001b[A\n",
      "Downloading data:   3%|         | 244k/9.08M [00:00<00:11, 740kB/s]\u001b[A\n",
      "Downloading data:   6%|         | 522k/9.08M [00:00<00:06, 1.41MB/s]\u001b[A\n",
      "Downloading data:  12%|        | 1.06M/9.08M [00:00<00:03, 2.63MB/s]\u001b[A\n",
      "Downloading data:  24%|       | 2.17M/9.08M [00:00<00:01, 5.12MB/s]\u001b[A\n",
      "Downloading data:  48%|     | 4.34M/9.08M [00:00<00:00, 9.93MB/s]\u001b[A\n",
      "Downloading data: 100%|| 9.08M/9.08M [00:00<00:00, 9.10MB/s]\u001b[A\n",
      "Downloading data files: 100%|| 1/1 [00:01<00:00,  1.95s/it]\n",
      "Extracting data files: 100%|| 1/1 [00:00<00:00, 24.09it/s]\n",
      "Generating validation split: 0 examples [00:00, ? examples/s]"
     ]
    },
    {
     "ename": "DatasetGenerationError",
     "evalue": "An error occurred while generating the dataset",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/home/ray/anaconda3/lib/python3.8/site-packages/datasets/features/audio.py:92\u001b[0m, in \u001b[0;36mAudio.encode_example\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msoundfile\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msf\u001b[39;00m  \u001b[38;5;66;03m# soundfile is a dependency of librosa, needed to decode audio files.\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'soundfile'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/home/ray/anaconda3/lib/python3.8/site-packages/datasets/builder.py:1625\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._prepare_split_single\u001b[0;34m(self, gen_kwargs, fpath, file_format, max_shard_size, split_info, check_duplicate_keys, job_id)\u001b[0m\n\u001b[1;32m   1616\u001b[0m     writer \u001b[38;5;241m=\u001b[39m writer_class(\n\u001b[1;32m   1617\u001b[0m         features\u001b[38;5;241m=\u001b[39mwriter\u001b[38;5;241m.\u001b[39m_features,\n\u001b[1;32m   1618\u001b[0m         path\u001b[38;5;241m=\u001b[39mfpath\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSSSSS\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshard_id\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m05d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJJJJJ\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob_id\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m05d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1623\u001b[0m         embed_local_files\u001b[38;5;241m=\u001b[39membed_local_files,\n\u001b[1;32m   1624\u001b[0m     )\n\u001b[0;32m-> 1625\u001b[0m example \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m record\n\u001b[1;32m   1626\u001b[0m writer\u001b[38;5;241m.\u001b[39mwrite(example, key)\n",
      "File \u001b[0;32m/home/ray/anaconda3/lib/python3.8/site-packages/datasets/features/features.py:1809\u001b[0m, in \u001b[0;36mFeatures.encode_example\u001b[0;34m(self, example)\u001b[0m\n\u001b[1;32m   1808\u001b[0m example \u001b[38;5;241m=\u001b[39m cast_to_python_objects(example)\n\u001b[0;32m-> 1809\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mencode_nested_example\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/ray/anaconda3/lib/python3.8/site-packages/datasets/features/features.py:1212\u001b[0m, in \u001b[0;36mencode_nested_example\u001b[0;34m(schema, obj, level)\u001b[0m\n\u001b[1;32m   1210\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot None but expected a dictionary instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m-> 1212\u001b[0m         {\n\u001b[1;32m   1213\u001b[0m             k: encode_nested_example(sub_schema, sub_obj, level\u001b[38;5;241m=\u001b[39mlevel \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   1214\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m k, (sub_schema, sub_obj) \u001b[38;5;129;01min\u001b[39;00m zip_dict(schema, obj)\n\u001b[1;32m   1215\u001b[0m         }\n\u001b[1;32m   1216\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m     )\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(schema, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n",
      "File \u001b[0;32m/home/ray/anaconda3/lib/python3.8/site-packages/datasets/features/features.py:1213\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1210\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot None but expected a dictionary instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m   1212\u001b[0m         {\n\u001b[0;32m-> 1213\u001b[0m             k: \u001b[43mencode_nested_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_schema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1214\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m k, (sub_schema, sub_obj) \u001b[38;5;129;01min\u001b[39;00m zip_dict(schema, obj)\n\u001b[1;32m   1215\u001b[0m         }\n\u001b[1;32m   1216\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m     )\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(schema, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n",
      "File \u001b[0;32m/home/ray/anaconda3/lib/python3.8/site-packages/datasets/features/features.py:1267\u001b[0m, in \u001b[0;36mencode_nested_example\u001b[0;34m(schema, obj, level)\u001b[0m\n\u001b[1;32m   1266\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(schema, (Audio, Image, ClassLabel, TranslationVariableLanguages, Value, _ArrayXD)):\n\u001b[0;32m-> 1267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1268\u001b[0m \u001b[38;5;66;03m# Other object should be directly convertible to a native Arrow type (like Translation and Translation)\u001b[39;00m\n",
      "File \u001b[0;32m/home/ray/anaconda3/lib/python3.8/site-packages/datasets/features/audio.py:94\u001b[0m, in \u001b[0;36mAudio.encode_example\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo support encoding audio data, please install \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoundfile\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[0;31mImportError\u001b[0m: To support encoding audio data, please install 'soundfile'.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDatasetGenerationError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mforced_decoder_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# load dummy dataset and read audio files\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhf-internal-testing/librispeech_asr_dummy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalidation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m sample \u001b[38;5;241m=\u001b[39m ds[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     15\u001b[0m input_features \u001b[38;5;241m=\u001b[39m processor(sample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m], sampling_rate\u001b[38;5;241m=\u001b[39msample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msampling_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m], return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39minput_features \n",
      "File \u001b[0;32m/home/ray/anaconda3/lib/python3.8/site-packages/datasets/load.py:1782\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, use_auth_token, task, streaming, num_proc, **config_kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m try_from_hf_gcs \u001b[38;5;241m=\u001b[39m path \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _PACKAGED_DATASETS_MODULES\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# Download and prepare data\u001b[39;00m\n\u001b[0;32m-> 1782\u001b[0m \u001b[43mbuilder_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_from_hf_gcs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtry_from_hf_gcs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1788\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;66;03m# Build dataset for splits\u001b[39;00m\n\u001b[1;32m   1791\u001b[0m keep_in_memory \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1792\u001b[0m     keep_in_memory \u001b[38;5;28;01mif\u001b[39;00m keep_in_memory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m is_small_dataset(builder_instance\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size)\n\u001b[1;32m   1793\u001b[0m )\n",
      "File \u001b[0;32m/home/ray/anaconda3/lib/python3.8/site-packages/datasets/builder.py:872\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[0;34m(self, output_dir, download_config, download_mode, verification_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_proc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         prepare_split_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_proc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_proc\n\u001b[0;32m--> 872\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdownload_and_prepare_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# Sync info\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(split\u001b[38;5;241m.\u001b[39mnum_bytes \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39msplits\u001b[38;5;241m.\u001b[39mvalues())\n",
      "File \u001b[0;32m/home/ray/anaconda3/lib/python3.8/site-packages/datasets/builder.py:1649\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_splits_kwargs)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_download_and_prepare\u001b[39m(\u001b[38;5;28mself\u001b[39m, dl_manager, verification_mode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprepare_splits_kwargs):\n\u001b[0;32m-> 1649\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1652\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_duplicate_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mVerificationMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBASIC_CHECKS\u001b[49m\n\u001b[1;32m   1653\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mVerificationMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mALL_CHECKS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1654\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprepare_splits_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1655\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/ray/anaconda3/lib/python3.8/site-packages/datasets/builder.py:967\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m split_dict\u001b[38;5;241m.\u001b[39madd(split_generator\u001b[38;5;241m.\u001b[39msplit_info)\n\u001b[1;32m    965\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;66;03m# Prepare split will record examples associated to the split\u001b[39;00m\n\u001b[0;32m--> 967\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    969\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m    970\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot find data file. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    971\u001b[0m         \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanual_download_instructions \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    972\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mOriginal error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    973\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[1;32m    974\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "File \u001b[0;32m/home/ray/anaconda3/lib/python3.8/site-packages/datasets/builder.py:1488\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._prepare_split\u001b[0;34m(self, split_generator, check_duplicate_keys, file_format, num_proc, max_shard_size)\u001b[0m\n\u001b[1;32m   1486\u001b[0m gen_kwargs \u001b[38;5;241m=\u001b[39m split_generator\u001b[38;5;241m.\u001b[39mgen_kwargs\n\u001b[1;32m   1487\u001b[0m job_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1488\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m job_id, done, content \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_split_single(\n\u001b[1;32m   1489\u001b[0m     gen_kwargs\u001b[38;5;241m=\u001b[39mgen_kwargs, job_id\u001b[38;5;241m=\u001b[39mjob_id, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_prepare_split_args\n\u001b[1;32m   1490\u001b[0m ):\n\u001b[1;32m   1491\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[1;32m   1492\u001b[0m         result \u001b[38;5;241m=\u001b[39m content\n",
      "File \u001b[0;32m/home/ray/anaconda3/lib/python3.8/site-packages/datasets/builder.py:1644\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._prepare_split_single\u001b[0;34m(self, gen_kwargs, fpath, file_format, max_shard_size, split_info, check_duplicate_keys, job_id)\u001b[0m\n\u001b[1;32m   1642\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, SchemaInferenceError) \u001b[38;5;129;01mand\u001b[39;00m e\u001b[38;5;241m.\u001b[39m__context__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1643\u001b[0m         e \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39m__context__\n\u001b[0;32m-> 1644\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetGenerationError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while generating the dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1646\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m job_id, \u001b[38;5;28;01mTrue\u001b[39;00m, (total_num_examples, total_num_bytes, writer\u001b[38;5;241m.\u001b[39m_features, num_shards, shard_lengths)\n",
      "\u001b[0;31mDatasetGenerationError\u001b[0m: An error occurred while generating the dataset"
     ]
    }
   ],
   "source": [
    "# load model and processor\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-large\")\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd9aed60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset librispeech_asr_dummy (/home/jovyan/.cache/huggingface/datasets/hf-internal-testing___librispeech_asr_dummy/clean/2.1.0/d3bc4c2bc2078fcde3ad0f0f635862e4c0fef78ba94c4a34c4c250a097af240b)\n",
      "/home/ray/anaconda3/lib/python3.8/site-packages/transformers/generation/utils.py:1288: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.config.forced_decoder_ids = None\n",
    "\n",
    "# load dummy dataset and read audio files\n",
    "\n",
    "ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "\n",
    "sample = ds[0][\"audio\"]\n",
    "\n",
    "input_features = processor(sample[\"array\"], sampling_rate=sample[\"sampling_rate\"], return_tensors=\"pt\").input_features \n",
    "\n",
    "# generate token ids\n",
    "\n",
    "predicted_ids = model.generate(input_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "389e670c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|startoftranscript|><|en|><|transcribe|><|notimestamps|> Mr. Quilter is the apostle of the middle classes and we are glad to welcome his gospel.<|endoftext|>']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.batch_decode(predicted_ids, skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "969b8899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Mr. Quilter is the apostle of the middle classes and we are glad to welcome his gospel.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.batch_decode(predicted_ids, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "801810ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "When passing a dictionary to AutomaticSpeechRecognitionPipeline, the dict needs to contain a \"raw\" key containing the numpy array representing the audio and a \"sampling_rate\" key, containing the sampling_rate associated with that array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[1;32m      3\u001b[0m transcriber \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautomatic-speech-recognition\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai/whisper-large\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtranscriber\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/ray/anaconda3/lib/python3.8/site-packages/transformers/pipelines/automatic_speech_recognition.py:272\u001b[0m, in \u001b[0;36mAutomaticSpeechRecognitionPipeline.__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    227\u001b[0m     inputs: Union[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    229\u001b[0m ):\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;124;03m    Transcribe the audio sequence(s) given as inputs to text. See the [`AutomaticSpeechRecognitionPipeline`]\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;124;03m    documentation for more information.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03m                    `\"\".join(chunk[\"text\"] for chunk in output[\"chunks\"])`.\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/ray/anaconda3/lib/python3.8/site-packages/transformers/pipelines/base.py:1101\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ChunkPipeline):\n\u001b[0;32m-> 1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_iterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\n\u001b[1;32m   1105\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[0;32m/home/ray/anaconda3/lib/python3.8/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m/home/ray/anaconda3/lib/python3.8/site-packages/transformers/pipelines/pt_utils.py:266\u001b[0m, in \u001b[0;36mPipelinePackIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m accumulator\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last:\n\u001b[0;32m--> 266\u001b[0m     processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed, torch\u001b[38;5;241m.\u001b[39mTensor):\n",
      "File \u001b[0;32m/home/ray/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/home/ray/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/home/ray/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:32\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 32\u001b[0m         data\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_iter\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/home/ray/anaconda3/lib/python3.8/site-packages/transformers/pipelines/pt_utils.py:183\u001b[0m, in \u001b[0;36mPipelineChunkIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubiterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;66;03m# Try to return next item\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m     processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubiterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# When a preprocess iterator ends, we can start lookig at the next item\u001b[39;00m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;66;03m# ChunkIterator will keep feeding until ALL elements of iterator\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;66;03m# Another way to look at it, is we're basically flattening lists of lists\u001b[39;00m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;66;03m# into a single list, but with generators\u001b[39;00m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubiterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n",
      "File \u001b[0;32m/home/ray/anaconda3/lib/python3.8/site-packages/transformers/pipelines/automatic_speech_recognition.py:336\u001b[0m, in \u001b[0;36mAutomaticSpeechRecognitionPipeline.preprocess\u001b[0;34m(self, inputs, chunk_length_s, stride_length_s, ignore_warning)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;66;03m# Accepting `\"array\"` which is the key defined in `datasets` for\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;66;03m# better integration\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msampling_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inputs \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inputs \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inputs)):\n\u001b[0;32m--> 336\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    337\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen passing a dictionary to AutomaticSpeechRecognitionPipeline, the dict needs to contain a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    338\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m key containing the numpy array representing the audio and a \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msampling_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m key, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    339\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontaining the sampling_rate associated with that array\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    340\u001b[0m     )\n\u001b[1;32m    342\u001b[0m _inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;66;03m# Remove path which will not be used from `datasets`.\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: When passing a dictionary to AutomaticSpeechRecognitionPipeline, the dict needs to contain a \"raw\" key containing the numpy array representing the audio and a \"sampling_rate\" key, containing the sampling_rate associated with that array"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eefd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89541560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ' Mr. Quilter is the apostle of the middle classes and we are glad to welcome his gospel.'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = ds[0][\"audio\"]\n",
    "transcriber(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4075c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb50a061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = ds[0][\"audio\"]\n",
    "type(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f7943aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'path': '/home/jovyan/.cache/huggingface/datasets/downloads/extracted/b4d8c39110b7503324cb12b1fc45eb98af56216dfebbfb9dffc303cdc4fd8206/dev_clean/1272/128104/1272-128104-0000.flac', 'array': array([0.00238037, 0.0020752 , 0.00198364, ..., 0.00042725, 0.00057983,\n",
      "       0.0010376 ], dtype=float32), 'sampling_rate': 16000}\n"
     ]
    }
   ],
   "source": [
    "print (sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c079262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytube==12.1.2 in /home/ray/anaconda3/lib/python3.8/site-packages (12.1.2)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement as (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for as\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pytube==12.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8540a5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytube as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e7416b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e10f23bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "pipe = pipeline(\n",
    "  \"automatic-speech-recognition\",\n",
    "  model=\"openai/whisper-large\",\n",
    "  chunk_length_s=30,\n",
    "  device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5cbe4463",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ray/anaconda3/lib/python3.8/site-packages/transformers/generation/utils.py:1288: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "yt_url = 'https://www.youtube.com/watch?v=kd-mWl1cq48'\n",
    "yt = pt.YouTube(yt_url)\n",
    "stream = yt.streams.filter(only_audio=True)[0]\n",
    "stream.download(filename=\"audio.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "71b30303",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ray/anaconda3/lib/python3.8/site-packages/transformers/generation/utils.py:1288: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "text = pipe(\"audio.mp3\", return_timestamps=True)[\"chunks\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b350ee53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'timestamp': (0.0, 9.44), 'text': \" Hello and welcome to Kubeflow update. We're going to give a Kubeflow update on the 1.1 release.\"}, {'timestamp': (9.44, 17.12), 'text': ' And I am Josh Bottom and I am part of the Kubeflow Community Product Management team.'}, {'timestamp': (18.96, 28.8), 'text': ' Kubeflow 1.1 has included several community deliveries and And in this portion, we are going to review'}, {'timestamp': (28.8, 31.4), 'text': ' the applications that have been completed,'}, {'timestamp': (31.4, 34.64), 'text': ' which finished up in August 2020.'}, {'timestamp': (35.66, 40.48), 'text': ' And in this release, we worked hard to follow the process'}, {'timestamp': (40.48, 44.76), 'text': \" that we've defined, which really came and fermented\"}, {'timestamp': (44.76, 47.0), 'text': ' around Kubeflow 1.0.'}, {'timestamp': (47.0, 54.0), 'text': ' And that includes using the Kubeflow and application roadmaps to define features in timing for releases,'}, {'timestamp': (54.0, 65.0), 'text': ' as well as the Kubeflow versioning policy, which defines the maturity level of the components, either stableava, Stable, Beta or Alpha.'}, {'timestamp': (65.64, 68.26), 'text': ' And for the Stable requirements,'}, {'timestamp': (68.26, 72.0), 'text': \" we've defined an applications requirement template,\"}, {'timestamp': (72.0, 74.9), 'text': ' or excuse me, applications requirements template,'}, {'timestamp': (74.9, 78.88), 'text': ' which gives a set of requirements that we expect folks'}, {'timestamp': (78.88, 83.12), 'text': \" to follow when they're creating a Stable version\"}, {'timestamp': (83.12, 85.0), 'text': ' of one of the components.'}, {'timestamp': (85.08, 89.76), 'text': \" We're tracking and have tracked the release of 1.1\"}, {'timestamp': (89.76, 93.32), 'text': ' in the Kanban board using this project here,'}, {'timestamp': (93.32, 97.54), 'text': ' which is just clickable, as well as this issue 5022.'}, {'timestamp': (97.54, 99.66), 'text': ' So both those are clickable and you can go through'}, {'timestamp': (99.66, 101.48), 'text': ' and look at where the progress is.'}, {'timestamp': (102.36, 107.36), 'text': ' In 1.1, you can see we made additional components stable,'}, {'timestamp': (108.5, 110.3), 'text': ' including Kubeflow pipelines,'}, {'timestamp': (110.3, 115.3), 'text': ' training operators for XGBoost and Fairen MXNet,'}, {'timestamp': (116.14, 118.7), 'text': ' and as well as the Fairen component.'}, {'timestamp': (118.7, 120.98), 'text': ' This is in addition to all the components'}, {'timestamp': (120.98, 128.08), 'text': ' that we have made stable in the March portion, the March release of Kubeflow 1.0.'}, {'timestamp': (128.72, 133.2), 'text': ' And you can see all the roadmaps for the different components that are posted'}, {'timestamp': (134.16, 141.12), 'text': ' over here in these clickable links. Kubeflow 1.1 has six major deliveries,'}, {'timestamp': (141.76, 145.68), 'text': ' and those include simplifying pipeline building workflows, so that includes'}, {'timestamp': (145.68, 152.6), 'text': ' build, train and tune as well as deploy from a notebook. Production operations and performance'}, {'timestamp': (152.6, 161.2), 'text': ' for MXNet and XGBoost distributed model training. Improved user isolation, security and administration,'}, {'timestamp': (161.2, 167.0), 'text': ' including multi-user pipelines. Improved model tuning with new frameworks and algorithms,'}, {'timestamp': (167.0, 171.0), 'text': ' as well as flexible configuration and tuning options.'}, {'timestamp': (171.0, 188.66), 'text': \" GitOps foundations for installation, configuration, and management, in some cases even upgrades, upgrades as well as easier QPLO blog posting via a fast I process that we'll talk about\"}, {'timestamp': (188.66, 190.2), 'text': ' here a little later.'}, {'timestamp': (190.2, 192.84), 'text': \" So now we're going to dive into the details.\"}, {'timestamp': (192.84, 197.8), 'text': \" In this first section we'll have Jingxi go over the fairing CUJ.\"}, {'timestamp': (197.8, 200.12), 'text': ' Jingxi, over to you.'}, {'timestamp': (200.12, 201.52), 'text': ' Hello everyone.'}, {'timestamp': (201.52, 205.0), 'text': ' So let me update the KuboFlow Firmware.'}, {'timestamp': (205.0, 216.0), 'text': ' So you know KuboFlow Firmware is a PANZ SDK that can help users to process your training code and build a doc image,'}, {'timestamp': (216.0, 226.96), 'text': ' and then deploy a job, gift job, or pet horse job to train your code and then you can use the file to public service.'}, {'timestamp': (226.96, 231.2), 'text': ' Of course, file support to public service by ksv.'}, {'timestamp': (231.2, 236.64), 'text': ' So this release we get a stable release for kubeflow file.'}, {'timestamp': (236.64, 248.94), 'text': ' So first item is that we improved the file quality in this release. And we fixed the sub-bugs and enhanced the testing'}, {'timestamp': (248.94, 253.36), 'text': ' and example under the kuboflow-finr wrapper.'}, {'timestamp': (253.36, 257.68), 'text': ' And the next one is we enhanced the API document.'}, {'timestamp': (257.68, 260.96), 'text': ' As you know, Finr has a lot of API'}, {'timestamp': (260.96, 264.82), 'text': ' and if there is no API document,'}, {'timestamp': (264.82, 268.08), 'text': ' that is very bad for the end user. So this release'}, {'timestamp': (268.8, 278.88), 'text': ' we take some effort to work on the API document enhancement. The next one is we made some'}, {'timestamp': (278.88, 287.9), 'text': ' generator function to interact with Kubernetes. So this function supports applying'}, {'timestamp': (287.9, 296.68), 'text': ' the backend spec to the Kubernetes cluster. Next one, we support one more'}, {'timestamp': (296.68, 309.84), 'text': ' build such as Podman and also support one more backend such as AmiCloud. And the next one is this release, family support'}, {'timestamp': (309.84, 318.16), 'text': \" config environment variables for deployment. That's very important for ad users. So you know\"}, {'timestamp': (319.04, 324.88), 'text': ' from this feature user can configure their environment variables for the deployment.'}, {'timestamp': (326.08, 333.0), 'text': ' user can configure their environment variables for the deployment. And also this release, FanRee supports two mountain volumes such as the PVC,'}, {'timestamp': (333.0, 337.04), 'text': ' CRID, and the config map for the deployer.'}, {'timestamp': (337.04, 344.4), 'text': ' So in one word, FanRee get stable release, so you can try the new FanRee release.'}, {'timestamp': (344.4, 348.08), 'text': ' Thank you.'}, {'timestamp': (353.24, 358.96), 'text': \" Okay. Thanks, Jiushi. Now we'll pass it over to Constantinos to talk about the KLCUJ. Constantinos? Hello, everyone. This is Constantinos from\"}, {'timestamp': (358.96, 366.04), 'text': ' Oricto. During the 1.1 release cycle, we made some significant improvements also to'}, {'timestamp': (366.04, 371.92), 'text': ' the end-to-end customer user journey for building, training, tuning and debugging'}, {'timestamp': (371.92, 376.48), 'text': \" models faster with Kailh. For those who don't know what Kailh is, Kailh is an\"}, {'timestamp': (376.48, 387.28), 'text': ' open source workflow tool on top of Kubeflow that allows you to build pipelines directly from your code in a notebook or your IDE,'}, {'timestamp': (387.28, 396.64), 'text': ' for example, VS Code. To do that, it comes as a JupyterLab extension or an SDK. So you'}, {'timestamp': (396.64, 404.48), 'text': ' simply tag a cell with your remote code via the UI to create a pipeline step. And with'}, {'timestamp': (404.48, 406.66), 'text': ' one click, Kailh snapshots the environment, builds and runs a pipeline step and with one click Kailh snapshots the environment'}, {'timestamp': (406.66, 412.1), 'text': ' builds and runs a pipeline without the need to write any'}, {'timestamp': (412.1, 420.3), 'text': ' Kubeflow pipelines DSL code or build any Docker images. So with 1.1 Kailh now'}, {'timestamp': (420.3, 425.0), 'text': ' supports HP tuning with the Kativep component of Kubeflow.'}, {'timestamp': (425.98, 430.98), 'text': ' So now you can tag shells to define hyperparameters'}, {'timestamp': (431.06, 433.5), 'text': ' and then set HP tuning job parameters'}, {'timestamp': (433.5, 437.9), 'text': ' all from a user interface, then starts the cattyp job.'}, {'timestamp': (437.9, 439.58), 'text': ' You can easily view the results'}, {'timestamp': (439.58, 443.18), 'text': ' and dig into the details provided by the pipeline runs.'}, {'timestamp': (443.18, 448.2), 'text': ' And it also comes with support for pipeline step caching'}, {'timestamp': (449.2, 452.66), 'text': ' that allows you to scale very efficiently.'}, {'timestamp': (453.7, 455.16), 'text': ' You can follow the links.'}, {'timestamp': (455.16, 460.16), 'text': ' We have an end-to-end tutorial that you can follow through'}, {'timestamp': (460.28, 463.4), 'text': ' and a video showcasing the end-to-end workflow.'}, {'timestamp': (463.4, 466.2), 'text': ' With that, back to you, Josh.'}, {'timestamp': (466.2, 468.0), 'text': ' Thanks, Carlos.'}, {'timestamp': (468.0, 471.96), 'text': \" Now we'll go to the distributed training operators.\"}, {'timestamp': (471.96, 473.4), 'text': ' Hi, everyone.'}, {'timestamp': (473.4, 476.44), 'text': ' This is Jiaxin from AWS.'}, {'timestamp': (476.44, 479.88), 'text': ' So I will give some updates on the training operators.'}, {'timestamp': (479.88, 483.4), 'text': ' In 1.1 release, community concentrate more'}, {'timestamp': (483.4, 489.0), 'text': ' on the reusability, performance, and maintainability of the training operators.'}, {'timestamp': (489.0, 494.0), 'text': ' The most important change is we released a stable Kubeflow common library.'}, {'timestamp': (494.0, 497.0), 'text': ' So some users may not have contacts of this library.'}, {'timestamp': (497.0, 505.84), 'text': ' As we know, Kubeflow has many distributed training operators and most of them have similar designs and implementations.'}, {'timestamp': (506.4, 513.76), 'text': ' So in mid 2019 we started Coolflow Common Projects, aims to extract those common reconciler'}, {'timestamp': (513.76, 519.92), 'text': ' logics and CRD types to make sure they can be reused in different training operators.'}, {'timestamp': (520.72, 529.0), 'text': ' Ideally we can add like generic logics and bug fixes in the Coolflow Common project.'}, {'timestamp': (529.0, 537.0), 'text': ' Different operators just need to upgrade common dependencies to leverage these benefits and new changes.'}, {'timestamp': (537.0, 545.4), 'text': ' In the latest stable version, it starts to support Volcano Batch Scheder, which is the main down'}, {'timestamp': (545.4, 547.28), 'text': ' scheduler offering in the community.'}, {'timestamp': (547.8, 552.56), 'text': ' It also provides the flexible interface to support like both'}, {'timestamp': (552.56, 555.44), 'text': ' informer and computer based operators.'}, {'timestamp': (556.12, 559.36), 'text': ' The app grades the dependency versions like Kubernetes,'}, {'timestamp': (559.56, 564.28), 'text': ' controller runtime, controller tools and refactor the codes to'}, {'timestamp': (564.28, 566.16), 'text': ' enhance the maintainability.'}, {'timestamp': (566.56, 570.92), 'text': ' So one last important feature is like common controller reconciles the'}, {'timestamp': (570.92, 575.36), 'text': ' workers scale down events to support dynamic or elastic training.'}, {'timestamp': (575.68, 579.6), 'text': ' So that means the number of the workers can be changed during the training.'}, {'timestamp': (579.96, 583.52), 'text': ' If the framework has the support like a torch elastic.'}, {'timestamp': (584.58, 588.64), 'text': ' if the framework has the support like torch elastic. Currently we have migrated TensorFlow, MXNet,'}, {'timestamp': (588.64, 592.14), 'text': ' XGBoost implementations to this fashion'}, {'timestamp': (592.14, 594.76), 'text': ' and PyTorch is in progress.'}, {'timestamp': (594.76, 598.12), 'text': ' The major user facing changes are MXNet,'}, {'timestamp': (598.12, 603.12), 'text': ' XGBoost and MPI operators both support V1 APIs.'}, {'timestamp': (603.46, 607.76), 'text': ' Most of the work to graduate to V1 has been done.'}, {'timestamp': (607.76, 610.52), 'text': \" However, we haven't officially claimed there are V1\"}, {'timestamp': (610.52, 614.48), 'text': ' because we want to do more scale and performance testing.'}, {'timestamp': (614.48, 619.1), 'text': ' User can use V1 API now and report issues to us.'}, {'timestamp': (620.44, 623.08), 'text': ' We have a few features and improvement plans'}, {'timestamp': (623.08, 624.72), 'text': ' in the roadmap doc.'}, {'timestamp': (624.72, 626.14), 'text': ' So feel free to take a look'}, {'timestamp': (626.3, 630.8), 'text': \" Yeah, that's all the updates from training operator side. Thank you\"}, {'timestamp': (631.86, 635.02), 'text': ' And now for the multi-user pipeline update'}, {'timestamp': (636.98, 638.86), 'text': ' Thank You Josh'}, {'timestamp': (638.86, 640.86), 'text': ' for cute little pipelines'}, {'timestamp': (641.14, 646.0), 'text': ' Now in cute for one point one, the most important thing is that'}, {'timestamp': (646.0, 653.0), 'text': \" Pipelines is now reaching 1.0 release, so it's becoming another stable component in Kubeflow.\"}, {'timestamp': (653.0, 661.0), 'text': ' The biggest feature in this release is multi-user support in Kubeflow Pipelines'}, {'timestamp': (661.0, 671.84), 'text': ' without needing to run multiple deployments. So basically, Kubeflow pipelines resources are separated by namespace, or also called'}, {'timestamp': (671.84, 674.16), 'text': ' profile in Kubeflow.'}, {'timestamp': (674.16, 687.84), 'text': ' And you can go to the UI and select the namespace selector to only view resources in your namespace. Also the pipelines run in user namespaces so you can'}, {'timestamp': (689.28, 697.6), 'text': ' separate extra resources like secrets or config maps or whatever you like when integrating with'}, {'timestamp': (697.6, 706.72), 'text': ' Qubeflow pipelines. Other benefits also important are like support an easier upgrade in Kubeflow.'}, {'timestamp': (708.16, 716.8), 'text': ' And we have brought new features like caching and artifact lineage auto tracking that are coming in'}, {'timestamp': (716.8, 725.94), 'text': ' this release. And do not forget that in 1.0 release, we have been doing a lot of bug fixes.'}, {'timestamp': (725.94, 735.08), 'text': ' We have improved usability and performance significantly that I hope will make the user'}, {'timestamp': (735.08, 738.22), 'text': ' experience more smoothly.'}, {'timestamp': (738.22, 740.12), 'text': ' And below are some references.'}, {'timestamp': (740.12, 742.4), 'text': ' You can get more information about this.'}, {'timestamp': (742.4, 744.26), 'text': \" I'll hand back to you, Josh.\"}, {'timestamp': (744.26, 746.08), 'text': ' Thank you. Thank you, Josh. Thank you.'}, {'timestamp': (746.92, 749.16), 'text': ' Thank you, Yuan. And I know that many people have been looking'}, {'timestamp': (749.16, 754.16), 'text': ' for the QPo pipelines, 1.0 and stable version.'}, {'timestamp': (754.8, 756.14), 'text': ' So great delivery here.'}, {'timestamp': (756.14, 758.2), 'text': ' Thank you very much for your work'}, {'timestamp': (758.2, 760.02), 'text': \" and for your team's work on this.\"}, {'timestamp': (761.2, 765.0), 'text': ' And now we hand off to Andre to give an update on Katib.'}, {'timestamp': (765.0, 774.0), 'text': \" Hi everyone. Today I'm just going to show you some quick updates for Katib, what we bring for 1.1 Kubeflow.\"}, {'timestamp': (774.0, 785.04), 'text': ' And for 1.1 Katib is still with an alpha 3.0 release, but we just bring some new features. And especially one of the main'}, {'timestamp': (789.84, 790.4), 'text': ' feature was integrating new frameworks, especially GOP tuna'}, {'timestamp': (793.6, 797.68), 'text': ' and we integrating the new high primary tunic algorithm called covariance matrix adaptation and evulsion strategy. And to'}, {'timestamp': (797.68, 800.16), 'text': ' continue integrating with neural architecture search'}, {'timestamp': (800.16, 803.84), 'text': ' algorithm, we integrated darts. This is like very common'}, {'timestamp': (803.84, 805.76), 'text': ' algorithm and should be very useful'}, {'timestamp': (806.48, 813.36), 'text': ' to use in KDIP. Also we tried to support other frameworks like Chocolate Hyperop and SQOP to'}, {'timestamp': (813.36, 825.3), 'text': ' bring more stability and usability for end user. And one of the main feature was integrating new Python SDK to'}, {'timestamp': (828.7, 829.6), 'text': ' to integrate KDP in notebooks, Kubeflow notebooks and run it'}, {'timestamp': (831.6, 832.54), 'text': ' very smoothly. Also,'}, {'timestamp': (836.34, 837.1), 'text': \" we're improving UI with new trial template editor and\"}, {'timestamp': (841.68, 842.32), 'text': ' right now users can run experiment without the goal. So it should be useful when you have'}, {'timestamp': (844.76, 852.8), 'text': ' when you want to run an experiment for a long time. And also, we integrate the resume policies, when you just easily can clean up your resources after the experiment is finished.'}, {'timestamp': (856.8, 864.8), 'text': ' Yeah, I think this is like the main features that we bring for 1.1, and also we try to make it stable for the future releases.'}, {'timestamp': (864.8, 865.2), 'text': \" Alright, now we'll hand off to make it stable for the future releases.\"}, {'timestamp': (865.2, 870.28), 'text': \" All right, now we'll hand off to Jeff to talk about CVE scanning.\"}, {'timestamp': (870.28, 871.16), 'text': ' Thanks.'}, {'timestamp': (871.16, 877.12), 'text': ' So the goal here was to mitigate some of the critical common'}, {'timestamp': (877.12, 882.08), 'text': ' vulnerabilities that we find when we scan Docker images.'}, {'timestamp': (882.08, 885.44), 'text': \" And the project's been going on, well, this process has been going on quite a while,\"}, {'timestamp': (885.44, 890.96), 'text': \" and with the creation of the new working groups, we're hoping, I'm hoping to get this\"}, {'timestamp': (891.52, 897.28), 'text': \" part of the working group process. But we've had some success with mitigating.\"}, {'timestamp': (898.8, 911.12), 'text': \" There's still a few outgoing. But more to come in the next releases. Now we get to hand it off to Animesh.\"}, {'timestamp': (911.12, 917.72), 'text': \" This is Animesh and thanks for being here. So we're going to talk in terms of\"}, {'timestamp': (917.72, 922.28), 'text': ' you know the enhancements we made to KFServing. Essentially the focus in this'}, {'timestamp': (922.28, 928.0), 'text': ' release was on stability and many features were added around that.'}, {'timestamp': (928.0, 933.0), 'text': ' But beyond stability, one of the key requirements we had around adding GPU support for PyTorch,'}, {'timestamp': (933.0, 935.0), 'text': ' model servers which was added,'}, {'timestamp': (935.0, 940.0), 'text': ' adding a Pickle format support for Scikit-learn model which was added.'}, {'timestamp': (940.0, 944.0), 'text': ' And in terms of the stability, one of the major moves which we did was'}, {'timestamp': (944.0, 948.86), 'text': ' upgrading from Knative APIs from V1 Alpha 1 to V1.'}, {'timestamp': (948.86, 954.28), 'text': ' And that also entailed in turn upgrading some of the Kubernetes dependencies to 1.15 and'}, {'timestamp': (954.28, 957.32), 'text': ' Knative dependencies to 1.11.'}, {'timestamp': (957.32, 961.32), 'text': ' That brought a lot of the features which have been made available in Knative vis-a-vis the'}, {'timestamp': (961.32, 962.32), 'text': ' stability.'}, {'timestamp': (962.32, 965.68), 'text': ' There are more enhancements which we added around'}, {'timestamp': (967.04, 973.6), 'text': ' routing. So for example, supporting internal mesh routing to inference service. So for example,'}, {'timestamp': (973.6, 980.24), 'text': ' you can route from a Kafka based event source using this mechanism. Other things were added'}, {'timestamp': (980.24, 986.4), 'text': ' around a parallelism field to allow setting auto-scaling target concurrency.'}, {'timestamp': (991.84, 998.88), 'text': ' Last but not the least, we also made the default for min replicas to one instead of zero. We have heard time and again from the community in terms of having a default scale back default to set to'}, {'timestamp': (998.88, 1004.32), 'text': ' one because in that case you take advantage of some of the delays which happen if you have'}, {'timestamp': (1004.32, 1008.88), 'text': ' defaulted back to zero. We are pretty know as Knative improves that feature will be improved'}, {'timestamp': (1009.68, 1016.16), 'text': ' to a core start from zero onwards. In addition there are quite a bit of you know talks'}, {'timestamp': (1017.84, 1028.7), 'text': \" we have compiled from different conferences which have been uploaded on the KF Serving community page, where it's either the contributors to KF Serving,\"}, {'timestamp': (1028.84, 1030.42), 'text': ' as well as the users of KF Serving,'}, {'timestamp': (1030.42, 1033.12), 'text': ' talking about the technical details,'}, {'timestamp': (1033.12, 1035.48), 'text': ' as well as their usage infrastructure.'}, {'timestamp': (1035.48, 1037.44), 'text': ' There is also a page which we have compiled,'}, {'timestamp': (1037.44, 1038.54), 'text': ' which actually goes,'}, {'timestamp': (1039.78, 1044.42), 'text': ' analysts all the different users of KF Serving,'}, {'timestamp': (1044.42, 1045.32), 'text': ' who are either'}, {'timestamp': (1045.32, 1049.52), 'text': ' running KFServing in production or providing KFServing support'}, {'timestamp': (1049.52, 1053.72), 'text': ' on their cloud platform or redistributing KFServing.'}, {'timestamp': (1053.72, 1056.08), 'text': \" So if you go, you'll see a pretty comprehensive list\"}, {'timestamp': (1056.08, 1061.2), 'text': ' at this point where we have 10 to 11 different adopters who'}, {'timestamp': (1061.2, 1064.88), 'text': ' are leveraging KFServing for their own needs.'}, {'timestamp': (1064.88, 1066.96), 'text': ' Thanks. With that, I will pass on to Igor.'}, {'timestamp': (1068.64, 1069.56), 'text': ' Hi everyone.'}, {'timestamp': (1070.42, 1073.88), 'text': ' In this version, we have made some significant improvements'}, {'timestamp': (1073.88, 1076.92), 'text': ' to GitOps processes for Kubeflow.'}, {'timestamp': (1076.92, 1081.5), 'text': ' Our goal is to simplify Kubeflow stack installation'}, {'timestamp': (1081.5, 1085.32), 'text': ' and configuration and management and eventually upgrades.'}, {'timestamp': (1085.32, 1090.88), 'text': ' So at the core of GitOps processes is Git repository,'}, {'timestamp': (1090.88, 1105.0), 'text': ' which is used as the central source of truth for all Kubeflow deployments for all environments. With GitOps, you can now commit all infrastructure'}, {'timestamp': (1107.4, 1111.56), 'text': ' as code scripts into Git,'}, {'timestamp': (1111.56, 1115.32), 'text': ' and then run installs and configurations'}, {'timestamp': (1115.32, 1117.34), 'text': ' from this Git repository.'}, {'timestamp': (1118.64, 1122.76), 'text': ' With Git, you will achieve a lot better automation'}, {'timestamp': (1122.76, 1128.72), 'text': ' and also auditing and debugging of all Kubeflow environments.'}, {'timestamp': (1128.72, 1134.32), 'text': ' And there are several GitOps projects that we would encourage you to take a look at.'}, {'timestamp': (1135.28, 1145.0), 'text': ' Here you will find a link to Erectus example of GitOps processes and a link to AgileStacks example of GitOps processes'}, {'timestamp': (1146.56, 1149.98), 'text': ' to install, deploy and manage Kubeflow.'}, {'timestamp': (1151.84, 1154.52), 'text': ' I will turn it over back to Josh.'}, {'timestamp': (1156.4, 1157.24), 'text': ' Thanks Igor.'}, {'timestamp': (1157.24, 1161.08), 'text': ' And now we will talk about some ecosystem enhancements'}, {'timestamp': (1161.08, 1163.24), 'text': ' and hand off to Clive from Seldon.'}, {'timestamp': (1165.0, 1167.0), 'text': \" Hi, thanks Josh. So I'm Clive, I'm CTO of Selden.\"}, {'timestamp': (1168.0, 1171.0), 'text': ' Selden is pleased to be part of the Kubeflow 1.1 release.'}, {'timestamp': (1172.0, 1175.0), 'text': ' So Selden is there for production ready, highly scalable inference'}, {'timestamp': (1176.0, 1178.0), 'text': ' alongside our work on the KFSR project for serverless deployment.'}, {'timestamp': (1179.0, 1182.0), 'text': ' In 1.2.1 of Selden, which comes in this release, we have new'}, {'timestamp': (1183.0, 1189.28), 'text': ' Go language service orchestrator, which is protocol agnosticostic which means we can now support Seldom and TensorFlow protocols and further'}, {'timestamp': (1189.28, 1193.76), 'text': ' protocols in the future. I mean as usual Seldom allows you to build powerful inference graphs'}, {'timestamp': (1193.76, 1200.24), 'text': \" made up of models routers ensemble and many after the box optimized model servers. We've also added\"}, {'timestamp': (1200.24, 1204.72), 'text': ' Qflow pipeline examples to show you how you can train and deploy models onto Seldom core and add'}, {'timestamp': (1204.72, 1208.12), 'text': ' key components such as state- the art outline detection drift detection.'}, {'timestamp': (1208.52, 1214.48), 'text': \" And model explanation components using Seldom's open source Adoai explain Adoai detect projects and you can find a link to those\"}, {'timestamp': (1215.16, 1224.2), 'text': \" Examples on this slide. So yeah, so in general, we're looking forward to getting your feedback and further integrating with Qflow in the future. So thanks and back to Josh.\"}, {'timestamp': (1222.16, 1224.4), 'text': ' further integrating with Kubeflow in the future. So thanks and back to Josh.'}, {'timestamp': (1225.28, 1226.72), 'text': ' Okay, well, thank you, Clive.'}, {'timestamp': (1226.72, 1230.26), 'text': \" And now we'll move on to another ecosystem enhancement\"}, {'timestamp': (1230.26, 1233.38), 'text': ' from the Feast community and off to Willem.'}, {'timestamp': (1234.44, 1235.64), 'text': ' Thanks Josh.'}, {'timestamp': (1235.64, 1238.56), 'text': ' This is Willem from the Feast community.'}, {'timestamp': (1238.56, 1241.44), 'text': \" So I'm excited to talk a bit about Feast 0.6\"}, {'timestamp': (1241.44, 1243.42), 'text': ' and what that means for Kubeflow.'}, {'timestamp': (1243.42, 1246.4), 'text': \" So with Kubeflow 1.1, it's a first step towards integrating Feast 0.6 and what that means for Kubeflow. So with Kubeflow 1.1, it's a first step towards\"}, {'timestamp': (1246.4, 1252.8), 'text': \" integrating Feast as a top-level component into Kubeflow. So for this release, we've extended the\"}, {'timestamp': (1252.8, 1258.48), 'text': ' Kubeflow documentation to include both the motivation for why you would want to use Feast,'}, {'timestamp': (1258.48, 1265.28), 'text': ' a feature store for machine learning in your use cases or for your use cases and how you can get started.'}, {'timestamp': (1265.64, 1270.76), 'text': \" So we've also included some guides on installing Feast alongside\"}, {'timestamp': (1270.76, 1275.92), 'text': ' Kubeflow, as well as tutorials and examples that show users how they can do that.'}, {'timestamp': (1276.2, 1280.96), 'text': ' So Feast is a system that essentially abstracts away your data modeling'}, {'timestamp': (1281.24, 1285.92), 'text': ' and your data engineering from your ML and operational requirements like model'}, {'timestamp': (1285.92, 1291.84), 'text': ' training and model serving. It manages ingestion jobs and the persistence of data. It allows teams'}, {'timestamp': (1291.84, 1299.04), 'text': ' to define and track features and reuse features. And it also provides a point in time correct view'}, {'timestamp': (1300.48, 1310.48), 'text': ' for retrieval of feature data for training and for serving. The latest Feast release, v0.6, also includes statistic generation and validation that'}, {'timestamp': (1310.48, 1315.6), 'text': ' ensures that your production system stays safe. For Kubeflow 1.2 and new releases,'}, {'timestamp': (1315.6, 1321.28), 'text': \" we're planning to also include or further integrate and potentially even deploy Feast\"}, {'timestamp': (1321.28, 1325.68), 'text': \" alongside Kubeflow. So we're excited to be working with the Kubeflow community on that.\"}, {'timestamp': (1326.72, 1329.04), 'text': \" That's it from my side. Back to you, Josh.\"}, {'timestamp': (1330.0, 1331.92), 'text': ' Thank you very much and a great update.'}, {'timestamp': (1332.48, 1336.48), 'text': ' And now on to simplifying blog posts with Hamil.'}, {'timestamp': (1336.48, 1338.88), 'text': ' Hamil, can you give us an update on your work here?'}, {'timestamp': (1340.16, 1347.72), 'text': ' Yeah, sure. So we now have a blog system that you can see on this'}, {'timestamp': (1347.72, 1356.56), 'text': ' GitHub repo, kuflow.blog. So the reason why we have instituted this'}, {'timestamp': (1356.56, 1363.6), 'text': ' alternative blogging system is to allow a process to happen with regards to'}, {'timestamp': (1363.6, 1368.56), 'text': ' reviewing blog posts and discussing blog posts because'}, {'timestamp': (1368.56, 1376.96), 'text': ' with Medium before it was really difficult to have a transparent process of review and'}, {'timestamp': (1376.96, 1388.16), 'text': ' the community really wanted something that looked a lot like a pull request where somebody write something and then people can comment on it and then propose'}, {'timestamp': (1388.16, 1396.0), 'text': ' or make suggestions and then it can go through some kind of formal review and then get merged.'}, {'timestamp': (1396.0, 1401.16), 'text': ' And so a question came up is whether something like that can be done with blogs.'}, {'timestamp': (1401.16, 1405.48), 'text': ' So it turns out that the Fast.ai community has'}, {'timestamp': (1405.48, 1412.32), 'text': \" something called Fast Pages. I'm the maintainer of that project and what that\"}, {'timestamp': (1412.32, 1418.28), 'text': \" project is, is it's a way where you can write blog posts with Jupyter notebooks\"}, {'timestamp': (1418.28, 1424.12), 'text': ' or Markdown and the purpose of that project is to make it really easy to'}, {'timestamp': (1424.12, 1427.0), 'text': ' write blog posts with Jupyter notebooks.'}, {'timestamp': (1427.0, 1431.0), 'text': ' Sort of before that, it was kind of difficult to write blog posts with Jupyter.'}, {'timestamp': (1431.0, 1440.0), 'text': ' You have to kind of prepare your notebook and then do a bunch of conversion scripts to kind of convert the notebook to HTML'}, {'timestamp': (1440.0, 1443.0), 'text': ' and then do all kinds of other stuff to make it suitable for a blog.'}, {'timestamp': (1443.0, 1448.0), 'text': ' And it was actually really complicated. So FastPages automates all of that.'}, {'timestamp': (1448.0, 1456.0), 'text': ' You save your notebook into a folder and then GitHub actions runs those conversion scripts for you,'}, {'timestamp': (1456.0, 1463.0), 'text': \" converts that to HTML, and then that's available as a blog post.\"}, {'timestamp': (1463.0, 1467.44), 'text': \" And so one thing that you should know is there's a lot of configuration options\"}, {'timestamp': (1467.44, 1470.88), 'text': \" and there's a lot of ways you can customize it.\"}, {'timestamp': (1471.04, 1473.84), 'text': \" And there's a lot of ways you can even customize a blog post itself,\"}, {'timestamp': (1475.0, 1477.4), 'text': ' especially the formatting and stuff like that.'}, {'timestamp': (1477.4, 1480.16), 'text': \" There's a fairly lengthy read me\"}, {'timestamp': (1480.68, 1485.76), 'text': ' that I encourage everybody to read if you are going to write a blog post. So'}, {'timestamp': (1485.76, 1491.12), 'text': \" if you go to the fast pages repo which is linked here on the slide, there's a\"}, {'timestamp': (1491.12, 1496.56), 'text': ' really big kind of like instruction manual on you know how to do things like'}, {'timestamp': (1496.56, 1503.94), 'text': ' you know embed images or tweak your social cards on your blog post or to'}, {'timestamp': (1503.94, 1506.56), 'text': ' enable comments if you want'}, {'timestamp': (1506.56, 1511.08), 'text': \" people to be able to make comments. So there's a commenting system that is\"}, {'timestamp': (1511.08, 1515.16), 'text': ' hooked in with GitHub issues so when people comment on your blog post it'}, {'timestamp': (1515.16, 1518.04), 'text': \" actually opens a GitHub issue on the blog website so it's actually pretty\"}, {'timestamp': (1518.04, 1528.16), 'text': \" convenient. And there's a lot of other cool stuff like the ability to have collapsible code cells and then you can put\"}, {'timestamp': (1529.2, 1535.84), 'text': \" images, GIFs with captions and all kinds of stuff. It's very rich. It's actually been used a lot in\"}, {'timestamp': (1535.84, 1547.28), 'text': ' the data science community and especially the Fast.ai community. We have a couple of blog posts, I think, that have launched recently from the Kubeflow community on this site.'}, {'timestamp': (1547.96, 1554.36), 'text': \" So I think, you know, I encourage everybody to check it out, and especially if you're interested in writing a blog post.\"}, {'timestamp': (1555.4, 1556.32), 'text': \" I'll give it back to you, Josh.\"}, {'timestamp': (1557.08, 1559.52), 'text': ' Hey, Hamill, thanks for all your work there.'}, {'timestamp': (1559.56, 1567.0), 'text': ' This is something critical to the growth of the community, especially in the need for us to let people know'}, {'timestamp': (1567.0, 1569.16), 'text': \" all the great work they're doing,\"}, {'timestamp': (1569.16, 1571.64), 'text': ' whether it be an article or a blog post,'}, {'timestamp': (1571.64, 1576.1), 'text': ' or even better yet, a tutorial with those notebooks in there.'}, {'timestamp': (1576.1, 1578.88), 'text': ' This is great work and we really do appreciate it.'}, {'timestamp': (1578.88, 1581.64), 'text': \" Okay, so we've covered a lot,\"}, {'timestamp': (1581.64, 1586.48), 'text': \" and now we're gonna talk about how how to get involved and especially since we've\"}, {'timestamp': (1588.88, 1597.68), 'text': ' confirmed or approved a proposal for the Kubeflow working groups. We really look forward to and encourage people to'}, {'timestamp': (1598.24, 1607.92), 'text': ' either join a working group or start one as either a team lead, a chair or a participating member.'}, {'timestamp': (1607.92, 1613.2), 'text': ' And for all of those folks that are just getting started in Kubeflow, remember we do have the'}, {'timestamp': (1613.2, 1620.04), 'text': ' Kubeflow Slack channel, the Kubeflow discuss mailing list, as well as the community meetings'}, {'timestamp': (1620.04, 1622.12), 'text': ' every Tuesday.'}, {'timestamp': (1622.12, 1627.44), 'text': ' You can see all the deliveries in Kubeflow in GitHub and we really look forward'}, {'timestamp': (1627.44, 1634.4), 'text': ' to your success with Kubeflow 1.1. And with that I would just like to make sure that as you look'}, {'timestamp': (1634.4, 1639.92), 'text': ' to join the Kubeflow community you can see on this list all the folks that have contributed'}, {'timestamp': (1639.92, 1649.14), 'text': ' in this release. There are many others but these are the ones that were primarily to this. And you can see many of this top market leaders,'}, {'timestamp': (1649.14, 1654.14), 'text': ' whether it be Ant or Bloomberg and Cisco, Google,'}, {'timestamp': (1654.38, 1659.1), 'text': ' Seldin, GitHub, Eriktto and Amazon.'}, {'timestamp': (1659.1, 1661.34), 'text': ' So I think this is a great group of folks'}, {'timestamp': (1661.34, 1664.42), 'text': ' and we really do encourage you to get involved'}, {'timestamp': (1664.42, 1666.32), 'text': ' and participate either as a'}, {'timestamp': (1666.32, 1671.36), 'text': ' contributor or user and we really do appreciate your feedback and work in the Kubeflow community.'}, {'timestamp': (1671.36, 1675.92), 'text': ' Thanks again we look forward to your questions and supporting your your work on 1.1.'}]\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "957695e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperTokenizer, WhisperFeatureExtractor, WhisperForConditionalGeneration\n",
    "\n",
    "# load pre-trained tokenizer and model\n",
    "ckpt = \"openai/whisper-large\"\n",
    "my_tokenizer = WhisperTokenizer.from_pretrained(ckpt)\n",
    "my_model = WhisperForConditionalGeneration.from_pretrained(ckpt)\n",
    "my_extractor =  WhisperFeatureExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7d55d248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50366, 1280)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define new tokens to add to vocab\n",
    "new_tokens = [\"Arriko\", \"Seldon\"]\n",
    "\n",
    "# check if the new tokens are already in the vocabulary\n",
    "#new_tokens = set(new_tokens) - set(tokenizer.vocab.keys())\n",
    "\n",
    "# add the tokens to the tokenizer vocabulary\n",
    "my_tokenizer.add_tokens(list(new_tokens))\n",
    "\n",
    "# add new random embeddings for the appended tokens\n",
    "my_model.resize_token_embeddings(len(my_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a32e354e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pipe = pipeline(\n",
    "  \"automatic-speech-recognition\",\n",
    "  model=my_model,\n",
    "  tokenizer=my_tokenizer,\n",
    "  feature_extractor=my_extractor,\n",
    "  chunk_length_s=30,\n",
    "  device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6654ba47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ray/anaconda3/lib/python3.8/site-packages/transformers/generation/utils.py:1288: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "my_text = pipe(\"audio.mp3\", return_timestamps=True)[\"chunks\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7ca7528c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'timestamp': (0.0, 9.44), 'text': \" Hello and welcome to Kubeflow update. We're going to give a Kubeflow update on the 1.1 release.\"}, {'timestamp': (9.44, 17.12), 'text': ' And I am Josh Bottom and I am part of the Kubeflow Community Product Management team.'}, {'timestamp': (18.96, 28.8), 'text': ' Kubeflow 1.1 has included several community deliveries and And in this portion, we are going to review'}, {'timestamp': (28.8, 31.4), 'text': ' the applications that have been completed,'}, {'timestamp': (31.4, 34.64), 'text': ' which finished up in August 2020.'}, {'timestamp': (35.66, 40.48), 'text': ' And in this release, we worked hard to follow the process'}, {'timestamp': (40.48, 44.76), 'text': \" that we've defined, which really came and fermented\"}, {'timestamp': (44.76, 47.0), 'text': ' around Kubeflow 1.0.'}, {'timestamp': (47.0, 54.0), 'text': ' And that includes using the Kubeflow and application roadmaps to define features in timing for releases,'}, {'timestamp': (54.0, 65.0), 'text': ' as well as the Kubeflow versioning policy, which defines the maturity level of the components, either stableava, Stable, Beta or Alpha.'}, {'timestamp': (65.64, 68.26), 'text': ' And for the Stable requirements,'}, {'timestamp': (68.26, 72.0), 'text': \" we've defined an applications requirement template,\"}, {'timestamp': (72.0, 74.9), 'text': ' or excuse me, applications requirements template,'}, {'timestamp': (74.9, 78.88), 'text': ' which gives a set of requirements that we expect folks'}, {'timestamp': (78.88, 83.12), 'text': \" to follow when they're creating a Stable version\"}, {'timestamp': (83.12, 85.0), 'text': ' of one of the components.'}, {'timestamp': (85.08, 89.76), 'text': \" We're tracking and have tracked the release of 1.1\"}, {'timestamp': (89.76, 93.32), 'text': ' in the Kanban board using this project here,'}, {'timestamp': (93.32, 97.54), 'text': ' which is just clickable, as well as this issue 5022.'}, {'timestamp': (97.54, 99.66), 'text': ' So both those are clickable and you can go through'}, {'timestamp': (99.66, 101.48), 'text': ' and look at where the progress is.'}, {'timestamp': (102.36, 107.36), 'text': ' In 1.1, you can see we made additional components stable,'}, {'timestamp': (108.5, 110.3), 'text': ' including Kubeflow pipelines,'}, {'timestamp': (110.3, 115.3), 'text': ' training operators for XGBoost and Fairen MXNet,'}, {'timestamp': (116.14, 118.7), 'text': ' and as well as the Fairen component.'}, {'timestamp': (118.7, 120.98), 'text': ' This is in addition to all the components'}, {'timestamp': (120.98, 128.08), 'text': ' that we have made stable in the March portion, the March release of Kubeflow 1.0.'}, {'timestamp': (128.72, 133.2), 'text': ' And you can see all the roadmaps for the different components that are posted'}, {'timestamp': (134.16, 141.12), 'text': ' over here in these clickable links. Kubeflow 1.1 has six major deliveries,'}, {'timestamp': (141.76, 145.68), 'text': ' and those include simplifying pipeline building workflows, so that includes'}, {'timestamp': (145.68, 152.6), 'text': ' build, train and tune as well as deploy from a notebook. Production operations and performance'}, {'timestamp': (152.6, 161.2), 'text': ' for MXNet and XGBoost distributed model training. Improved user isolation, security and administration,'}, {'timestamp': (161.2, 167.0), 'text': ' including multi-user pipelines. Improved model tuning with new frameworks and algorithms,'}, {'timestamp': (167.0, 171.0), 'text': ' as well as flexible configuration and tuning options.'}, {'timestamp': (171.0, 188.66), 'text': \" GitOps foundations for installation, configuration, and management, in some cases even upgrades, upgrades as well as easier QPLO blog posting via a fast I process that we'll talk about\"}, {'timestamp': (188.66, 190.2), 'text': ' here a little later.'}, {'timestamp': (190.2, 192.84), 'text': \" So now we're going to dive into the details.\"}, {'timestamp': (192.84, 197.8), 'text': \" In this first section we'll have Jingxi go over the fairing CUJ.\"}, {'timestamp': (197.8, 200.12), 'text': ' Jingxi, over to you.'}, {'timestamp': (200.12, 201.52), 'text': ' Hello everyone.'}, {'timestamp': (201.52, 205.0), 'text': ' So let me update the KuboFlow Firmware.'}, {'timestamp': (205.0, 216.0), 'text': ' So you know KuboFlow Firmware is a PANZ SDK that can help users to process your training code and build a doc image,'}, {'timestamp': (216.0, 226.96), 'text': ' and then deploy a job, gift job, or pet horse job to train your code and then you can use the file to public service.'}, {'timestamp': (226.96, 231.2), 'text': ' Of course, file support to public service by ksv.'}, {'timestamp': (231.2, 236.64), 'text': ' So this release we get a stable release for kubeflow file.'}, {'timestamp': (236.64, 248.94), 'text': ' So first item is that we improved the file quality in this release. And we fixed the sub-bugs and enhanced the testing'}, {'timestamp': (248.94, 253.36), 'text': ' and example under the kuboflow-finr wrapper.'}, {'timestamp': (253.36, 257.68), 'text': ' And the next one is we enhanced the API document.'}, {'timestamp': (257.68, 260.96), 'text': ' As you know, Finr has a lot of API'}, {'timestamp': (260.96, 264.82), 'text': ' and if there is no API document,'}, {'timestamp': (264.82, 268.08), 'text': ' that is very bad for the end user. So this release'}, {'timestamp': (268.8, 278.88), 'text': ' we take some effort to work on the API document enhancement. The next one is we made some'}, {'timestamp': (278.88, 287.9), 'text': ' generator function to interact with Kubernetes. So this function supports applying'}, {'timestamp': (287.9, 296.68), 'text': ' the backend spec to the Kubernetes cluster. Next one, we support one more'}, {'timestamp': (296.68, 309.84), 'text': ' build such as Podman and also support one more backend such as AmiCloud. And the next one is this release, family support'}, {'timestamp': (309.84, 318.16), 'text': \" config environment variables for deployment. That's very important for ad users. So you know\"}, {'timestamp': (319.04, 324.88), 'text': ' from this feature user can configure their environment variables for the deployment.'}, {'timestamp': (326.08, 333.0), 'text': ' user can configure their environment variables for the deployment. And also this release, FanRee supports two mountain volumes such as the PVC,'}, {'timestamp': (333.0, 337.04), 'text': ' CRID, and the config map for the deployer.'}, {'timestamp': (337.04, 344.4), 'text': ' So in one word, FanRee get stable release, so you can try the new FanRee release.'}, {'timestamp': (344.4, 348.08), 'text': ' Thank you.'}, {'timestamp': (353.24, 358.96), 'text': \" Okay. Thanks, Jiushi. Now we'll pass it over to Constantinos to talk about the KLCUJ. Constantinos? Hello, everyone. This is Constantinos from\"}, {'timestamp': (358.96, 366.04), 'text': ' Oricto. During the 1.1 release cycle, we made some significant improvements also to'}, {'timestamp': (366.04, 371.92), 'text': ' the end-to-end customer user journey for building, training, tuning and debugging'}, {'timestamp': (371.92, 376.48), 'text': \" models faster with Kailh. For those who don't know what Kailh is, Kailh is an\"}, {'timestamp': (376.48, 387.28), 'text': ' open source workflow tool on top of Kubeflow that allows you to build pipelines directly from your code in a notebook or your IDE,'}, {'timestamp': (387.28, 396.64), 'text': ' for example, VS Code. To do that, it comes as a JupyterLab extension or an SDK. So you'}, {'timestamp': (396.64, 404.48), 'text': ' simply tag a cell with your remote code via the UI to create a pipeline step. And with'}, {'timestamp': (404.48, 406.66), 'text': ' one click, Kailh snapshots the environment, builds and runs a pipeline step and with one click Kailh snapshots the environment'}, {'timestamp': (406.66, 412.1), 'text': ' builds and runs a pipeline without the need to write any'}, {'timestamp': (412.1, 420.3), 'text': ' Kubeflow pipelines DSL code or build any Docker images. So with 1.1 Kailh now'}, {'timestamp': (420.3, 425.0), 'text': ' supports HP tuning with the Kativep component of Kubeflow.'}, {'timestamp': (425.98, 430.98), 'text': ' So now you can tag shells to define hyperparameters'}, {'timestamp': (431.06, 433.5), 'text': ' and then set HP tuning job parameters'}, {'timestamp': (433.5, 437.9), 'text': ' all from a user interface, then starts the cattyp job.'}, {'timestamp': (437.9, 439.58), 'text': ' You can easily view the results'}, {'timestamp': (439.58, 443.18), 'text': ' and dig into the details provided by the pipeline runs.'}, {'timestamp': (443.18, 448.2), 'text': ' And it also comes with support for pipeline step caching'}, {'timestamp': (449.2, 452.66), 'text': ' that allows you to scale very efficiently.'}, {'timestamp': (453.7, 455.16), 'text': ' You can follow the links.'}, {'timestamp': (455.16, 460.16), 'text': ' We have an end-to-end tutorial that you can follow through'}, {'timestamp': (460.28, 463.4), 'text': ' and a video showcasing the end-to-end workflow.'}, {'timestamp': (463.4, 466.2), 'text': ' With that, back to you, Josh.'}, {'timestamp': (466.2, 468.0), 'text': ' Thanks, Carlos.'}, {'timestamp': (468.0, 471.96), 'text': \" Now we'll go to the distributed training operators.\"}, {'timestamp': (471.96, 473.4), 'text': ' Hi, everyone.'}, {'timestamp': (473.4, 476.44), 'text': ' This is Jiaxin from AWS.'}, {'timestamp': (476.44, 479.88), 'text': ' So I will give some updates on the training operators.'}, {'timestamp': (479.88, 483.4), 'text': ' In 1.1 release, community concentrate more'}, {'timestamp': (483.4, 489.0), 'text': ' on the reusability, performance, and maintainability of the training operators.'}, {'timestamp': (489.0, 494.0), 'text': ' The most important change is we released a stable Kubeflow common library.'}, {'timestamp': (494.0, 497.0), 'text': ' So some users may not have contacts of this library.'}, {'timestamp': (497.0, 505.84), 'text': ' As we know, Kubeflow has many distributed training operators and most of them have similar designs and implementations.'}, {'timestamp': (506.4, 513.76), 'text': ' So in mid 2019 we started Coolflow Common Projects, aims to extract those common reconciler'}, {'timestamp': (513.76, 519.92), 'text': ' logics and CRD types to make sure they can be reused in different training operators.'}, {'timestamp': (520.72, 529.0), 'text': ' Ideally we can add like generic logics and bug fixes in the Coolflow Common project.'}, {'timestamp': (529.0, 537.0), 'text': ' Different operators just need to upgrade common dependencies to leverage these benefits and new changes.'}, {'timestamp': (537.0, 545.4), 'text': ' In the latest stable version, it starts to support Volcano Batch Scheder, which is the main down'}, {'timestamp': (545.4, 547.28), 'text': ' scheduler offering in the community.'}, {'timestamp': (547.8, 552.56), 'text': ' It also provides the flexible interface to support like both'}, {'timestamp': (552.56, 555.44), 'text': ' informer and computer based operators.'}, {'timestamp': (556.12, 559.36), 'text': ' The app grades the dependency versions like Kubernetes,'}, {'timestamp': (559.56, 564.28), 'text': ' controller runtime, controller tools and refactor the codes to'}, {'timestamp': (564.28, 566.16), 'text': ' enhance the maintainability.'}, {'timestamp': (566.56, 570.92), 'text': ' So one last important feature is like common controller reconciles the'}, {'timestamp': (570.92, 575.36), 'text': ' workers scale down events to support dynamic or elastic training.'}, {'timestamp': (575.68, 579.6), 'text': ' So that means the number of the workers can be changed during the training.'}, {'timestamp': (579.96, 583.52), 'text': ' If the framework has the support like a torch elastic.'}, {'timestamp': (584.58, 588.64), 'text': ' if the framework has the support like torch elastic. Currently we have migrated TensorFlow, MXNet,'}, {'timestamp': (588.64, 592.14), 'text': ' XGBoost implementations to this fashion'}, {'timestamp': (592.14, 594.76), 'text': ' and PyTorch is in progress.'}, {'timestamp': (594.76, 598.12), 'text': ' The major user facing changes are MXNet,'}, {'timestamp': (598.12, 603.12), 'text': ' XGBoost and MPI operators both support V1 APIs.'}, {'timestamp': (603.46, 607.76), 'text': ' Most of the work to graduate to V1 has been done.'}, {'timestamp': (607.76, 610.52), 'text': \" However, we haven't officially claimed there are V1\"}, {'timestamp': (610.52, 614.48), 'text': ' because we want to do more scale and performance testing.'}, {'timestamp': (614.48, 619.1), 'text': ' User can use V1 API now and report issues to us.'}, {'timestamp': (620.44, 623.08), 'text': ' We have a few features and improvement plans'}, {'timestamp': (623.08, 624.72), 'text': ' in the roadmap doc.'}, {'timestamp': (624.72, 626.14), 'text': ' So feel free to take a look'}, {'timestamp': (626.3, 630.8), 'text': \" Yeah, that's all the updates from training operator side. Thank you\"}, {'timestamp': (631.86, 635.02), 'text': ' And now for the multi-user pipeline update'}, {'timestamp': (636.98, 638.86), 'text': ' Thank You Josh'}, {'timestamp': (638.86, 640.86), 'text': ' for cute little pipelines'}, {'timestamp': (641.14, 646.0), 'text': ' Now in cute for one point one, the most important thing is that'}, {'timestamp': (646.0, 653.0), 'text': \" Pipelines is now reaching 1.0 release, so it's becoming another stable component in Kubeflow.\"}, {'timestamp': (653.0, 661.0), 'text': ' The biggest feature in this release is multi-user support in Kubeflow Pipelines'}, {'timestamp': (661.0, 671.84), 'text': ' without needing to run multiple deployments. So basically, Kubeflow pipelines resources are separated by namespace, or also called'}, {'timestamp': (671.84, 674.16), 'text': ' profile in Kubeflow.'}, {'timestamp': (674.16, 687.84), 'text': ' And you can go to the UI and select the namespace selector to only view resources in your namespace. Also the pipelines run in user namespaces so you can'}, {'timestamp': (689.28, 697.6), 'text': ' separate extra resources like secrets or config maps or whatever you like when integrating with'}, {'timestamp': (697.6, 706.72), 'text': ' Qubeflow pipelines. Other benefits also important are like support an easier upgrade in Kubeflow.'}, {'timestamp': (708.16, 716.8), 'text': ' And we have brought new features like caching and artifact lineage auto tracking that are coming in'}, {'timestamp': (716.8, 725.94), 'text': ' this release. And do not forget that in 1.0 release, we have been doing a lot of bug fixes.'}, {'timestamp': (725.94, 735.08), 'text': ' We have improved usability and performance significantly that I hope will make the user'}, {'timestamp': (735.08, 738.22), 'text': ' experience more smoothly.'}, {'timestamp': (738.22, 740.12), 'text': ' And below are some references.'}, {'timestamp': (740.12, 742.4), 'text': ' You can get more information about this.'}, {'timestamp': (742.4, 744.26), 'text': \" I'll hand back to you, Josh.\"}, {'timestamp': (744.26, 746.08), 'text': ' Thank you. Thank you, Josh. Thank you.'}, {'timestamp': (746.92, 749.16), 'text': ' Thank you, Yuan. And I know that many people have been looking'}, {'timestamp': (749.16, 754.16), 'text': ' for the QPo pipelines, 1.0 and stable version.'}, {'timestamp': (754.8, 756.14), 'text': ' So great delivery here.'}, {'timestamp': (756.14, 758.2), 'text': ' Thank you very much for your work'}, {'timestamp': (758.2, 760.02), 'text': \" and for your team's work on this.\"}, {'timestamp': (761.2, 765.0), 'text': ' And now we hand off to Andre to give an update on Katib.'}, {'timestamp': (765.0, 774.0), 'text': \" Hi everyone. Today I'm just going to show you some quick updates for Katib, what we bring for 1.1 Kubeflow.\"}, {'timestamp': (774.0, 785.04), 'text': ' And for 1.1 Katib is still with an alpha 3.0 release, but we just bring some new features. And especially one of the main'}, {'timestamp': (789.84, 790.4), 'text': ' feature was integrating new frameworks, especially GOP tuna'}, {'timestamp': (793.6, 797.68), 'text': ' and we integrating the new high primary tunic algorithm called covariance matrix adaptation and evulsion strategy. And to'}, {'timestamp': (797.68, 800.16), 'text': ' continue integrating with neural architecture search'}, {'timestamp': (800.16, 803.84), 'text': ' algorithm, we integrated darts. This is like very common'}, {'timestamp': (803.84, 805.76), 'text': ' algorithm and should be very useful'}, {'timestamp': (806.48, 813.36), 'text': ' to use in KDIP. Also we tried to support other frameworks like Chocolate Hyperop and SQOP to'}, {'timestamp': (813.36, 825.3), 'text': ' bring more stability and usability for end user. And one of the main feature was integrating new Python SDK to'}, {'timestamp': (828.7, 829.6), 'text': ' to integrate KDP in notebooks, Kubeflow notebooks and run it'}, {'timestamp': (831.6, 832.54), 'text': ' very smoothly. Also,'}, {'timestamp': (836.34, 837.1), 'text': \" we're improving UI with new trial template editor and\"}, {'timestamp': (841.68, 842.32), 'text': ' right now users can run experiment without the goal. So it should be useful when you have'}, {'timestamp': (844.76, 852.8), 'text': ' when you want to run an experiment for a long time. And also, we integrate the resume policies, when you just easily can clean up your resources after the experiment is finished.'}, {'timestamp': (856.8, 864.8), 'text': ' Yeah, I think this is like the main features that we bring for 1.1, and also we try to make it stable for the future releases.'}, {'timestamp': (864.8, 865.2), 'text': \" Alright, now we'll hand off to make it stable for the future releases.\"}, {'timestamp': (865.2, 870.28), 'text': \" All right, now we'll hand off to Jeff to talk about CVE scanning.\"}, {'timestamp': (870.28, 871.16), 'text': ' Thanks.'}, {'timestamp': (871.16, 877.12), 'text': ' So the goal here was to mitigate some of the critical common'}, {'timestamp': (877.12, 882.08), 'text': ' vulnerabilities that we find when we scan Docker images.'}, {'timestamp': (882.08, 885.44), 'text': \" And the project's been going on, well, this process has been going on quite a while,\"}, {'timestamp': (885.44, 890.96), 'text': \" and with the creation of the new working groups, we're hoping, I'm hoping to get this\"}, {'timestamp': (891.52, 897.28), 'text': \" part of the working group process. But we've had some success with mitigating.\"}, {'timestamp': (898.8, 911.12), 'text': \" There's still a few outgoing. But more to come in the next releases. Now we get to hand it off to Animesh.\"}, {'timestamp': (911.12, 917.72), 'text': \" This is Animesh and thanks for being here. So we're going to talk in terms of\"}, {'timestamp': (917.72, 922.28), 'text': ' you know the enhancements we made to KFServing. Essentially the focus in this'}, {'timestamp': (922.28, 928.0), 'text': ' release was on stability and many features were added around that.'}, {'timestamp': (928.0, 933.0), 'text': ' But beyond stability, one of the key requirements we had around adding GPU support for PyTorch,'}, {'timestamp': (933.0, 935.0), 'text': ' model servers which was added,'}, {'timestamp': (935.0, 940.0), 'text': ' adding a Pickle format support for Scikit-learn model which was added.'}, {'timestamp': (940.0, 944.0), 'text': ' And in terms of the stability, one of the major moves which we did was'}, {'timestamp': (944.0, 948.86), 'text': ' upgrading from Knative APIs from V1 Alpha 1 to V1.'}, {'timestamp': (948.86, 954.28), 'text': ' And that also entailed in turn upgrading some of the Kubernetes dependencies to 1.15 and'}, {'timestamp': (954.28, 957.32), 'text': ' Knative dependencies to 1.11.'}, {'timestamp': (957.32, 961.32), 'text': ' That brought a lot of the features which have been made available in Knative vis-a-vis the'}, {'timestamp': (961.32, 962.32), 'text': ' stability.'}, {'timestamp': (962.32, 965.68), 'text': ' There are more enhancements which we added around'}, {'timestamp': (967.04, 973.6), 'text': ' routing. So for example, supporting internal mesh routing to inference service. So for example,'}, {'timestamp': (973.6, 980.24), 'text': ' you can route from a Kafka based event source using this mechanism. Other things were added'}, {'timestamp': (980.24, 986.4), 'text': ' around a parallelism field to allow setting auto-scaling target concurrency.'}, {'timestamp': (991.84, 998.88), 'text': ' Last but not the least, we also made the default for min replicas to one instead of zero. We have heard time and again from the community in terms of having a default scale back default to set to'}, {'timestamp': (998.88, 1004.32), 'text': ' one because in that case you take advantage of some of the delays which happen if you have'}, {'timestamp': (1004.32, 1008.88), 'text': ' defaulted back to zero. We are pretty know as Knative improves that feature will be improved'}, {'timestamp': (1009.68, 1016.16), 'text': ' to a core start from zero onwards. In addition there are quite a bit of you know talks'}, {'timestamp': (1017.84, 1028.7), 'text': \" we have compiled from different conferences which have been uploaded on the KF Serving community page, where it's either the contributors to KF Serving,\"}, {'timestamp': (1028.84, 1030.42), 'text': ' as well as the users of KF Serving,'}, {'timestamp': (1030.42, 1033.12), 'text': ' talking about the technical details,'}, {'timestamp': (1033.12, 1035.48), 'text': ' as well as their usage infrastructure.'}, {'timestamp': (1035.48, 1037.44), 'text': ' There is also a page which we have compiled,'}, {'timestamp': (1037.44, 1038.54), 'text': ' which actually goes,'}, {'timestamp': (1039.78, 1044.42), 'text': ' analysts all the different users of KF Serving,'}, {'timestamp': (1044.42, 1045.32), 'text': ' who are either'}, {'timestamp': (1045.32, 1049.52), 'text': ' running KFServing in production or providing KFServing support'}, {'timestamp': (1049.52, 1053.72), 'text': ' on their cloud platform or redistributing KFServing.'}, {'timestamp': (1053.72, 1056.08), 'text': \" So if you go, you'll see a pretty comprehensive list\"}, {'timestamp': (1056.08, 1061.2), 'text': ' at this point where we have 10 to 11 different adopters who'}, {'timestamp': (1061.2, 1064.88), 'text': ' are leveraging KFServing for their own needs.'}, {'timestamp': (1064.88, 1066.96), 'text': ' Thanks. With that, I will pass on to Igor.'}, {'timestamp': (1068.64, 1069.56), 'text': ' Hi everyone.'}, {'timestamp': (1070.42, 1073.88), 'text': ' In this version, we have made some significant improvements'}, {'timestamp': (1073.88, 1076.92), 'text': ' to GitOps processes for Kubeflow.'}, {'timestamp': (1076.92, 1081.5), 'text': ' Our goal is to simplify Kubeflow stack installation'}, {'timestamp': (1081.5, 1085.32), 'text': ' and configuration and management and eventually upgrades.'}, {'timestamp': (1085.32, 1090.88), 'text': ' So at the core of GitOps processes is Git repository,'}, {'timestamp': (1090.88, 1105.0), 'text': ' which is used as the central source of truth for all Kubeflow deployments for all environments. With GitOps, you can now commit all infrastructure'}, {'timestamp': (1107.4, 1111.56), 'text': ' as code scripts into Git,'}, {'timestamp': (1111.56, 1115.32), 'text': ' and then run installs and configurations'}, {'timestamp': (1115.32, 1117.34), 'text': ' from this Git repository.'}, {'timestamp': (1118.64, 1122.76), 'text': ' With Git, you will achieve a lot better automation'}, {'timestamp': (1122.76, 1128.72), 'text': ' and also auditing and debugging of all Kubeflow environments.'}, {'timestamp': (1128.72, 1134.32), 'text': ' And there are several GitOps projects that we would encourage you to take a look at.'}, {'timestamp': (1135.28, 1145.0), 'text': ' Here you will find a link to Erectus example of GitOps processes and a link to AgileStacks example of GitOps processes'}, {'timestamp': (1146.56, 1149.98), 'text': ' to install, deploy and manage Kubeflow.'}, {'timestamp': (1151.84, 1154.52), 'text': ' I will turn it over back to Josh.'}, {'timestamp': (1156.4, 1157.24), 'text': ' Thanks Igor.'}, {'timestamp': (1157.24, 1161.08), 'text': ' And now we will talk about some ecosystem enhancements'}, {'timestamp': (1161.08, 1163.24), 'text': ' and hand off to Clive from Seldon.'}, {'timestamp': (1165.0, 1167.0), 'text': \" Hi, thanks Josh. So I'm Clive, I'm CTO of Selden.\"}, {'timestamp': (1168.0, 1171.0), 'text': ' Selden is pleased to be part of the Kubeflow 1.1 release.'}, {'timestamp': (1172.0, 1175.0), 'text': ' So Selden is there for production ready, highly scalable inference'}, {'timestamp': (1176.0, 1178.0), 'text': ' alongside our work on the KFSR project for serverless deployment.'}, {'timestamp': (1179.0, 1182.0), 'text': ' In 1.2.1 of Selden, which comes in this release, we have new'}, {'timestamp': (1183.0, 1189.28), 'text': ' Go language service orchestrator, which is protocol agnosticostic which means we can now support Seldom and TensorFlow protocols and further'}, {'timestamp': (1189.28, 1193.76), 'text': ' protocols in the future. I mean as usual Seldom allows you to build powerful inference graphs'}, {'timestamp': (1193.76, 1200.24), 'text': \" made up of models routers ensemble and many after the box optimized model servers. We've also added\"}, {'timestamp': (1200.24, 1204.72), 'text': ' Qflow pipeline examples to show you how you can train and deploy models onto Seldom core and add'}, {'timestamp': (1204.72, 1208.12), 'text': ' key components such as state- the art outline detection drift detection.'}, {'timestamp': (1208.52, 1214.48), 'text': \" And model explanation components using Seldom's open source Adoai explain Adoai detect projects and you can find a link to those\"}, {'timestamp': (1215.16, 1224.2), 'text': \" Examples on this slide. So yeah, so in general, we're looking forward to getting your feedback and further integrating with Qflow in the future. So thanks and back to Josh.\"}, {'timestamp': (1222.16, 1224.4), 'text': ' further integrating with Kubeflow in the future. So thanks and back to Josh.'}, {'timestamp': (1225.28, 1226.72), 'text': ' Okay, well, thank you, Clive.'}, {'timestamp': (1226.72, 1230.26), 'text': \" And now we'll move on to another ecosystem enhancement\"}, {'timestamp': (1230.26, 1233.38), 'text': ' from the Feast community and off to Willem.'}, {'timestamp': (1234.44, 1235.64), 'text': ' Thanks Josh.'}, {'timestamp': (1235.64, 1238.56), 'text': ' This is Willem from the Feast community.'}, {'timestamp': (1238.56, 1241.44), 'text': \" So I'm excited to talk a bit about Feast 0.6\"}, {'timestamp': (1241.44, 1243.42), 'text': ' and what that means for Kubeflow.'}, {'timestamp': (1243.42, 1246.4), 'text': \" So with Kubeflow 1.1, it's a first step towards integrating Feast 0.6 and what that means for Kubeflow. So with Kubeflow 1.1, it's a first step towards\"}, {'timestamp': (1246.4, 1252.8), 'text': \" integrating Feast as a top-level component into Kubeflow. So for this release, we've extended the\"}, {'timestamp': (1252.8, 1258.48), 'text': ' Kubeflow documentation to include both the motivation for why you would want to use Feast,'}, {'timestamp': (1258.48, 1265.28), 'text': ' a feature store for machine learning in your use cases or for your use cases and how you can get started.'}, {'timestamp': (1265.64, 1270.76), 'text': \" So we've also included some guides on installing Feast alongside\"}, {'timestamp': (1270.76, 1275.92), 'text': ' Kubeflow, as well as tutorials and examples that show users how they can do that.'}, {'timestamp': (1276.2, 1280.96), 'text': ' So Feast is a system that essentially abstracts away your data modeling'}, {'timestamp': (1281.24, 1285.92), 'text': ' and your data engineering from your ML and operational requirements like model'}, {'timestamp': (1285.92, 1291.84), 'text': ' training and model serving. It manages ingestion jobs and the persistence of data. It allows teams'}, {'timestamp': (1291.84, 1299.04), 'text': ' to define and track features and reuse features. And it also provides a point in time correct view'}, {'timestamp': (1300.48, 1310.48), 'text': ' for retrieval of feature data for training and for serving. The latest Feast release, v0.6, also includes statistic generation and validation that'}, {'timestamp': (1310.48, 1315.6), 'text': ' ensures that your production system stays safe. For Kubeflow 1.2 and new releases,'}, {'timestamp': (1315.6, 1321.28), 'text': \" we're planning to also include or further integrate and potentially even deploy Feast\"}, {'timestamp': (1321.28, 1325.68), 'text': \" alongside Kubeflow. So we're excited to be working with the Kubeflow community on that.\"}, {'timestamp': (1326.72, 1329.04), 'text': \" That's it from my side. Back to you, Josh.\"}, {'timestamp': (1330.0, 1331.92), 'text': ' Thank you very much and a great update.'}, {'timestamp': (1332.48, 1336.48), 'text': ' And now on to simplifying blog posts with Hamil.'}, {'timestamp': (1336.48, 1338.88), 'text': ' Hamil, can you give us an update on your work here?'}, {'timestamp': (1340.16, 1347.72), 'text': ' Yeah, sure. So we now have a blog system that you can see on this'}, {'timestamp': (1347.72, 1356.56), 'text': ' GitHub repo, kuflow.blog. So the reason why we have instituted this'}, {'timestamp': (1356.56, 1363.6), 'text': ' alternative blogging system is to allow a process to happen with regards to'}, {'timestamp': (1363.6, 1368.56), 'text': ' reviewing blog posts and discussing blog posts because'}, {'timestamp': (1368.56, 1376.96), 'text': ' with Medium before it was really difficult to have a transparent process of review and'}, {'timestamp': (1376.96, 1388.16), 'text': ' the community really wanted something that looked a lot like a pull request where somebody write something and then people can comment on it and then propose'}, {'timestamp': (1388.16, 1396.0), 'text': ' or make suggestions and then it can go through some kind of formal review and then get merged.'}, {'timestamp': (1396.0, 1401.16), 'text': ' And so a question came up is whether something like that can be done with blogs.'}, {'timestamp': (1401.16, 1405.48), 'text': ' So it turns out that the Fast.ai community has'}, {'timestamp': (1405.48, 1412.32), 'text': \" something called Fast Pages. I'm the maintainer of that project and what that\"}, {'timestamp': (1412.32, 1418.28), 'text': \" project is, is it's a way where you can write blog posts with Jupyter notebooks\"}, {'timestamp': (1418.28, 1424.12), 'text': ' or Markdown and the purpose of that project is to make it really easy to'}, {'timestamp': (1424.12, 1427.0), 'text': ' write blog posts with Jupyter notebooks.'}, {'timestamp': (1427.0, 1431.0), 'text': ' Sort of before that, it was kind of difficult to write blog posts with Jupyter.'}, {'timestamp': (1431.0, 1440.0), 'text': ' You have to kind of prepare your notebook and then do a bunch of conversion scripts to kind of convert the notebook to HTML'}, {'timestamp': (1440.0, 1443.0), 'text': ' and then do all kinds of other stuff to make it suitable for a blog.'}, {'timestamp': (1443.0, 1448.0), 'text': ' And it was actually really complicated. So FastPages automates all of that.'}, {'timestamp': (1448.0, 1456.0), 'text': ' You save your notebook into a folder and then GitHub actions runs those conversion scripts for you,'}, {'timestamp': (1456.0, 1463.0), 'text': \" converts that to HTML, and then that's available as a blog post.\"}, {'timestamp': (1463.0, 1467.44), 'text': \" And so one thing that you should know is there's a lot of configuration options\"}, {'timestamp': (1467.44, 1470.88), 'text': \" and there's a lot of ways you can customize it.\"}, {'timestamp': (1471.04, 1473.84), 'text': \" And there's a lot of ways you can even customize a blog post itself,\"}, {'timestamp': (1475.0, 1477.4), 'text': ' especially the formatting and stuff like that.'}, {'timestamp': (1477.4, 1480.16), 'text': \" There's a fairly lengthy read me\"}, {'timestamp': (1480.68, 1485.76), 'text': ' that I encourage everybody to read if you are going to write a blog post. So'}, {'timestamp': (1485.76, 1491.12), 'text': \" if you go to the fast pages repo which is linked here on the slide, there's a\"}, {'timestamp': (1491.12, 1496.56), 'text': ' really big kind of like instruction manual on you know how to do things like'}, {'timestamp': (1496.56, 1503.94), 'text': ' you know embed images or tweak your social cards on your blog post or to'}, {'timestamp': (1503.94, 1506.56), 'text': ' enable comments if you want'}, {'timestamp': (1506.56, 1511.08), 'text': \" people to be able to make comments. So there's a commenting system that is\"}, {'timestamp': (1511.08, 1515.16), 'text': ' hooked in with GitHub issues so when people comment on your blog post it'}, {'timestamp': (1515.16, 1518.04), 'text': \" actually opens a GitHub issue on the blog website so it's actually pretty\"}, {'timestamp': (1518.04, 1528.16), 'text': \" convenient. And there's a lot of other cool stuff like the ability to have collapsible code cells and then you can put\"}, {'timestamp': (1529.2, 1535.84), 'text': \" images, GIFs with captions and all kinds of stuff. It's very rich. It's actually been used a lot in\"}, {'timestamp': (1535.84, 1547.28), 'text': ' the data science community and especially the Fast.ai community. We have a couple of blog posts, I think, that have launched recently from the Kubeflow community on this site.'}, {'timestamp': (1547.96, 1554.36), 'text': \" So I think, you know, I encourage everybody to check it out, and especially if you're interested in writing a blog post.\"}, {'timestamp': (1555.4, 1556.32), 'text': \" I'll give it back to you, Josh.\"}, {'timestamp': (1557.08, 1559.52), 'text': ' Hey, Hamill, thanks for all your work there.'}, {'timestamp': (1559.56, 1567.0), 'text': ' This is something critical to the growth of the community, especially in the need for us to let people know'}, {'timestamp': (1567.0, 1569.16), 'text': \" all the great work they're doing,\"}, {'timestamp': (1569.16, 1571.64), 'text': ' whether it be an article or a blog post,'}, {'timestamp': (1571.64, 1576.1), 'text': ' or even better yet, a tutorial with those notebooks in there.'}, {'timestamp': (1576.1, 1578.88), 'text': ' This is great work and we really do appreciate it.'}, {'timestamp': (1578.88, 1581.64), 'text': \" Okay, so we've covered a lot,\"}, {'timestamp': (1581.64, 1586.48), 'text': \" and now we're gonna talk about how how to get involved and especially since we've\"}, {'timestamp': (1588.88, 1597.68), 'text': ' confirmed or approved a proposal for the Kubeflow working groups. We really look forward to and encourage people to'}, {'timestamp': (1598.24, 1607.92), 'text': ' either join a working group or start one as either a team lead, a chair or a participating member.'}, {'timestamp': (1607.92, 1613.2), 'text': ' And for all of those folks that are just getting started in Kubeflow, remember we do have the'}, {'timestamp': (1613.2, 1620.04), 'text': ' Kubeflow Slack channel, the Kubeflow discuss mailing list, as well as the community meetings'}, {'timestamp': (1620.04, 1622.12), 'text': ' every Tuesday.'}, {'timestamp': (1622.12, 1627.44), 'text': ' You can see all the deliveries in Kubeflow in GitHub and we really look forward'}, {'timestamp': (1627.44, 1634.4), 'text': ' to your success with Kubeflow 1.1. And with that I would just like to make sure that as you look'}, {'timestamp': (1634.4, 1639.92), 'text': ' to join the Kubeflow community you can see on this list all the folks that have contributed'}, {'timestamp': (1639.92, 1649.14), 'text': ' in this release. There are many others but these are the ones that were primarily to this. And you can see many of this top market leaders,'}, {'timestamp': (1649.14, 1654.14), 'text': ' whether it be Ant or Bloomberg and Cisco, Google,'}, {'timestamp': (1654.38, 1659.1), 'text': ' Seldin, GitHub, Eriktto and Amazon.'}, {'timestamp': (1659.1, 1661.34), 'text': ' So I think this is a great group of folks'}, {'timestamp': (1661.34, 1664.42), 'text': ' and we really do encourage you to get involved'}, {'timestamp': (1664.42, 1666.32), 'text': ' and participate either as a'}, {'timestamp': (1666.32, 1671.36), 'text': ' contributor or user and we really do appreciate your feedback and work in the Kubeflow community.'}, {'timestamp': (1671.36, 1675.92), 'text': ' Thanks again we look forward to your questions and supporting your your work on 1.1.'}]\n"
     ]
    }
   ],
   "source": [
    "print(my_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f97ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
